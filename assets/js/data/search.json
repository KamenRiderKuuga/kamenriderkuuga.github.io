[ { "title": "wrk简介与使用备忘", "url": "/posts/wrk-1/", "categories": "wrk", "tags": "技术备忘, 自动化测试, wrk", "date": "2024-11-03 00:00:00 +0800", "snippet": "一、什么是wrk在平时的开发过程中，对于部分业务，我们对其性能具有一定的要求，或者想对其QPS达到多少有一个大概的概念，这时候就需要借助基准测试工具wrk是一款针对HTTP协议的基准测试工具，具备如下优点： 轻量级性能测试工具，安装简单 学习成本低 基于异步事件驱动框架，单机支持并发高比较常用的性能测试工具有Apache JMeter，Apache ab等，但是对于开发人员来说，在不需...", "content": "一、什么是wrk在平时的开发过程中，对于部分业务，我们对其性能具有一定的要求，或者想对其QPS达到多少有一个大概的概念，这时候就需要借助基准测试工具wrk是一款针对HTTP协议的基准测试工具，具备如下优点： 轻量级性能测试工具，安装简单 学习成本低 基于异步事件驱动框架，单机支持并发高比较常用的性能测试工具有Apache JMeter，Apache ab等，但是对于开发人员来说，在不需要如接口串联，场景压测等太多丰富功能的情况下，用JMeter这样的工具过于重了。而相对轻量，简单的选择中，ab的性能和wrk比起来又逊色不少（Nginx官方进行压测时也用wrk，而ab只能使用单核。本身就可能是压测的瓶颈），所以在日常工作中，推荐使用wrk对想要测试的接口进行基准测试二、安装因为wrk使用了一些限定于类UNIX操作系统使用的的编程特性，比如epoll，kqueue等来保证其在低资源占用情况下还能保证如此好的性能，所以我们只能在Linux环境，或者通过在Windows上运行的WSL子系统，虚拟机等环境使用它通常的网络教程会让我们先从Github上拉取最新的源码，再在自己电脑上进行构建，我们这里直接下载安装别人构建好的最新版：结合在我们公司经常接触到的Linux环境（CentOS），先下载RPM包，RPM resource wrk ，然后安装：yum install -y ./wrk-4.2.0-1.2.x86_64.rpm三、使用示例 wrk只占用非常少的资源，可选参数：-c, --connections: total number of HTTP connections to keep open with each thread handling N = connections/threads-d, --duration: duration of the test, e.g. 2s, 2m, 2h-t, --threads: total number of threads to use-s, --script: LuaJIT script, see SCRIPTING-H, --header: HTTP header to add to request, e.g. \"User-Agent: wrk\" --latency: print detailed latency statistics --timeout: record a timeout if a response is not received within this amount of time.3.1 GET请求命令示例，这里以携带了一个Authorization头的请求为例：wrk -c12 -t12 -d30s --latency -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzZXJ2ZXIiOmZhbHNlLCJzdWIiOiIzNzE1NjczMDQ3ODE4OTMiLCJ1c2VyX25hbWUiOiIxODg4ODg4 ODg4OCIsInNjb3BlIjpbInNldmVyIl0sIm5hbWUiOiIxODg4ODg4ODg4OCIsImV4cCI6MTY3NjI1MDU3MiwianRpIjoiOTZkOTNkZjgtZjI1ZS00YTVkLTkyZWMtZmNiNmVhOWQ2ZGIxIiwidGVuYW50IjoidDM3MTY3NzU4OTU5NDI4MCIsI mNsaWVudF9pZCI6InN5cyJ9.vIhY2tf9uLJepxt5T8EV5DEqgiOL2rhLYl411rQ6qMU\" 'http://192.168.100.1:8080/api/iot-device/devicemanage/v1/device/detail?instance=yvS58FQ8&amp;deviceId=ktj10'3.2 POST请求 要发起POST请求，需要在lua脚本中指定body内容命令示例：wrk -c100 -t12 -d30s -s wrk.lua http://192.168.100.1:8080/api/script-engine/runner/v1/decodewrk.lua文件内容：wrk.method = \"POST\"wrk.body = \"{\\\"language\\\":\\\"JavaScript\\\",\\\"script\\\":\\\"business/public/script-engine/debug.js\\\"}\"wrk.headers[\"Content-Type\"] = \"application/json\"四、测试报告Running 30s test @ http://192.168.3.24:8080 12 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 675.82us 477.60us 21.34ms 89.46% Req/Sec 11.62k 0.90k 16.35k 68.86% Latency Distribution 50% 550.00us 75% 806.00us 90% 1.14ms 99% 2.35ms 4165550 requests in 30.04s, 158.90MB readRequests/sec: 138683.40Transfer/sec: 5.29MB会对测试的延迟分布情况，吞吐量等有一个直观的报告，在这里不多赘述，如图，代表在30秒内完成了4165550次请求，平均每秒138683.40次，并且百分之99以上的请求延迟都在2.35ms以内五、注意事项 对比压测结果，记得结合实际运行服务的机器的实际情况，比如测试一个部署在自己电脑上的接口，与测试部署在开发环境的接口，因为电脑的配置不同，通常会有较为明显的差异，不能直接进行比较 在对开发环境的服务进行压力测试时，建议直接请求服务暴露出来的宿主机端口，而不是经过网关，因为在需要非常高性能的情况下，往往网关是一个不能突破的瓶颈 若要对开发环境的服务进行压测，请在Rancher上对自己的服务允许使用的最大内存进行预限制，防止因为无限制占用资源影响到整个环境的稳定性参考资料 wg/wrk: Modern HTTP benchmarking tool (github.com) 不同性能压测工具对比 (aliyun.com) wrk（2）- Lua 脚本的使用 - 小菠萝测试笔记 - 博客园 (cnblogs.com)" }, { "title": "Erlang程序设计", "url": "/posts/Erlang-1/", "categories": "Erlang", "tags": "读书札记, 编程技术", "date": "2024-08-09 00:00:00 +0800", "snippet": "第三章 变量 在Erlang里，变量就像数学里的那样。当关联一个值与一个变量时，所下的是一种断言， 也就是事实陈述。这个变量具有那个值，仅此而已。 变量的作用域是它定义时所处的语汇单元。因此，如果X被用在一条单独的函数子句 之内，它的值就不会“逃出”这个子句。没有同一函数的不同子句共享全局或私有变量这种说法。 如果X出现在许多不同的函数里，那么所有这些X的值都是不相干的。 Erlan...", "content": "第三章 变量 在Erlang里，变量就像数学里的那样。当关联一个值与一个变量时，所下的是一种断言， 也就是事实陈述。这个变量具有那个值，仅此而已。 变量的作用域是它定义时所处的语汇单元。因此，如果X被用在一条单独的函数子句 之内，它的值就不会“逃出”这个子句。没有同一函数的不同子句共享全局或私有变量这种说法。 如果X出现在许多不同的函数里，那么所有这些X的值都是不相干的。 Erlang里没有可变状态，没有共享内存，也没有锁。这让程序并行变得简单了。 模式匹配例子：{X,abc} = {123,abc}. % X = 123{X,Y,Z} = {222,def,\"cat\"}. % X = 222, Y = def, Z = \"cat\"{X,Y} = {333,ghi,\"cat\"}. % 失败：元组的形状不同X = true. % X = true{X,Y,X} = {{abc,12},42,{abc,12}}. % X = {abc,12}, Y = 42{X,Y,X} = {{abc,12},42,true}. % 失败：X不能既是{abc,12}又是true[H|T] = [1,2,3,4,5]. % H = 1, T = [2,3,4,5][H|T] = \"cat\". % H = 99, T = \"at\"[A,B,C|T] = [a,b,c,d,e,f]. % A = a, B = b, C = c, T = [d,e,f] f()命令让shell忘记现有的任何绑定。第四章 模块与函数% 模块声明，模块名必须与文件名相同-module(geometry).% 导出声明，Name/N代表带有N个参数的函数Name，N被称为函数的arity（元数）% export的参数是一个函数列表，表示这些函数可以被外部调用% 未从模块导出的函数相当于OOPL（面向对象编程语言）中的私有函数，只能在模块内部调用-export([area/1, test/0]).% area函数有两个字句，采用分号分隔，每个字句都有一个头部和一个主题% 头部包含函数名，后接零个或更多模式% 主体包含一列表达式，会在头部里的模式与调用参数成功匹配时执行，会按照子句的定义顺序进行匹配area({rectangle, Width, Height}) -&gt; Width * Height;area({square, Side}) -&gt; Side * Side.% test函数用于测试area函数test() -&gt; 12 = area({rectangle, 3, 4}), 144 = area({square, 12}), tests_worked.c(geomerty)命令可以编译上面的代码，编译成功后会在当前目录生成一个名为geometry.beam的目标代码模块。 如果你碰巧选择了与系统模块相冲突的模块名，那么编译模块时会得到一条奇怪的消息，说不能加载位于固定目录（sticky directory）的模块。只需重命名那个模块，然后删除编译模块时生成的所有.beam文件就可以了。 Erlang shell有许多内建命令可供查看和修改当前的工作目录。 pwd()打印当前工作目录。 ls()列出当前工作目录里所有的文件名。 cd(Dir)修改当前工作目录至Dir。 逗号（,）分隔函数调用、数据构造和模式中的参数。 分号（;）分隔子句。我们能在很多地方看到子句，例如函数定义，以及case、if、try..catch和receive表达式。 句号（.）（后接空白）分隔函数整体，以及shell里的表达式。 Erlang是一种函数式编程语言。此外，函数式编程语言还表示函数可以被用作其他函数的参数，也可以返回函数。操作其他函数的函数被称为高阶函数（higher-order function），而在Erlang中用于代表函数的数据类型被称为fun。L = [1, 2, 3, 4],% 将会输出[2, 4, 6, 8]lists:map(fun(X) -&gt; X * 2 end, L). map和filter等函数能在一次调用里对整个列表执行某种操作，我们把它们称为一次一列表（list-at-a-time）式操作。使用一次一列表式操作让程序变得更小，而且易于理解。之所以易于理解是因为我们可以把对整个列表的每一次操作看作程序的单个概念性步骤。否则，就必须将对列表元素的每一次操作视为程序的单独步骤了。1&gt; Fruit = [apple, pear, orange].[apple,pear,orange]2&gt; MakeTest = fun(L) -&gt; (fun(X) -&gt; lists:member(X, L) end) end.#Fun&lt;erl_eval.42.39164016&gt;3&gt; IsFruit = MakeTest(Fruit).#Fun&lt;erl_eval.42.39164016&gt;4&gt; IsFruit(pear).true5&gt; IsFruit(apple).true6&gt; IsFruit(dog).false 记住，括号里的东西就是返回值。MakeTest(Fruit)执行后返回fun(X) -&gt; lists:member(X, Fruit) end，即一个关于X的函数，Fruit是前面的fun的参数。IsFruit(apple)，即是计算lists:member(apple, Fruit)的值。定义自己的控制抽象：-module(lib_misc).-export([for/3, test_for/0]).for(Max, Max, F) -&gt; [F(Max)];for(I, Max, F) -&gt; [F(I) | for(I + 1, Max, F)].test_for() -&gt; [2, 4, 6, 8] = for(1, 4, fun(X) -&gt; X * 2 end), tests_worked.自定义sum与map：-module(mylists).-export([sum/1, test_sum/0, map/2, test_map/0]).sum([H | T]) -&gt; H + sum(T);sum([]) -&gt; 0.map(F, [H | T]) -&gt; [F(H) | map(F, T)];map(_, []) -&gt; [].test_sum() -&gt; 10 = sum([1, 2, 3, 4]), tests_worked.test_map() -&gt; [2, 4, 6, 8] = map(fun(X) -&gt; X * 2 end, [1, 2, 3, 4]), tests_worked. 编写程序时，我的做法是“编写一点”然后“测试一点”。我从一个包含少量函数的小模 块开始，先编译它，然后在shell里用一些命令测试它。当我觉得满意后，就会再编写一些函数， 编译它们，测试它们，以此类推。 通常，我并不完全确定程序需要什么样的数据结构，通过测试那些样本代码，我就能看 出所选的数据结构是否合适。 我倾向于让程序“生长”，而不是事先就完全想好要如何编写它们，这样就不会在出现问 题时才发现犯了大错。最重要的是，这样做很有趣。我能立即获得反馈，而且只要在程序里输 入就能知道我的想法是否有效。 一旦弄清楚如何在shell里做某些事情，我通常就会转而编写makefile和一些代码，重现我 在shell里学到的内容。1&gt; L = [1,2,3,4,5].[1,2,3,4,5]2&gt; [2*X || X &lt;- L].[2,4,6,8,10]上面的方式叫做列表推导，这种[F(X) || X &lt;- L]的写法，表示一个由F(X)组成的列表，而X是从L当中提取的。" }, { "title": "Java异步编程漫游", "url": "/posts/Java-1/", "categories": "Java", "tags": "技术分享, 编程技术, 异步编程", "date": "2024-01-30 00:00:00 +0800", "snippet": " 原本计划分享ZooKeeper，但作为许多基础组件的组件，它离运维越来越近，离业务开发越来越远，以至于不容易找到或者举出什么真实的业务例子来介绍Zookeeper在实际工作中应该如何使用（比如虽然它可以拿来做分布式锁，却不是首选）。加上我并不认为短短的一个小时能介绍完ZooKeeper的重要内容，经过一番抉择之后，最终决定分享Java异步编程的相关内容，也是一个科普 + 知识漫游。一、前...", "content": " 原本计划分享ZooKeeper，但作为许多基础组件的组件，它离运维越来越近，离业务开发越来越远，以至于不容易找到或者举出什么真实的业务例子来介绍Zookeeper在实际工作中应该如何使用（比如虽然它可以拿来做分布式锁，却不是首选）。加上我并不认为短短的一个小时能介绍完ZooKeeper的重要内容，经过一番抉择之后，最终决定分享Java异步编程的相关内容，也是一个科普 + 知识漫游。一、前言在程序中发起请求是一个很常见的操作，访问数据库，发送邮件，使用搜索引擎时，我们都在发起请求。网络的使用极大扩展了我们的程序能力，但与此同时也需要付出代价，在使用网络进行通信的分布式架构下，我们需要承担网络故障和延迟可能对我们造成的影响，并且每个服务经常需要维护多个传入和传出的网络连接。 在编程时遇到需要同时处理多个网络请求时，应该采用什么策略呢，我们从简单的阻塞API讲起。一、简单的阻塞API服务需要管理多个请求时，传统且普遍的形式就是为每个连接都分配一个线程，很多框架或者组件也是用的这样的模型，比如：Python的Flask，Spring（在3.0之前），ASP.NET（现在也叫ASP.NET Core，在4.5版本之前）。这种模式的优点是简单，因为它是同步的，但是弊端也很明显。我们来看这张图：使用阻塞模型时，线程干等着网络IO，什么也干不了，虽然这些等待中的线程不处于运行状态，也不占用任何CPU资源，但线程在操作系统中绝对不是廉价的资源。线程需要消耗内存（比如JVM的 -Xss参数就是用来设置为每个Java线程分配的栈内存大小，在64位操作系统下，一个Java线程通常会被分配1MB大小的线程栈），并且操作系统为了调度线程，频繁进行线程切换也需要消耗CPU资源。虽然可以引入线程池来减轻开启新线程的代价，但无论如何，还是很容易出现需要的线程数比线程池的可用线程数要高的情况，当成千上万的请求一下子到来的时候，这种方案的局限性是显而易见的。二、基于非阻塞IO的异步编程为了解决同步阻塞IO带来的种种问题，Java标准库引入了NIO相关包。Java标准库的NIO提供了Channel，Selector等抽象，其工作模式像这样（这里写while(true)只是想说明当前只用了一个线程在循环处理）： 上图中的Selector会调用内核的I/O多路复用器(select()，poll()，或Linux特有的epoll()，这部分具体的工作原理相对比较深，本次「漫游」就不涉及到这些内容了，想深入了解的建议读一下《Linux/UNIX系统编程手册》这本书中的相关内容)。NIO的思路是先请求一个操作（阻塞的IO操作），然后继续执行其他任务，直到操作结果已经准备好了，再继续回过来继续进行后续操作。在这个模型中，可以有许多并发连接在单个线程上多路复用，我们可以看一段使用NIO的Java代码：public static void main(String[] args) throws IOException { Selector selector = Selector.open(); ServerSocketChannel serverSocketChannel = ServerSocketChannel.open serverSocketChannel.bind(new InetSocketAddress(3000)); // 将Channel设置为非阻塞模式 serverSocketChannel.configureBlocking(false); // 将Channel注册到Selector上，监听连接事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) { selector.select(); // 获取所有已经就绪的SelectionKey（所有提醒事件） Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator(); while (it.hasNext()) { SelectionKey key = it.next(); if (key.isAcceptable()) { // 有新的连接 newConnection(selector, key); } else if (key.isReadable()) { // Socket有数据可读 echo(key); } else if (key.isWritable()) { // Socket再次可写 continueEcho(selector, key); } // 处理完毕后，需要从就绪集合中移除当前key，否则下次循环还会进来 it.remove(); } }}Java从很早之前（在Java1.4中引入）就有了NIO（non-blocking IO）的包，但我们极少直接与其打交道。从上面代码我们可以看出来，和阻塞IO相比，直接使用NIO进行编程复杂程度会大大增加，并且最主要的是，和Java的很多标准库一样，java.nio只关注它的作用，不提供更高级别的特定于协议（比如HTTP）的帮助类，也没有规定线程模型（对于非阻塞IO编程来说，一个合适的线程模型更能充分发挥它的优势），直接基于java.nio编程无异于刀耕火种，并且维护成本高。因此，像Netty，Apache MINA这样的网络编程库的出现，就是为了解决Java标准NIO库的这些短板（它们都是基于Java NIO的，并且进行了进一步的封装（例如为多种协议提供了专门的编解码器，简化了协议处理的复杂性）和优化（例如通过池化，零拷贝等技术进一步进行资源和性能优化），简化了网络编程的复杂性）。三、Event Loop我们本次主要讨论Java异步编程的发展，所以不对详细的库（如Netty，Vert.x等）做过多介绍，Event Loop作为各种Java异步编程库中最流行的一种机制，我们有必要了解一下它是如何提高资源利用率，而在Event Loop中我们又是怎样进行编程的。关于Event Loop我们可以看这张图，Event Loop其实很简单，一个单独的Event-Loop线程一直循环，各种不应该阻塞线程的事件被触发时（例如数据准备就绪的I/O事件，计时器被触发的事件等）再进行处理（处理这个事件的线程可以是当前的Event Loop的线程，也可以是另外的线程，不同的框架有不同的选择，例如Netty就提供了多种线程模型供选择，而Vert.x则选择直接使用Event Loop线程作为处理线程）。 了解前端编程的朋友应该知道，Event Loop是JavaScript中的一个重要概念，这与两方面原因有关（当然这两方面原因可能也有因果关系）。首先，因为JavaScript是单线程的（这里要注意，浏览器本身的运行是多线程的，不要将两者混淆），同一时刻只会有一段JS代码在运行；其次，在GUI编程中，单线程事件驱动的机制几乎是一个通用法则，因为如果想用多线程进行更新，用锁等机制保证线程安全的话，最终总是特别容易陷入死锁（总是会有多个调用试图访问一些绘图相关的共享数据），因此使用Event Dispatch线程，或者被叫做UI线程来进行界面相关操作。 得益于巧妙的线程机制，服务端领域的Node.js也总是可以用少量资源应付大流量访问。「当事件被触发时，再进行处理」，意味着在异步编程中代码不总是从上到下依次执行的，而是「穿插」执行的，使用Event Loop时，通常有两种编程风格：3.1 回调当提到回调时，很多人会马上想到「回调地狱」，（甚至于有一个网站就叫做Callback Hell），它也是很多JavaScript程序员痛苦的原因，举个简单的例子，这是基于Vert.x框架编写的一段代码，用于从三个部署在localhost的传感器（Sensor）服务中获取数据，汇总数据后请求一个快照（snapshot）服务将这些数据保存下来，保存完成后对客户端请求进行响应：List&lt;JsonObject&gt; responses = new ArrayList&lt;&gt;();AtomicInteger counter = new AtomicInteger(0);for (int i = 0; i &lt; 3; i++) { webClient .get(3000 + i, \"localhost\", \"/\") .expect(ResponsePredicate.SC_SUCCESS) .as(BodyCodec.jsonObject()) .send(ar -&gt; { // 并行对传感器服务发起请求 if (ar.succeeded()) { responses.add(ar.result().body()); } else { logger.error(\"Sensor down?\", ar.cause()); } // 三个请求都已完成（注意，这段代码位于上面send函数的回调中） if (counter.incrementAndGet() == 3) { JsonObject data = new JsonObject() .put(\"data\", new JsonArray(responses)); webClient .post(4000, \"localhost\", \"/\") .expect(ResponsePredicate.SC_SUCCESS) .sendJsonObject(data, ar1 -&gt; { // 发送数据给快照服务 if (ar1.succeeded()) { // 响应当前请求 request.response() .putHeader(\"Content-Type\", \"application/json\") .end(data.encode()); } else { logger.error(\"Snapshot down?\", ar1.cause()); request.response().setStatusCode(500).end(); } }); } });}虽然嵌套层级并不是很深，但是不是感受到「地狱」的味道了？事实上，借助一些编程时的技巧，很容易让嵌套看起来没那么可怕，比如上面的那段代码中，我们可以将三个请求都已经完成后进行操作的后续代码提取出来作为一个单独的函数，按照这种思路，往往可以有效避免看到一个被嵌套成「金字塔」的函数，即：List&lt;JsonObject&gt; responses = new ArrayList&lt;&gt;();AtomicInteger counter = new AtomicInteger(0);for (int i = 0; i &lt; 3; i++) { webClient .get(3000 + i, \"localhost\", \"/\") .expect(ResponsePredicate.SC_SUCCESS) .as(BodyCodec.jsonObject()) .send(ar -&gt; { // 并行发送给传感器服务的请求 if (ar.succeeded()) { responses.add(ar.result().body()); } else { logger.error(\"Sensor down?\", ar.cause()); } // 三个请求都已完成 if (counter.incrementAndGet() == 3) { JsonObject data = new JsonObject() .put(\"data\", new JsonArray(responses)); // 发送数据给快照服务 sendToSnapshot(request, data); } });}过多使用回调确实让代码更不易读了，但是最大的问题还不在这里，最大的问题在于原本的功能实现代码和异步协调代码结合得太深了，很难一眼从代码中看出来这三个请求是并行发出的，并且所有请求的结果将会被组装然后返回。3.2 Future 在介绍Event Loop时提到的Future与后文会提到的Java标准库中的Future有区别，注意不要混淆。看过回调的代码后，我们再来看同样是Vert.x中一种叫做Future的抽象，和其名称一样，「未来」，用于保存一个操作的结果，而这个结果在当下没有意义，当执行完成后，会通过其定义的handler进行通知，借助这种抽象，我们就可以很容易将异步操作包装成看得见摸得着的对象：private void handleRequest(HttpServerRequest request) { // 并行发起并等待三个对传感器服务的请求 CompositeFuture.all( fetchTemperature(3000), fetchTemperature(3001), fetchTemperature(3002)) .flatMap(this::sendToSnapshot) .onSuccess(data -&gt; request.response() .putHeader(\"Content-Type\", \"application/json\") .end(data.encode())) .onFailure(err -&gt; { logger.error(\"Something went wrong\", err); request.response().setStatusCode(500).end(); });}private Future&lt;JsonObject&gt; fetchTemperature(int port) { // 请求传感器服务，并将结果作为一个Future返回 return webClient .get(port, \"localhost\", \"/\") .expect(ResponsePredicate.SC_SUCCESS) .as(BodyCodec.jsonObject()) .send().map(HttpResponse::body);}private Future&lt;JsonObject&gt; sendToSnapshot(CompositeFuture temp List&lt;JsonObject&gt; tempData = temps.list(); JsonObject data = new JsonObject() .put(\"data\", new JsonArray() .add(tempData.get(0)) .add(tempData.get(1)) .add(tempData.get(2))); return webClient .post(4000, \"localhost\", \"/\") .expect(ResponsePredicate.SC_SUCCESS) .sendJson(data) .map(response -&gt; data);}四、其他异步编程内容4.1 CompletableFuture与ForkJoinPool日常使用多线程编程时，我们可以注意到当进行ExecutorService.submit()后我们会得到一个Future对象，其允许我们获取异步计算的结果，Future是在Java 5引入的（包含在java.util.concurrent内，java.util.concurrent也是这个版本引入的）。 有趣的是，上文中提到了Java1.4引入了NIO，Java从1.5版本开始对外推广的版本号中就直接去掉了主版本号前面的部分，直接称为Java 5，Java 6等，而在对外推广的版本中也从来没出现过Java 3，Java 4这两个版本。 Java内部发行版本 发布时间 Java对外推广版本号 JDK 1.0 1996年1月 Java 1.0 JDK 1.1 1997年2月 Java 1.1 JDK 1.2 1998年12月 Java 2 JDK 1.3 2000年5月 Java 2 JDK 1.4 2002年2月 Java 2 JDK 1.5 2004年9月 J2SE 5.0 JDK 1.6 2006年12月 Java SE 6 JDK 1.7 2011年7月 Java SE 7 JDK 1.8 2014年3月 Java SE 8 这是一段Future的使用示例：public static void main(String[] args) throws InterruptedException, ExecutionException { ExecutorService executorService = Executors.newFixedThreadPool(1); // 使用 Future 进行异步相加操作 Future&lt;Integer&gt; futureResult = executorService.submit(() -&gt; { // 模拟耗时操作 Thread.sleep(1000); return 1 + 2; }); System.out.println(\"Doing other work...\"); // 阻塞等待任务完成 Integer result = futureResult.get(); System.out.println(\"Result: \" + result); executorService.shutdown();}而Java 8中引入了CompletableFuture，除了原有的Future接口外，其还实现了CompletionStage接口，使得其API更加丰富和灵活，支持链式调用，组合操作，并且有回调机制，异常处理机制等，以下是一个CompletableFuture的使用示例：public static void main(String[] args) { // 使用 CompletableFuture 进行异步相加操作 CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture.supplyAsync(() -&gt; { // 模拟耗时操作 try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } return 1 + 2; }); System.out.println(\"Doing other work...\"); // 链式调用，通过 thenApply 处理异步操作的结果 CompletableFuture&lt;String&gt; resultFuture = completableFuture.thenApply(result -&gt; { System.out.println(\"Result received: \" + result); return \"Processed Result: \" + result; }); // 异步操作完成后的回调 resultFuture.thenAccept(processedResult -&gt; { System.out.println(\"Final Result: \" + processedResult); }); // 防止主线程提前退出 try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); }}上面的代码肯定会让你感到奇怪，CompletableFuture的创建并没有指定线程池，它是如何实现异步的呢，首先要说明的是，CompletableFuture是可以自定义线程池的：ExecutorService customExecutor = Executors.newFixedThreadPool(10);CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; {   // 执行任务的代码}, customExecutor);但是这不是重点，重点是若没有指定的线程池，其会默认使用ForkJoinPool线程池来执行异步任务。ForkJoinPoolForkJoinPool是一种基于工作窃取（work-stealing）算法的线程池实现，在Java 7中被引入，通常用于处理可以分解为较小任务的问题，这张图可以简单说明工作窃取算法的工作原理：每个工作线程都有自己的双端队列用于存储任务。当一个线程完成自己队列中的任务后，它可以从其他线程的队列末尾“窃取”任务执行，从而保持线程的工作状态。这样的设计有助于充分利用 CPU 资源，提高并行计算效率。 CompletableFuture默认使用ForkJoinPool.commonPool()，它是一个共享的全局线程池，如果被其他任务占用，可能会影响性能，因此如果有必要，需要创建自己的ForkJoinPool实例。4.2 Reactive ExtensionsReactive extensions（这里讨论的是Java实现，后面直接表述为RxJava）是一套基于观察者模式的扩展库，最开始在.NET平台上流行起来，后面越来越多的语言和技术栈都开始使用（不仅在服务端，并且还有各种客户端界面库也使用它，比如WPF，Android等），具体可以参考ReactiveX。在这里不对其做深入介绍，但举个简单的例子你就能体会到其强大之处，假如现在你从数据库中获取一些用户信息，然后将这些信息按照一定规则进行处理：传统同步代码：import java.util.List;public class UserService { public List&lt;User&gt; getUsers() { // 同步获取用户列表的数据库操作 List&lt;User&gt; users = DatabaseService.getUsersFromDatabase(); // 处理用户数据 List&lt;UserInfo&gt; userInfos = processUserList(users); // 返回处理后的结果 return userInfos; } private List&lt;UserInfo&gt; processUserList(List&lt;User&gt; users) { // 处理用户信息的业务逻辑 // ... return processedUserInfos; }}使用RxJava的异步代码：import io.reactivex.Observable;import io.reactivex.schedulers.Schedulers;public class UserService { public Observable&lt;UserInfo&gt; getUsersAsync() { // 异步获取用户列表的数据库操作\t return Observable.fromCallable(() -&gt; DatabaseService.getUsersFromDatabase()) .flatMapIterable(users -&gt; users) .subscribeOn(Schedulers.io()) .observeOn(Schedulers.computation()) .map(this::processUser); } private UserInfo processUser(User user) { // 处理用户信息的业务逻辑 // ... return processedUserInfo; }}在这段代码中，除了创建Observable（可观察对象），还有后续的链式处理函数外，最亮眼的莫过于subscribeOn(Schedulers.io())以及observeOn(Schedulers.computation())： subscribeOn(Schedulers.io()) 将数据获取的流程切换到I/O线程上进行。 observeOn(Schedulers.computation())将后续的处理过程又放到计算线程上执行。使用RxJava时，并不直接操作Thread或者ExecutorService，而是操作像上面一样名为调度器（Schedulers）的抽象API，使用调度器，可以非常流畅迅速地在不同类型的线程上进行切换，大大提高了异步编程的效率和容错率。并且其不局限于特定的线程模型，在上文中提到的Vert.x框架中也有对应的RxJava库。Reactive除了是一种异步方案之外，还是一种编程思想，在不需要进行异步编程的时候也可以使用，有兴趣的可以通过上面的链接进一步了解。4.3 背压（Back-pressure）背压是一种消费者向生产者发出信号的机制，用于提醒生产者正在用比自己处理速度更快的速度发送数据（也有相当多的文章说背压应该是一种问题而不是机制，个人比较赞同的说法是「在编程世界中，背压是一种Web应用中的常见问题，而久而久之，人们也用这个术语来表达处理这类问题的机制」），有几张图片可以很形象地描述背压：从第二个图片中可以看出，当没有正确处理好背压的时候，慢消费者就会被生产者压垮。那为什么要在异步编程中单独提起背压呢，因为在使用阻塞模型时，生产者天然被阻塞（设想Spring Boot线程池中的所有线程都处于正在处理请求的状态），只能等待消费者完成处理（即使有更多请求，当超过一定数量时，也会被Spring Boot所拒绝，例如在使用Tomcat时，对应配置项为server.tomcat.accept-count，代表启用的线程数达到最大时，接收排队的请求个数）。因此在使用阻塞模型时，背压并不是什么显著的问题。而根据前文的描述，使用非阻塞IO时，为了提高吞吐量，必然会一股脑接收大量生产者的所有消息，等到有空的时候再进行处理，这种操作非常容易引发背压，而缓存起来的消息最终会造成消费者自身的OOM。为了应对这种情况，各种异步框架都有自己的背压机制，大体上分为三类： 控制（Control），以各种方式协调生产者，从源头减少流量（类似TCP协议中使用滑动窗口进行流量控制； 缓冲（Buffer），将多余的消息暂时存储起来，之后再处理，但是当生产者速率持续高于消费者时，缓冲始终不是长久之计，例如会像上面说的一样造成OOM，当然，利用Kafka等外部消息队列，能创建出更大的进程之外的缓冲区 丢弃（Drop），在权衡利弊，允许丢弃部分消息的情况下，这往往是最快速有效的办法 最近我在实际工作中也遇到了背压问题：在持续压测设备消息上报时，我的服务需要请求设备服务获取设备详情，而此时设备服务也处于被压测的情况下，偶尔会处于短暂不可用状态，由于Vert.x官方的WebClient暂时没有直接帮忙做处理，因此发向设备服务的请求会在一瞬间大量积压，很快就造成OOM，服务重启。因此在很多情况下，由于异步框架的默认实现不能覆盖所有情况等原因，背压依然是需要结合实际情况去手动处理的。五、Java虚拟线程Java 21已经于2023 年9月19日正式发布，作为目前最新的LTS版本，其可能也会是近些年来最重要，影响最大的Java版本，因为其带来的虚拟线程这一特性，为Java程序员打开了新世界的大门。 作为一个使用过其他带有语言级别异步编程模型的程序员，最开始接触Java时，对Java的各种库为了实现异步编程从过去到现在所做的那么多努力，发明的那么多花式编程方式感到诧异，「这在C#里面，就是个aysnc加await就能解决的，这都是些啥啊，搞那么麻烦」。不过好在终于，属于Java自己的JVM级别的异步编程支持来了。5.1 什么是Java虚拟线程要想知道什么是Java虚拟线程（在很多其他语言中也被称为协程，用户态线程等），我们首先需要分清平台线程和虚拟线程之间的区别：平台线程平台线程可以看作是JVM对操作系统线程的一层薄的封装，可以直接理解为系统线程，被操作系统内核管理。一个系统能同时调度的线程是有限的，并且线程切换也会消耗CPU资源，所以通常被认为是一种重量级资源。虚拟线程而虚拟线程则不同，虽然其仍在操作系统线程上运行，但其不由操作系统管理，而是由JVM管理和调度，是一种用户态线程，不需要在内核态和用户态之间来回切换，非常轻量级。当代码在虚拟线程中执行阻塞I/O的操作时，JVM其将其挂起，直到可以继续执行为止。简单来说就是在一个虚拟线程阻塞时自动切到另一个虚拟线程。虚拟线程的实现方式与虚拟内存类似，JVM将大量虚拟线程映射到少量系统线程，并且由JVM自行调度进行切换。而Java虚拟线程的核心就在于这个调度的过程，这个过程主要由Continuation实现，这个词经常在协程理论中出现，它就是协程的本质，为程序提供了暂停/继续 （yield/resume）的能力。5.2 如何使用虚拟线程关于这部分的代码，官网和网上已经有不少示例，这里直接把官网的示例贴上来，这里最想表达的是，Java作为一个生态强大的语言，它的虚拟线程考虑到了对很多现有代码的兼容性和改造成本，因此尽可能和以前的线程创建方式接近，我想这也是为什么Java使用了现在的实现而不是其他语言中的协程实现：使用Thread.ofVirtual()创建一个虚拟线程并等待：Thread thread = Thread.ofVirtual().start(() -&gt; System.out.println(\"Hello\"));thread.join();指定ExecutorService类型（不难想象很多代码使用这种方式就能很快改造完成）：try (ExecutorService myExecutor = Executors.newVirtualThreadPerTaskExecutor()) { Future&lt;?&gt; future = myExecutor.submit(() -&gt; System.out.println(\"Running thread\")); future.get(); System.out.println(\"Task completed\"); // ...5.3 注意事项不要池化虚拟线程上面也提到，虚拟线程是很轻量的用户态线程，创建和切换过程中并不会产生那么大的开销，池化反而会导致性能受限。虽然官方文档也这么建议，但情况不能一概而论。比如上面提到过的背压问题，这个问题在虚拟线程中也是容易出现的，这时候池化反而是一个可选的方案。避免长期且频繁的synchronized块当前虚拟线程的实现决定了其在遇到synchronized块时无法进行调度，会阻塞宝贵的系统线程。因此应该在使用协程时应避免出现时间较长并且比较频繁的synchronized块，若是改造原有代码，也需要留意以前的代码实现是否存在这种情况，而官方也提供了一些方法用于探测是否存在这样的代码。虚拟线程性能就一定更好吗事实上，作为一种「用户态线程」，我们可以说虚拟线程的实现比之前的提到的EventLoop更官方，相对来说更底层（JVM自动调度），但是不能一定就认为使用虚拟线程就一定更好或者更快。相反的，在以往其他语言的开发经验中，因为创建协程的代价过于低廉，很多程序员实际上不清楚什么时候该使用它，或者使用它会产生什么后果（甚至于混淆协程与线程的概念，使用协程进行CPU密集形的任务），随意滥用虚拟线程或者协程导致的是调试难度增加以及诡异的问题增多。这不是说虚拟线程就不强大，使用方便本身就是它的一大优势，不然的话也不会有很多人认为这是对以前那些异步编程库的一次大冲击了（我也这么认为，当虚拟线程出现后，之前围绕着异步I/O开发的各种库和编程方式都显得没那么有必要）。5.4 展望目前来看，对于原本就使用了过去的那些异步编程框架的程序来说，改造成虚拟线程的提升不会那么大，并且由于编程风格的变化，改造难度也会更大。相反以前使用同步模型的服务改造阻力反而会更小。当然，仍然有不少框架需要重写或者适配，才能发挥出虚拟线程的作用，这里可能有疑惑，明明JDK已经尽量避免和原来使用线程的模式产生差异了，原来我开一个普通线程去调他们的库，现在开一个虚拟线程去调他们的库就好了，使用方改不就好了，为什么还需要重写？因为过去很多库为了提高吞吐，都会采用Event Loop结合限量线程池的方式自己做一些处理。而现在要调整和优化的代码，也正好是这些代码。因此才说原本就采用同步模型的库反而改动更小。关于这方面的展望在知乎上的问题「如果java虚拟线程稳定了，是不是有一大批框架和工具要重写？」当中，也有不少讨论和见解：![[java-async-11.png]]  Project Loom 是 OpenJDK 的一个子项目，致力于为 Java 引入轻量级线程（称为 Virtual Threads 或者 Loom Threads）。Loom 的目标是在不改变现有 Java 程序的前提下，为 Java 增加纤程的能力。Loom 的设计目标是实现一个高效且易用的协程和轻量级线程模型，以解决 Java 并发编程的挑战。  Java的虚拟线程就是Loom项目孵化的。![[java-async-12.png]]![[java-async-13.png]]六、实战一次实践，原有的项目侧设备数据流转使用单消费者 + 单生产者进行数据转发，导致吞吐量始终达不到接近IoT侧的地步（但是由于已满足性能指标，就没有继续优化）。在这里基于原有项目建立两个demo分支，直接使用JDK 21，并使用上面提到的多线程与虚拟线程技术，对比资源消耗及性能提升情况。 尚未完成参考 [异步编程 - ASP.NET 上的 Async/Await 简介 Microsoft Learn](https://learn.microsoft.com/zh-cn/archive/msdn-magazine/2014/october/async-programming-introduction-to-async-await-on-asp-net) [并发模型与事件循环 - JavaScript MDN (mozilla.org)](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Event_loop) 什么是 Event Loop？ - 阮一峰的网络日志 (ruanyifeng.com) Virtual Threads (oracle.com) [异步编程场景 - C# Microsoft Learn](https://learn.microsoft.com/zh-cn/dotnet/csharp/asynchronous-programming/async-scenarios) Java虚拟线程的核心: Continuation - 知乎 (zhihu.com) 虚拟线程调度执行流程及原理 - 掘金 (juejin.cn)" }, { "title": "Windows使用备忘", "url": "/posts/Windows-1/", "categories": "Windows", "tags": "技术备忘, 日常工具, Windows", "date": "2023-11-03 00:00:00 +0800", "snippet": "Win10自带输入法设置自定义用户词组在右下角输入法图标上点击右键，打开设置：选中词库和自学习：找到并点击添加或编辑自定义短语为了方便输入中文直角引号「」和『』，我们如图示添加短语：添加完成后，我们输入”yh”，就能很方便打出上面自定义的短语了批量替换文件名# 获取当前目录下所有文件$files = Get-ChildItem -Fileforeach ($file in $files) {...", "content": "Win10自带输入法设置自定义用户词组在右下角输入法图标上点击右键，打开设置：选中词库和自学习：找到并点击添加或编辑自定义短语为了方便输入中文直角引号「」和『』，我们如图示添加短语：添加完成后，我们输入”yh”，就能很方便打出上面自定义的短语了批量替换文件名# 获取当前目录下所有文件$files = Get-ChildItem -Fileforeach ($file in $files) { # 检查文件名是否包含指定字符串 if ($file.Name -match \"m瑰d故s\") { # 替换文件名中的字符串 $newFileName = $file.Name -replace \"m瑰d故s\", \"玫瑰的故事\" # 重命名文件 Rename-Item -Path $file.FullName -NewName $newFileName }}如何有效删除hiberfil.sys文件需要禁用休眠模式，使用命令：powercfg.exe /hibernate off如何有效删除pagefile.sys文件 右击「此电脑」，选择「属性」，依次点击「高级系统设置」-「高级」，找到「性能」，依次点击「设置」-「高级」，再点击「虚拟内存」区域点击「更改」。 更改方式：先选中C盘，然后选「无分页文件」，再点「设置」按钮；之后选中要生成该文件的盘符，在下面点选「自定义大小」并输入合适的数值，此数值通常为物理内存的1.5倍，再单击「设置」，最后单击「确定」就可以了。 重新启动电脑，该文件就会存放到其他分区上了。" }, { "title": "VSCode使用备忘", "url": "/posts/VSCode-1/", "categories": "VSCode", "tags": "技术备忘, 日常工具, VSCode", "date": "2023-11-03 00:00:00 +0800", "snippet": "1. 设置Java项目启动参数在 Visual Studio Code (VS Code) 中设置 Java 项目的启动路径可以通过配置 launch.json 文件来实现。以下是详细步骤： 安装必要的扩展：确保已经安装了 VS Code 的 Java 相关扩展包，如 Java Extension Pack，其中包含了调试和运行 Java 所需的插件。 创建 laun...", "content": "1. 设置Java项目启动参数在 Visual Studio Code (VS Code) 中设置 Java 项目的启动路径可以通过配置 launch.json 文件来实现。以下是详细步骤： 安装必要的扩展：确保已经安装了 VS Code 的 Java 相关扩展包，如 Java Extension Pack，其中包含了调试和运行 Java 所需的插件。 创建 launch.json 文件： 打开 VS Code，进入你的 Java 项目。 按下 Ctrl + Shift + P（Windows）或 Cmd + Shift + P（Mac），输入 Debug: Open launch.json，然后选择该选项。 如果没有 launch.json，VS Code 会提示你选择环境。选择 Java，然后它会自动生成一个 launch.json 文件。 配置启动路径： 在生成的 launch.json 文件中，找到或添加一个配置项 \"cwd\"，用于设置程序运行的当前工作目录。 将 \"${workspaceFolder}/your/start/path\" 替换为你想要的启动路径。 保存并运行： 保存 launch.json 文件。 现在，当你启动调试或运行 Java 程序时，VS Code 会按照指定的启动路径执行。 这样，你就可以通过配置 launch.json 文件，灵活地设置 Java 项目的启动路径。需要注意的是，cwd 是相对路径，也可以使用绝对路径。配置示例：{ \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"java\", \"name\": \"Debug (Launch) - Current File\", \"request\": \"launch\", \"mainClass\": \"${file}\", \"cwd\": \"${workspaceFolder}/your/start/path\", // 设置你的启动路径 \"args\": [] // 可选，传递程序启动参数 } ]}2. 切换工作区打开多个 vscode 窗口的时候，我们可以通过 command + ` 来切换不同的工作区窗口。这个快捷键在大部分软件中效果都是如此。3. 切换文件在 Windows 和 Linux 系统中，使用 Ctrl + Tab 来切换到下一个打开的页面，使用 Ctrl + Shift + Tab 来切换到上一个页面。4. 删除行Shift + Ctrl + K (Windows/Linux)" }, { "title": "Linux使用备忘", "url": "/posts/Linux-1/", "categories": "Linux", "tags": "技术备忘, 日常工具, Linux", "date": "2023-11-03 00:00:00 +0800", "snippet": "使用echo命令写入文件在容器化部署的条件下，为了减小容器体积，经常会使用非常精简的操作系统，不含有Vim编辑器，此时可以借助echo命令将文本内容直接输出到文件，例如：使用echo命令创建一个cert.csr文件并填充其内容（其中&gt;用于覆盖原有文件，&gt;&gt;能够追加文件内容）：echo \"-----BEGIN CERTIFICATE REQUEST-----\" &gt; ce...", "content": "使用echo命令写入文件在容器化部署的条件下，为了减小容器体积，经常会使用非常精简的操作系统，不含有Vim编辑器，此时可以借助echo命令将文本内容直接输出到文件，例如：使用echo命令创建一个cert.csr文件并填充其内容（其中&gt;用于覆盖原有文件，&gt;&gt;能够追加文件内容）：echo \"-----BEGIN CERTIFICATE REQUEST-----\" &gt; cert.csrecho \"MIIC0jCCAboCAQAwWzELMAkGA1UEBhMCQ04xEjAQBgNVBAgMCUd1YW5nZG9uZzER\" &gt;&gt; cert.csrecho \"MA8GA1UEBwwIU2hlbnpoZW4xDDAKBgNVBAoMA0RBUzEXMBUGA1UEAwwOMTIwLjc4\" &gt;&gt; cert.csrecho \"LjE1Ny4xNzMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDQ5oTd0apH\" &gt;&gt; cert.csrecho \"3m+KklUOSrsIM82kmHosrFqQc19SV6L1tJVXoVdE1OgJEyKkbauWaAD8bPB8F9cu\" &gt;&gt; cert.csrecho \"O4v/xEo3adBiOTny/zfhuhsK4x5bYh6g2OpMEEher83wcVV4WIl79vUNNCjNEE/m\" &gt;&gt; cert.csrecho \"O3KIageV4NmRnu0xnWbE2BnPSjdEDCX+V43L3eboCQ492TurssZ5Aqi55MXSGvq9\" &gt;&gt; cert.csrecho \"L7rvjka8HOodEefdZsPGpqKxVeWqi0JBjZRh4usuEzmu9GekHGKg4mmvtUF4FdsN\" &gt;&gt; cert.csrecho \"cq3kw6pH28NudBnWbRgCnUH6WpVqyxy4XuB6eLs34C0MrDvwZbDPf8myrLlGRsIf\" &gt;&gt; cert.csrecho \"JET3a7gTcnfzAgMBAAGgMjAwBgkqhkiG9w0BCQ4xIzAhMB8GA1UdEQQYMBaHBHhO\" &gt;&gt; cert.csrecho \"na2CDjEyMC43OC4xNTcuMTczMA0GCSqGSIb3DQEBCwUAA4IBAQCxxbfAO/lle5K/\" &gt;&gt; cert.csrecho \"94JZFcQxf8p1m3o+dN7t0j7gHozm+xXxBMttIDIxWmC/waywzwUDf8U32BSDDKUE\" &gt;&gt; cert.csrecho \"DwG6g0EGVyACo4oMWZxeWNteyJ9n0dyNIzpem+z55vdpaWJAg4FklhPqx0/mZlBB\" &gt;&gt; cert.csrecho \"RuVBETP5nt3vnzTkvVFJqGvO3NKGR1Ud6t7NZVMJqvAxpl34BzBGwL/2VL8FJ1+S\" &gt;&gt; cert.csrecho \"T+vNh4fvaEogrF9VgYFodmsnQi0oXd5057OfZkmA01QLffwx/yJMI5Y9bhoqHcii\" &gt;&gt; cert.csrecho \"u7fj3wl2gF5PHZmMgK/8r5SVMaK9zP3iaM0ejIcEQ7DT8AY7zbn1a54JCDtQ2UCX\" &gt;&gt; cert.csrecho \"JpTukniP\" &gt;&gt; cert.csrecho \"-----END CERTIFICATE REQUEST-----\" &gt;&gt; cert.csr" }, { "title": "Docker&K8s相关使用备忘", "url": "/posts/K8s-1/", "categories": "K8s", "tags": "技术备忘, 容器技术, Docker, K8s", "date": "2023-11-03 00:00:00 +0800", "snippet": "将Rancher与K8s集群绑定Rancher界面 - 全局 - 添加集群 - 导入，点击创建后在K8s宿主机执行生成的第三条命令快速新增负载均衡YAML模板apiVersion: v1 kind: Service metadata:   name: redis-lb   namespace: default spec:   externalTrafficPolicy: Clus...", "content": "将Rancher与K8s集群绑定Rancher界面 - 全局 - 添加集群 - 导入，点击创建后在K8s宿主机执行生成的第三条命令快速新增负载均衡YAML模板apiVersion: v1 kind: Service metadata:   name: redis-lb   namespace: default spec:   externalTrafficPolicy: Cluster   ports:   - name: 6379tcp02     port: 6379     protocol: TCP     targetPort: 6379   selector:     app: redis   sessionAffinity: None   type: LoadBalancer快速新增工作负载YAML模板apiVersion: apps/v1 kind: Deployment metadata: name: openobserve spec: selector: matchLabels: app: openobserve strategy: type: Recreate template: metadata: labels: app: openobserve spec: containers: - image: openobserve/openobserve:v0.10.7 imagePullPolicy: IfNotPresent name: openobserve ports: - containerPort: 5080 name: 5080tcp2 protocol: TCP env: - name: ZO_ROOT_USER_EMAIL value: root@example.com - name: ZO_ROOT_USER_PASSWORD value: Complexpass#123 - name: ZO_DATA_DIR value: /data volumeMounts: - mountPath: /data name: data nodeSelector: kubernetes.io/hostname: k3sserver volumes: - hostPath: path: /opt/data/appdata/openobserve/data type: \"\" name: data dnsPolicy: ClusterFirst restartPolicy: Always kubectl命令记录获取Pod的内存占用情况，其中Pod名称和命名空间名称都不是必传的：kubectl top pod &lt;Pod名称&gt; -n &lt;命名空间名称&gt;从Pod中复制文件：kubectl cp &lt;pod名称&gt;:&lt;容器内路径&gt; &lt;目标本地路径&gt;从本地拷贝文件至Pod：kubectl cp -n $ns data/cert.csr $datahub_pod_name:/opt/emqx/etc/certsdocker命令记录压缩镜像：docker save your_image_name:tag | gzip &gt; image.tar.gz加载镜像：gzip -dc image.tar.gz | docker load让容器保持运行command: [\"/bin/sh\"]args: [\"-c\", \"tail -f /dev/null\"]" }, { "title": "Vector使用备忘", "url": "/posts/DevOps-1/", "categories": "DevOps", "tags": "技术备忘, DevOps, Vector", "date": "2023-11-03 00:00:00 +0800", "snippet": " Vector是高性能的可观测性数据管道（Observability Pipelines，关于什么是可观测性数据管道可以查看官方文档），用来收集，转换和路由日志和指标数据。一、为什么使用Vector高性能，低资源消耗，有一些相关的测评文章： [Who is the winner — Comparing Vector, Fluent ...", "content": " Vector是高性能的可观测性数据管道（Observability Pipelines，关于什么是可观测性数据管道可以查看官方文档），用来收集，转换和路由日志和指标数据。一、为什么使用Vector高性能，低资源消耗，有一些相关的测评文章： [Who is the winner — Comparing Vector, Fluent Bit, Fluentd performance by Ajay Gupta IBM Cloud Medium](https://medium.com/ibm-cloud/log-collectors-performance-benchmarking-8c5218a08fea) 构建高性能可观测性数据流水线：使用Vector实现实时日志分析 - 知乎 (zhihu.com)官方文档的Tuning（调优）页面这样说： Vector is written in Rust and therefore doesn’t include a runtime or a virtual machine. There are no special service-level steps you need to undertake to improve performance as Vector takes full advantage of all system resources by default and without any adjustments.翻译过来就是： Vector 是用 Rust 编写的，因此不包含运行时或虚拟机。 您无需执行任何特殊的服务级别步骤即可提高性能，因为 Vector 默认情况下会充分利用所有系统资源，且无需任何调整。 除了性能之外，Vector还具有一些高级特性，比如：自适应并发请求（[Adaptive request concurrency (ARC) Vector documentation](https://vector.dev/docs/about/under-the-hood/networking/arc/)。请求下游服务时，根据响应速率自适应调节自身的并发速率）。 二、部署参考文档：Install Vector on Docker | Vector documentation2.1 拉取镜像 这里记录的是实际操作时使用的镜像信息，Vector的镜像每天都会自动构建nightly镜像并且上传到Docker Hub，这里我们使用已经Release的版本。docker pull timberio/vector:0.39.0-alpine2.2 部署到k8s最终部署时使用的完整YAML内容是：apiVersion: apps/v1kind: DaemonSetmetadata: labels: app: vector name: vector namespace: opsspec: selector: matchLabels: app: vector template: metadata: labels: app: vector spec: containers: - env: - name: VECTOR_SELF_NODE_NAME valueFrom: fieldRef: apiVersion: v1 fieldPath: spec.nodeName image: timberio/vector:0.39.0-alpine imagePullPolicy: IfNotPresent name: vector ports: - containerPort: 8686 name: 8686tcp02 protocol: TCP volumeMounts: - mountPath: /var/log/pods name: podlogdir - mountPath: /opt/docker-data/docker/containers name: dockerlogdir - mountPath: /opt/data/appdata/vector/data name: vectordata - mountPath: /root/.kube/config name: config subPath: config - mountPath: /etc/vector/vector.yaml name: vector subPath: vector.yaml imagePullSecrets: - name: redistry-key restartPolicy: Always volumes: - hostPath: path: /var/log/pods type: \"\" name: podlogdir - hostPath: path: /opt/docker-data/docker/containers type: \"\" name: dockerlogdir - hostPath: path: /opt/data/appdata/vector/data type: \"\" name: vectordata - configMap: defaultMode: 292 items: - key: config path: config name: kubernetes optional: false name: config - configMap: defaultMode: 292 items: - key: vector.yaml path: vector.yaml name: vector optional: false name: vector--- apiVersion: v1 kind: Service metadata: name: vector namespace: ops spec: ports: - name: 8686tcp02 port: 8686 protocol: TCP targetPort: 8686 selector: app: vector sessionAffinity: None type: ClusterIP --- apiVersion: v1 kind: Service metadata: name: vector-lb namespace: ops spec: externalTrafficPolicy: Cluster ports: - name: 8686tcp02 port: 8686 protocol: TCP targetPort: 8686 selector: app: vector sessionAffinity: None type: LoadBalancer三、配置Vector有三个重要概念，分别是Sources（数据从哪来），Transforms（对日志进行何种转换），以及Sinks（将数据写到哪里去）。对于这三种概念，都有非常丰富的配置可供选择。Vector的配置文件默认放置于/etc/vector/vector.yaml，我们先进行一些初始化配置（配置中还能使用环境变量，并且支持多配置文件）：# 默认文件存储目录，Vector需要一些磁盘空间来持久化当前运行状态# 例如用来当作磁盘缓冲区，或者保存checkpointsdata_dir: \"/opt/data/appdata/vector/data\"# Vector HTTP API配置（默认不启用）api: enabled: true address: \"0.0.0.0:8686\"3.1 Sources 首先配置日志的Sources，也就是日志来源，当前我们想采集Kubernetes logs，参考文档：[Kubernetes logs Vector documentation](https://vector.dev/docs/reference/configuration/sources/kubernetes_logs/)。 sources: k8s: type: kubernetes_logs kube_config_file: /root/.kube/config3.2 Transforms日志的转换是关键步骤，如果直接完整记录k8s中采集到的日志，那么结构就像这样：内容多固然是好事，可惜有很多内容是我们不需要的，并且其结构不太符合我们的预期，因此我们希望能够借助某种能力将其进行转换，这时候就要用到Transforms。Vector支持多种Transform方式，我们选用Remap with VRL的方式，因为这种方式不仅和Filter一样可以用来过滤数据，并且在数据转换上的性能比Lua更好（官方文档上描述的是使用Lua进行数据转换大约会比VRL慢百分之60）。3.2.1 编写脚本转换apisix网关的日志apisix作为开源网关工具，它的日志详细格式我们无法自定义，在这里，我们希望将其日志转换成如下格式： 将部分k8s日志本身的内容提取成字段，以k8s_作为前缀，解析message字段中的内容，以app_log_作为前缀，并进行部分数值转换 {\t\"app_log_body_bytes_sent\": 155,\t\"app_log_http_host\": \"192.168.100.26\",\t\"app_log_http_referer\": \"http://192.168.100.26/enterpriseadmin/orchestrationengine/dataPreview?groupId=1189505254941294592&amp;project=371344636432453&amp;showLayout=false\",\t\"app_log_http_user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\t\"app_log_remote_addr\": \"10.233.64.1\",\t\"app_log_request\": \"GET /api/progress/accessor/v1/progress/ji35KoYlzwemrjopvjDCY?project=371344636432453 HTTP/1.1\",\t\"app_log_request_time\": 0,\t\"app_log_status\": 200,\t\"app_log_time_local\": \"03/Jan/2024:14:46:40 +0000\",\t\"app_log_upstream_addr\": \"10.233.149.174:80\",\t\"app_log_upstream_response_time\": 1,\t\"app_log_upstream_status\": 200,\t\"k8s_namespace\": \"default\",\t\"k8s_pod_name\": \"gateway-76d8fd7cd-n5hqn\",\t\"k8s_service_name\": \"gateway\"} 编写VRL表达式时，官方有许多资料可供参考（包括函数，异常，简单示例等）。并且官方还提供了VRL playground，可以直接将当前数据粘贴上去，一边编写程序一边调试。这里直接粘贴编写好的脚本：. = flatten(., \"_\")if (.kubernetes_container_name == \"gateway\" &amp;&amp; starts_with(string!(.message), \"{\")) { msg_data = .message . = { \"k8s_service_name\": .kubernetes_container_name, \"k8s_pod_name\": .kubernetes_pod_name, \"k8s_namespace\": .kubernetes_pod_namespace } data = parse_json!(msg_data) if (is_null(data.request_time) || is_null(data.upstream_response_time)) { abort } data.request_time = string!(data.request_time) data.upstream_response_time = string!(data.upstream_response_time) if (is_empty(data.request_time) || is_empty(data.upstream_response_time)) { abort } request_time = parse_float!(data.request_time) * 1000 upstream_response_time = parse_float!(data.upstream_response_time) * 1000 .app_log_time_local = data.time_local .app_log_remote_addr = data.remote_addr .app_log_http_host = data.http_host .app_log_request = data.request .app_log_status = parse_int!(data.status) .app_log_body_bytes_sent = parse_int!(data.body_bytes_sent) .app_log_request_time = request_time .app_log_http_referer = data.http_referer .app_log_http_user_agent = data.http_user_agent .app_log_upstream_addr = data.upstream_addr .app_log_upstream_status = parse_int!(data.upstream_status) .app_log_upstream_response_time = upstream_response_time} else { abort}3.2.2 配置Transforms这里需要指定transform的inputs，并且将type指定为remap，另外我们还希望abort操作丢弃数据，因此最后的配置为：transforms: apisix_transform: type: remap inputs: - k8s drop_on_abort: true source: |- . = flatten(., \"_\") if (.kubernetes_container_name == \"gateway\" &amp;&amp; starts_with(string!(.message), \"{\")) { msg_data = .message . = { \"k8s_service_name\": .kubernetes_container_name, \"k8s_pod_name\": .kubernetes_pod_name, \"k8s_namespace\": .kubernetes_pod_namespace } data = parse_json!(msg_data) if (is_null(data.request_time) || is_null(data.upstream_response_time)) { abort } data.request_time = string!(data.request_time) data.upstream_response_time = string!(data.upstream_response_time) if (is_empty(data.request_time) || is_empty(data.upstream_response_time)) { abort } request_time = parse_float!(data.request_time) * 1000 upstream_response_time = parse_float!(data.upstream_response_time) * 1000 .app_log_time_local = data.time_local .app_log_remote_addr = data.remote_addr .app_log_http_host = data.http_host .app_log_request = data.request .app_log_status = parse_int!(data.status) .app_log_body_bytes_sent = parse_int!(data.body_bytes_sent) .app_log_request_time = request_time .app_log_http_referer = data.http_referer .app_log_http_user_agent = data.http_user_agent .app_log_upstream_addr = data.upstream_addr .app_log_upstream_status = parse_int!(data.upstream_status) .app_log_upstream_response_time = upstream_response_time } else { abort }3.3 Sinks当前需要将日志记录到OpenObserve，其提供了HTTP方式的API，HTTP Sink的文档参考：HTTP | Vector documentation。这里参考了OpenObserve提供的配置示例：Vector - OpenObserve Documentationsinks: openobserve: type: http inputs: - k8s # 使用上面配置的k8s日志source作为输入 uri: http://openobserve:5080/api/k8s/pods/_json method: post auth: strategy: basic user: root@example.com password: Complexpass#123 compression: gzip encoding: codec: json timestamp_format: \"rfc3339\" apisix_openobserve: type: http inputs: - apisix_transform # 使用上面配置的transform作为输入 uri: http://openobserve:5080/api/services/gateway/_json method: post auth: strategy: basic user: root@example.com password: Complexpass#123 compression: gzip encoding: codec: json timestamp_format: \"rfc3339\" " }, { "title": "实现一个短链服务器", "url": "/posts/url-shorter-1/", "categories": "经验技巧, 经验总结", "tags": "短链", "date": "2022-05-01 00:00:00 +0800", "snippet": " 短链服务器，即将长链接转换为短链接的服务器，本文记录实现一个短链服务器的过程。背景将长链接转换成短链接有几个显而易见的好处： 方便记忆 便于分享 在需要生成二维码时，能降低二维码的复杂度以及一些其他用途，例如可以基于短链服务做一些流量统计，增加链接过期等功能。构思实现短链的转换，存储及跳转是非常容易的，但是在实际实现过程中，还是有一些需要考虑的问题：短链编码生成方式的选择短链编码，...", "content": " 短链服务器，即将长链接转换为短链接的服务器，本文记录实现一个短链服务器的过程。背景将长链接转换成短链接有几个显而易见的好处： 方便记忆 便于分享 在需要生成二维码时，能降低二维码的复杂度以及一些其他用途，例如可以基于短链服务做一些流量统计，增加链接过期等功能。构思实现短链的转换，存储及跳转是非常容易的，但是在实际实现过程中，还是有一些需要考虑的问题：短链编码生成方式的选择短链编码，即短链中唯一变化的部分。可选的方式不止一种，但是有一个共同点，就是如果生成了一个10进制的数字，则可以将其进行进一步进行base62编码，因为base62可以使用包括数字，小写字母，大写字母在内的62个字符（有些短网址方案还包含-和_），可以进一步缩短短链的长度。1. 自增ID使用各种方式（程序内存内自增，数据库自增，Redis自增等）生成一个自增的ID，然后将这个ID转换为62进制的字符串作为短链的编码。这种处理方式的好处是因为基于现有的自增逻辑，只要能够保证自增机制的可靠以及唯一性，就可以保证短链的生成无碰撞。但缺点也很明显，首先这样生成的编码是有序的，很容易被其他人遍历到所有的短链；其次，生成的短链和原长链接本身不具有任何关联性，这意味着如果希望不对一个长链接重复生成短链，就需要在每次生成短链之前，用当前这个长链接查询是否已经生成过短链，考虑到原链接可能会非常长，这样产生的查询开销显然是不低的；另外，如果借助的是数据库主键自增的方式，数据库逐渐自增的速率也可能会成为瓶颈。2. 随机数直接在程序内使用普通随机数作为短链编码，然后将其转换为62进制的字符串。这种方式的好处是生成的短链是无序的，不容易被遍历到所有的短链。缺点是随机数的生成本身是有碰撞的，在生成速度比较快的情况下，这个碰撞的几率可能会非常大，这样一来，可能需要重复几次随机过程才能生成一个新的短链，另外如果希望不重复，和自增ID的方式一样，也需要在生成短链之前，用当前这个长链接查询是否已经存在短链。3. HASH算法使用HASH算法，例如MD5，SHA1等，将长链接转换为一个固定长度的字符串。这样生成的短码是无序的，而且生成的短码和原长链接具有一定的关联性，这样一来，只需要在HASH之后直接验证当前生成的HASH值有没有生成过短链即可，而不需要再使用长链本身进行查询。HASH算法的缺点在于虽然碰撞概率较低，但是还是存在碰撞的可能性，而且如果使用的是MD5，SHA1等算法，生成的短链长度也会比较长，不利于短链的使用。最终选型综合考虑，最终选型为使用HASH算法，因为它兼具了无序性以及和原链接有关联的特点。目前需要解决的问题主要是HASH值过长的问题，参考了其他实现之后，决定采用非加密HASH算法，例如MurmurHash，xxHash，CityHash等。非加密HASH算法和加密HASH算法最大的区别1是，这类算法的初衷往往只是为了防止数据被意外修改（比如CRC），或者将数据分散到不同的桶中，而不是为了防止数据被恶意修改，因此这类算法的设计目标是尽可能快地计算出HASH值，而不是尽可能难以被破解2。鉴于目前的场景，显然非加密HASH函数更适合我们，因为我们需要更短的HASH值，而许多非加密HASH都提供生成32位HASH值的选项。而具体到选择哪种非加密HASH函数，在参考了一些其他人的测试结果，综合性能，生成质量（离散性，随机性），以及社区活跃度（参考了其在Github上的活跃程度以及各语言实现库的数量）3，最终选择采用xxHash（XXH32）作为我们的HASH函数。至于碰撞的问题，显然只能通过假如碰撞了就在原字符串后追加一些内容，再重新生成的方式。存储方式的选择对于当前业务场景，我选取存储方式的标准主要有： 读写性能，短链的存取速度应该尽可能快，至少存储不能成为瓶颈 较少的依赖，短链服务应该尽可能独立，不应该依赖于其他服务 对于我们将要使用的语言及框架（C# on dotnet 6），有成熟的可用支持库综合考虑，最终排除了SQLite，Redis，LevelDB三种存储方式，他们的缺点分别对应上面的三点最终，我选择了FASTER KV作为存储方案，其作为一个嵌入式，支持持久化的key-value存储库，在支持基本key-value操作的同时，还拥有非常优秀的性能（根据官方的基准测试，在单台服务器的ops达到了惊人的1.6亿，而我在自己的电脑上直接运行官方的基准测试，也达到了接近4000万的ops），并且其具有原生的C#实现，非常适合在当前项目中使用。状态码的选择选择302临时重定向，因为301永久重定向的结果会被浏览器缓存，导致无法应对后续的访问信息（访问数，User-Agent等）统计，短链过期等需求。总览经过上述的技术选型，我们可以直接得到一个简单的构建短链请求的流程图：代码实现https://github.com/KamenRiderKuuga/UrlShorter What is the difference between a Hash Function and a Cryptographic Hash Function? &#8617; 像MD5这样的算法，虽然已经被证实存在安全缺陷，但是由于它的初衷是为了安全，目前仍然愿意将其归类为加密HASH函数，因为是否会在一种HASH函数中出现这种情况是很难预测的 &#8617; 参考了漫谈非加密哈希算法，xxHash#benchmarks &#8617; " }, { "title": "自定义供日常使用的PowerShell脚本模块", "url": "/posts/tips-6/", "categories": "经验技巧, 经验总结", "tags": "PowerShell", "date": "2021-11-01 00:00:00 +0800", "snippet": " 在使用Windows操作系统时，经常会以PowerShell作为Shell工具，本文描述如何封装自己经常使用的脚本供日常使用编写脚本在这里我们编写一个脚本，用来找出桌面上一个星期以上（大于或者等于8天）没有访问过的文件，因为是用于示例，这里使用相对容易理解的语法，并且添加了注释：function Get-OldFiles { # 获取桌面上所有的文件信息 $all_files...", "content": " 在使用Windows操作系统时，经常会以PowerShell作为Shell工具，本文描述如何封装自己经常使用的脚本供日常使用编写脚本在这里我们编写一个脚本，用来找出桌面上一个星期以上（大于或者等于8天）没有访问过的文件，因为是用于示例，这里使用相对容易理解的语法，并且添加了注释：function Get-OldFiles { # 获取桌面上所有的文件信息 $all_files = Get-ChildItem $env:USERPROFILE\\Desktop -Recurse -File # 循环文件信息，返回其文件名，路径，以及没有访问的天数 foreach ($file in $all_files) { $not_access_day = ((Get-Date) - $file.LastAccessTime).Days if ($not_access_day -ge 8) { $value = [PSCustomObject] @{ Name = \"\" NotAccessDays = 0 Path = \"\" } $value.Name = $file.Name $value.Path = $file.FullName $value.NotAccessDays = $not_access_day Write-Output $value } }}可以看到，脚本里只有一个函数Get-OldFiles，这个函数可以用来查询出所有一个星期以上没有访问的文件信息存储脚本在将这个脚本保存为文件之前，我们先要了解一些关于PSModulePath的内容，这些内容可以查看about PSModulePath - PowerShell我们可以了解到，PSModulePath也就是PowerShell脚本模块的保存路径，PowerShell会在里面递归搜索.psd1和.psm1文件，使其中定义的脚本模块在当前PowerShell会话中可用因此，我们现在要做的，就是把我们写好的脚本保存到PSMoudulePath，那么电脑上的PsModulePath指的是哪个文件夹呢，其实他不是一个文件夹，而是一些文件夹，PowerShell会在这些文件夹中寻找可以导入的模块。上面的链接中也有提及，这里进行简要说明（只对于没有自定义过PSModulePath，而使用默认路径的情况，关于如何自定义PSModulePath，也可以参考上面链接中的内容）：对于Windows系统来说（提及的路径可以在PowerShell中输出出来，例如Write-Output $PSHOME\\Modules） 用于Windows系统管理的模块放置在：$PSHOME\\Modules对于PowerShell 7.x版本： 用户自行安装（当前用户可用，安装时指定的Scope为CurrentUser）的模块放置在：$HOME\\Documents\\PowerShell\\Modules 用户自行安装（所有用户可用，安装时指定的Scope为AllUsers）的模块放置在：$env:ProgramFiles\\PowerShell\\Modules对于PowerShell 5.1版本（Win10自带PowerShell）: 用户自行安装（当前用户可用，安装时指定的Scope为CurrentUser）的模块放置在：$HOME\\Documents\\WindowsPowerShell\\Modules 用户自行安装（所有用户可用，安装时指定的Scope为AllUsers）的模块放置在：$env:ProgramFiles\\WindowsPowerShell\\Modules综上，现在我们想要新增的脚本模块对于这台电脑上的所有用户可用，我们选择将上面的脚本内容存储到$env:ProgramFiles\\WindowsPowerShell\\Modules文件夹切换到上面说的文件夹：cd $env:ProgramFiles\\PowerShell\\Modules在这里新建一个文件夹，值得说明的是，这个文件夹将会作为稍后的模块名称，我们这里编写的函数是和文件有关的，我们起名叫FileTool，于是接着上面的命令：mkdir FileTool; start FileTool现在我们就创建并打开了我们的脚本模块文件夹，接着，我们将之前写好的脚本粘贴进任意的文本编辑器并保存到这个文件夹，文件后缀为.psm1即可，这里需要注意的是，一个模块里面至少要有一个文件和模块名称本身相同，关于这一点，可以查看Installing a PowerShell Module - PowerShell页面的Use the Correct Module Directory Name部分，所以这里我们将其保存为FileTool.psm1使用脚本保存完成后，我们在PowerShell中使用Get-Command -Module FileTool命令，发现FileTool模块的命令列表被列出来了，由于我们这里只定义了一个，可以看到：CommandType Name Version Source----------- ---- ------- ------Function Get-OldFiles 0.0 FileTool输入Get-OldFiles命令，命令被正确执行，至此，自定义PowerShell脚本模块的过程完成扩展内容.psd1文件的使用在前面编写脚本部分，提到PowerShell也会检索.psd1文件，.psd1文件中记录的内容也被称为模块描述清单（module manifest），里面的内容是使用PowerShell语法创建的一个hash table，里面的键值对记录一个模块被导入时的一些配置，这个文件不需要我们手写，我们可以定位到上面保存.psm1文件的FileTool文件夹，使用命令创建一个.psd1文件New-ModuleManifest -Path .\\FileTool.psd1 -ModuleVersion \"1.0\" -Author \"HANABI\" -RootModule FileTool可以看到，我们在这个命令中指定了.psd1文件的名称，脚本模块版本号，作者，以及与其关联的脚本模块名称。执行完这条命令后，我们启动一个新的PowerShell，再次输入命令Get-Command -Module FileTool，可以看到：CommandType Name Version Source----------- ---- ------- ------Function Get-OldFiles 1.0 FileTool版本信息已经成功改变了，.psd1文件的作用不限于此，还能通过它来指定有哪些函数是需要从脚本模块文件中导出的，从而只对外暴露那些想要被使用的函数，关于模块描述清单的更多信息，可以查看How to Write a PowerShell Module Manifest - PowerShell关于模块导入其实，查看当前PowerShell会话的可用脚本模块，应该使用的命令是Get-Module，但当我们在上述的编写脚本，存储脚本步骤之后使用这个命令，是不能看到我们这次新增的FileTool模块的，只有当我们使用了属于这个模块的命令Get-OldFiles，或者使用Get-Command -Module FileTool命令之后，再次使用Get-Module命令，才能看到FileTool模块之所以会出现这种情况，是因为实际上一个脚本模块，是需要先导入，才能进行使用的，但是从PowerShell 3.0开始，模块可以在使用其命令，或者使用上面提到的Get-Command命令（指定相应的模块或者命令）时被自动导入，而不需要再进行手动导入，具体可以查看Importing a PowerShell Module - PowerShell如果需要显式导入的话，可以使用Import-Module FileTool命令来为当前PowerShell会话导入这个模块，若需要在每个PowerShell会话时都默认导入这个模块，可以在PowerShell的profile.ps1文件中添加每次启动PowerShell会话时都默认运行的脚本，profile.ps1文件的存储位置可以在PowerShell中通过命令查看：$PROFILE | Select-Object CurrentUserAllHosts,AllUsersAllHosts | Format-List输出的结果中，CurrentUserAllHosts是对当前用户的所有会话生效的profile.ps1文件路径，AllUsersAllHosts则是对应所有用户的所有会话的，我们可以使用命令向这个文件添加内容：Add-Content $PROFILE.AllUsersAllHosts 'Import-Module FileTool'之后再打开新的PowerShell会话，使用Get-Module，可以看到FileTool脚本模块已经被正确列出不难发现，profile能做到的事情还有很多，不局限于自动导入脚本模块，如果想要了解更多关于PowerShell profile的内容，可以查看about Profiles - PowerShell一些小事 保存.psm1文件，并且需要输出非ASCII字符时，文件的编码格式需要为UTF-8 with BOM，否则在使用PowerShell 5.1版本时会出现乱码或者脚本无法正常执行的问题（对于这里的.psm1文件来说，这会导致脚本模块无法被正常检测），这一点对于平时编写的.ps1文件（普通的PowerShell脚本文件）也同样适用 从上文对于.psd1文件的描述中不难看出，一个脚本模块文件可以定义不止一个函数，并且可以通过.psd1文件进行导出 对于PowerShell命令名的命名规范，请尽量使用&lt;Verb&gt;-&lt;宾语&gt;的格式，可以观察到PowerShell的几乎所有内置命令都是以这样的格式命名的，可用的Verb列表可以使用Get-Verb命令查看，这个命令会列出动词及其描述 关于脚本模块文件的存储路径，这里选择使用PowerShell 5.1的路径，是因为只要一台Win10电脑上具有默认的5.1版本的PowerShell并且脚本模块路径没有被自定义过，这个路径就总是可用的，各个版本的PowerShell都会查找每一个可用的脚本模块路径，这些路径可以通过命令$Env:PSModulePath -split ';'列出 结合自己的编程环境，通过在PowerShell脚本中结合Python脚本或者DLL，或许可以更快速的包装出一些更复杂更高效的命令 参考内容Script modules - PowerShell" }, { "title": "通过Windows系统服务守护进程的运行", "url": "/posts/tips-5/", "categories": "经验技巧, 经验总结", "tags": ".NET", "date": "2021-09-13 00:00:00 +0800", "snippet": " 遇到这样一个需求，需要保持一个桌面客户端程序在用户电脑上的运行，并在意外关闭或者手动关闭后也要重新启动初步尝试在平时的开发过程中，遇到需要启动进程的需求，肯定会想到使用：System.Diagnostics.Process.Start(\"Example.exe\");这样的方式来启动一个进程，于是针对现在的需求，我们可能会在系统服务程序中写这样的代码：var processName = \"...", "content": " 遇到这样一个需求，需要保持一个桌面客户端程序在用户电脑上的运行，并在意外关闭或者手动关闭后也要重新启动初步尝试在平时的开发过程中，遇到需要启动进程的需求，肯定会想到使用：System.Diagnostics.Process.Start(\"Example.exe\");这样的方式来启动一个进程，于是针对现在的需求，我们可能会在系统服务程序中写这样的代码：var processName = \"notepad\";while (true){ Thread.Sleep(5000); if (!(Process.GetProcessesByName(\"notepad\")?.Length &gt; 0)) { Process.Start(processName); }}为了验证是否能够生效，我们安装系统服务并启动这个系统服务1等待了一段时间，在操作系统界面上，没有看到记事本程序像预期那样启动。通常可能会认为进程没有被正常的启动，或者代码执行过程中出现了什么问题，但是当我们使用任务管理器等方式查找进程，却发现名字为notepad的进程已经存在了，这是怎么回事呢？探索原因在一番搜索之后，终于发现了原因（具体可以查看本文下方中获取到这些知识的文章）。原来从Windows Vista开始，Windows系统引入了Session 0 隔离机制，这个机制是出于一些安全方面的考量 In Windows XP, Windows Server 2003, and earlier versions of the Windows operating system, all services run in the same session as the first user who logs on to the console. This session is called Session 0. Running services and user applications together in Session 0 poses a security risk because services run at elevated privilege and therefore are targets for malicious agents who are looking for a means to elevate their own privilege level.首先要明白Windows系统中Session的概念，在Windows系统中，每个登录的用户都会被分配到一个唯一的SessionId，每个Session之间是彼此有隔离的，按照目前对于Session的理解，可以认为： 进程是为了内部的执行的线程提供一个空间和环境，而会话则是为内部所有的进程提供一个执行的空间和环境。在早期的Windows系统中，Windows服务进程与第一个登录进入系统的用户共享同一个Session，没有做任何隔离，这样会引发一些隐患，比如恶意软件可以通过与Windows服务进程进行通讯，来造成一些超出用户权限能力的破坏于是，由于Windows服务被隔离到了一个单独的Session，也就是Session 0，所以当我们通过Windows服务启动进程的时候，这个进程是在Session 0中被启动，我们无法看到其交互界面解决问题按照参考文章中的说法，想要从Session 0产生一些具有交互界面的行为，可以使用调用Win32 Api来实现： 可以使用 WTSSendMessage往用户桌面创建一个简单的消息框 使用CreateProcessAsUser 函数在用户会话中创建进程很明显，第二个选项就是我们需要的，于是我们在代码中调用这个函数，即可解决这个问题，详见代码[ProcessGuard/ApplicationLoader.cs at main · GadHao/ProcessGuard (github.com)]里的StartProcessInSession0()函数，代码中有详细注释开发工具利用上面介绍的方法开发了进程守护服务，并且制作了WPF界面管理整个守护服务从安装使用到停止和卸载的整个过程，有兴趣或者有需要的可以下载使用：Releases · GadHao/ProcessGuard (github.com)参考内容本文，特别是文中的引用部分参考了这些文章的内容：Subverting Vista UAC in Both 32 and 64 bit Architectures By Pero MatićApplication Compatibility - Session 0 Isolation By Craig Marcho理解Windows会话 关于如何安装和启动系统服务，可以查看Windows相关备忘的第18到20点 &#8617; " }, { "title": "Docker使用备忘", "url": "/posts/docker-1/", "categories": "经验技巧, 日常工具", "tags": "Docker", "date": "2021-06-27 00:00:00 +0800", "snippet": " 这里记录在学习以及使用Docker时的一些点，用到的Linux版本为Debian10安装打开Docker官方文档并找到Install指引页面，选中自己正在使用的系统，按照指引进行安装即可指南中的步骤，依次介绍了如何卸载旧版本的Docker，如何安装Docker（使用推荐的通过repository的安装方式，或者在没有外网的环境时通过安装包进行安装），这里需要注意的事，如果服务器不具备相关...", "content": " 这里记录在学习以及使用Docker时的一些点，用到的Linux版本为Debian10安装打开Docker官方文档并找到Install指引页面，选中自己正在使用的系统，按照指引进行安装即可指南中的步骤，依次介绍了如何卸载旧版本的Docker，如何安装Docker（使用推荐的通过repository的安装方式，或者在没有外网的环境时通过安装包进行安装），这里需要注意的事，如果服务器不具备相关网络条件，可以使用阿里云镜像地址：https://mirrors.aliyun.com，或者直接使用适用于国内环境的安装脚本：curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun安装完成后可以按照官方文档，试着运行sudo docker run hello-world测试是否是否正确安装，这个命令检测到本地还没有hello-world这个镜像，就会去拉取这个镜像到本地，拉取并成功运行后，可以通过docker images命令，查看当前已经安装的所有镜像卸载在官方文档中也有提及，使用：sudo apt-get purge docker-ce docker-ce-cli containerd.io，注意，执行命令之后，宿主机上的镜像，容器，挂载卷，还有一些自定义配置信息不会被自动删除，如果想要删除它们，可以使用：sudo rm -rf /var/lib/dockersudo rm -rf /var/lib/containerd配置国内镜像加速服务 如果没有文件夹etc/docker，则先创建它 在该文件夹中的deamon.json文件中(若无则创建)，添加registry-mirrors字段的内容，该字段是一个字符串数组，可以在其中添加多个加速镜像源，以便docker在源不可用时，自动切换到可用的源，这里可以用命令： sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF' { \"registry-mirrors\":[ \"https://docker.mirrors.ustc.edu.cn/\", \"https://hub-mirror.c.163.com/\", \"https://reg-mirror.qiniu.com\" ] } EOF 编辑完并保存之后，重启服务即可: $ sudo systemctl daemon-reload $ sudo systemctl restart docker Docker的常用命令docker version # 显示docker的版本信息docker info # docker的运行信息，包括`Containers`和`Images`的数量docker &lt;command&gt; --help # 帮助命令镜像命令docker images：查看本地镜像docker search：搜索镜像docker pull：拉取镜像docker rmi mysql：删除本地镜像容器命令运行容器docker run# 可选参数--name # 容器名，用来区分容器-d 后台方式运行 # 后台运行是有前提的，如果运行之后没有前台进程，容器就会自动退出，所以需要使用一些阻塞挂起命令启动容器，或者使用交互方式运行后再不停止并退出容器-it 使用交互方式运行，进入容器查看内容-p 指定容器的端口-P 随机指定容器端口--rm 在容器停止后自动删除容器以及其挂载的相关匿名卷 # 用于测试的情况比较多-v 将容器内的目录挂载到宿主机上的目录（在挂载时指定的容器目录后可以加:ro或者:rw，指定在容器内文件的独写权限）--volumes-from 同步容器之间的数据（eg: docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 --name mysql02 --volumes-from mysql01 mysql:5.7）列出容器docker ps# 可选参数-a # 列出当前正在运行的容器 + 历史运行过的容器-n=&lt;数量&gt; # 显示最近创建的指定数量个容器-q # 只显示容器的编号退出容器exit：停止并退出容器 Ctrl + P + Q：不停止并退出容器删除容器docker rm &lt;容器ID&gt;docker rm -f $(docker ps -aq) # 强制删除所有容器docker ps -a -q|xargs docker rm # 删除所有容器启动和停止容器的操作docker start &lt;容器ID&gt; # 启动一个容器docker restart &lt;容器ID&gt; # 重启一个容器docker stop &lt;容器ID&gt; # 停止一个容器docker kill &lt;容器ID&gt; # 强制停止一个容器查看容器中的进程信息docker top &lt;容器ID&gt;查看容器的元数据docker inspect &lt;容器ID&gt;进入当前正在运行的容器docker exec -it &lt;容器ID&gt; /bin/bashdocker attach &lt;容器ID&gt;其他命令拷贝命令（从容器内拷贝到主机上）docker cp &lt;容器ID&gt;:&lt;文件路径&gt; &lt;目标文件夹&gt;查看运行中容器的资源占用情况docker stats运行Portainer可视化面板docker run -d -p 8088:9000 --restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainer基于现有容器的改动创建新的镜像docker commit -a\"&lt;author&gt;\" -m\"&lt;message&gt;\" &lt;容器ID&gt; &lt;新镜像名称&gt;DockerFile用途：用来构建docker镜像的文件指令：FROM # 基础镜像MAINTAINER # 镜像维护者信息RUN # 构建镜像时需要运行的命令ADD # 添加内容WORKDIR # 镜像的工作目录VOLUME # 挂载目录EXPOSE # 暴露端口CMD # 指定容器启动时要运行的命令，只有最后一个会生效ENTRYPOINT # 指定容器启动时要运行的命令，可以在命令后进行追加ONBUILD # 构建时要执行的指令COPY # 类似ADD命令，将文件拷贝到镜像中ENV # 构建的时候设置环境变量通过Dockerfile构建镜像docker build -f &lt;Dockerfile路径&gt; -t &lt;镜像名&gt;:&lt;tag&gt; &lt;PATH&gt; 查看Docker镜像的构建步骤docker history &lt;ImageId&gt;" }, { "title": "CLR via C#学习笔记（1）", "url": "/posts/csharp-2/", "categories": "编程语言, C#", "tags": "笔记, CLR, CSharp", "date": "2021-04-28 00:00:00 +0800", "snippet": " .NET的CLR和.NET Core的CoreCLR主体没有太大区别，之前对于这本书的了解程度是在需要的时候去查阅，现在希望能够对其进行一个相对系统，整体的学习CLR简介CLR，全名Common Language Runtime ，一般翻译成公共语言运行时，所谓运行时，可以对标Java生态中的JVM，无论是什么编程语言，只要能通过各种编译器编译成托管模块(managed module)...", "content": " .NET的CLR和.NET Core的CoreCLR主体没有太大区别，之前对于这本书的了解程度是在需要的时候去查阅，现在希望能够对其进行一个相对系统，整体的学习CLR简介CLR，全名Common Language Runtime ，一般翻译成公共语言运行时，所谓运行时，可以对标Java生态中的JVM，无论是什么编程语言，只要能通过各种编译器编译成托管模块(managed module)，就可以通过CLR执行，CLR为其运行提供了环境，其核心功能包括：内存管理、程序集加载、安全性、异常处理和线程管理等托管模块托管模块是指通过面向CLR的编译器编译的，最后通过CLR运行的PE（Portable Executable：可移植执行体）文件托管模块包括几个部分： PE32或PE32+头，这里标识了托管模块可以运行的操作系统版本，以及文件类型（GUI，CUI或DLL），文件生成时间 CLR头：包含要求的CLR版本，一些flags，托管模块的入口函数(Main函数)的MethodDef元数据token，以及包括模块的元数据、资源、强名称、标志，还有其他一些不太重要的数据项的位置/大小 元数据(metadata)：述源代码中定义的类型和成员，以及引用的类型和成员 IL(中间语言)代码：编译器编译源码产生的代码，在运行时，会被CLR编译成编辑CPU指令 程序集CLR直接与程序集(assembly)打交道，程序集是一个抽象概念，程序集中包含一个名为清单（manifest）的数据块。清单也是元数据表的集合，这些表描述了构成程序集的文件、程序集中文件所实现的公开导出的类型，与程序集关联的资源或数据文件等。编译器默认将生成的托管模块转换成程序集，也就是说，C#编译器生成的是含有清单的托管模块。所以，对于只有一个托管模块且无其他资源文件的项目，程序集就是托管模块，生成过程中无需执行任何其他操作的步骤，但是如果希望将一组文件合并到程序集中，就需要程序集链接器和其他命令行选项。在程序集的模块中，还包含与引用的程序集有关的信息（包括版本号）。这些信息使程序集可以自描述(self-describing)，CLR可以通过这些信息判断程序集的直接依赖对象（immediate dependency）是什么，而不需要在注册表或其他地方保存额外的信息，所以和非托管组件相比，程序集更容易部署加载CLRWindows执行可执行文件时，先检查其文件头，判断需要32位还是64位地址空间。其中，如果操作系统是64位的，需要运行32位Windows应用程序的话，会通过Wow64（Windows on Windows64）技术运行32位Windows应用程序。判断完成之后，其会在进程地址空间加载MSCorEE.dll，接着，进程调用MSCorEE.dll中定义的一个方法，这个方法初始化CLR，加载EXE程序集，调用其入口方法（Main），随即，托管应用程序启动并运行。值得注意的是，如果非托管程序调用LoadLibrary加载托管程序集，Windows会自动加载并初始化CLR。因为此时进程以及你个启动并运行了，所以可能会限制程序集的可用性，例如，64位进程完全无法加载使用文件头为PE32的托管程序集执行程序集的代码托管程序集同时包含元素据和IL，IL是与CPU无关的机器语言，它比大多数CPU机器语言都高级，可以将其视为一种面向对象的机器语言，其能够访问和操作对象类型，具有创建和初始化对象、调用对象上的虚方法以及直接操作数组元素的指令高级语言通常只公开了CLR全部功能的一个子集。然而，IL汇编语言允许开发人员访问CLR的全部功能。所以如果你选择的编程语言隐藏了你迫切需要的一个CLR功能，可以换用IL汇编语言或者提供了所需功能的另一种编程语言来写那部分代码为了执行方法，首先必须把方法的IL转换成本机(native)CPU指令。这是CLR的JIT(just-in-time)编译器的职责。书里举了一个调用Console.WriteLine函数的例子其在方法首次被调用时，验证并将IL代码编译成本机CPU指令，本机CPU指令保存到动态分配的内存块中。之后，JITCompiler回到CLR为类型创建的内部数据结构，替换被调用方法对应的那条记录的引用，使其指向内存块（包含了刚才编译号的本机CPU指令）的地址。最后，JITCompiler函数跳转到内存块中的代码，代码执行完毕并返回时，会回到Main中的代码，并像往常一样继续执行第二次调用WriteLine时，因为已经对WriteLine的代码进行了验证和编译，所以会直接执行内存块中的代码，完全跳过JITCompiler函数。所以，方法仅在首次调用时才会有一些性能损失。以后对该方法的所有调用都以本机代码的形式全速运行，无需重新验证IL并把它编译成本机代码程序重新启动，或者同时动应用程序的两个实例，JIT编译器都会再次将IL编译成本机指令。相比之下，本机（native）应用程序的只读代码页可由应用程序正在运行的所有实例共享/optimize和/debug这两个编译开关对编译生成的IL代码会有影响，这些编译选项主要是会对程序的调试提供帮助因为JIT编译器对程序执行环境的认识比非托管编译器更深刻，所以有理由相信，托管应用程序有能力超越非托管应用程序的性能IL和验证IL基于栈，并且是无类型(typeless)的。其是对底层CPU的抽象，并且由于将IL编译成本机CPU指令时，CLR会执行一个验证过程，这个过程会检查IL代码，确认代码所作的一切都是安全的，所以其构建的应用程序具有健壮性和安全性。上面提到的可以验证安全性的代码，被称为安全(safe)代码，Microsoft C#编译器也允许开发人员写不安全的(unsafe)代码。不安全的代码允许直接操作内存地址，并可操作这些地址处的字节。这类包含不安全代码的所有方法都需要用unsafe关键字标记。除此之外，C#编译器要求使用/unsafe编译器开关来编译源代码本机代码生成器使用.NET Framework提供的NGen.exe工具，可以在应用程序安装到用户的计算机上时，将IL代码编译成本机代码，其作用是可以提交程序的启动速度以及减少程序运行时独自占用的内存（其将IL编译成本机代码，并保存到单独的文件中。该文件可以通过内存映射的方式，同时映射到多个进程地址空间中，使代码得到了共享，避免每个进程都需要一份单独的代码拷贝）但是，需要注意的是NGen生成的文件是没有知识产权保护的，因为在运行时CLR要求访问程序集的元数据（用于反射，序列化等功能），所以要求发布包含IL和元数据的程序集，另外，如果因为各种原因，NGen生成的文件失去了同步，也必须要对程序集的IL进行JIT编译，所以IL代码必须处于可用状态。由于编译代码时，NGen无法像JIT编译器那样对执行环境进行许多假定，所以这会造成其造成性能较差的代码Framework类库.NET Framework包含Framework类库（Framework Class Library, FCL），这是一组DLL程序集的统称，其中定义了数千个拥有各自功能的类通用类型系统CLR的一切围绕类型展开，Microsoft制定了一个正式的规范来描述类型的定义和行为，这就是通用类型系统" }, { "title": "一些.NET相关的工具整理", "url": "/posts/tips-4/", "categories": "经验技巧, 日常工具", "tags": "日常技能", "date": "2021-02-04 00:00:00 +0800", "snippet": " 在日常工作与学习过程中接触和使用了一些很实用的和.NET生态相关的工具dnSpy一个可以用来直接反编译并且调整C#或者VB.NET程序代码的工具ILSpy同样也是一个.NET的反编译工具，就使用体验来说，这个的反编译效果更好，但是不能像dnSpy一样对代码进行调整并且重编译，不过其开发了Visual Studio 2017/2019和Visual Studio Code的扩展应用Shar...", "content": " 在日常工作与学习过程中接触和使用了一些很实用的和.NET生态相关的工具dnSpy一个可以用来直接反编译并且调整C#或者VB.NET程序代码的工具ILSpy同样也是一个.NET的反编译工具，就使用体验来说，这个的反编译效果更好，但是不能像dnSpy一样对代码进行调整并且重编译，不过其开发了Visual Studio 2017/2019和Visual Studio Code的扩展应用SharpDevelop一款小巧轻便的C# IDEProcess Monitor用于Windows的高级监视工具，可显示监视文件系统动作，注册表和进程/线程活动，在调试和排查问题的时候，特别是面对一些自己不了解的黑盒子的时候非常有用" }, { "title": "VS Code使用备忘", "url": "/posts/vscode-1/", "categories": "编程工具, 编辑器", "tags": "Visual Studio Code", "date": "2020-12-27 00:00:00 +0800", "snippet": " 这里记录一些在使用VS Code的过程中遇到的值得记录的点，包括快捷键，插件等导航到上一个/下一个光标位置Windows: Alt + ←/→打开Markdown侧边栏预览Windows: Ctrl + K V将剪切板中的JSON直接粘贴成代码类使用Paste JSON as Code插件，复制JSON后，在VS Code里直接使用:Windows: Ctrl + Shift + V参数...", "content": " 这里记录一些在使用VS Code的过程中遇到的值得记录的点，包括快捷键，插件等导航到上一个/下一个光标位置Windows: Alt + ←/→打开Markdown侧边栏预览Windows: Ctrl + K V将剪切板中的JSON直接粘贴成代码类使用Paste JSON as Code插件，复制JSON后，在VS Code里直接使用:Windows: Ctrl + Shift + V参数提示MacOS: Command + Shift + Space为erb文件添加Emmet支持Setting - 搜索Emmet - 在Include Languages中添加两行:{ \"erb\": \"html\", \"ruby\": \"html\"}另外记得将Emmet: Trigger Expansion On Tab设置为true" }, { "title": "Git使用备忘", "url": "/posts/git-1/", "categories": "经验技巧, 日常工具", "tags": "Git", "date": "2020-12-14 00:00:00 +0800", "snippet": " 使用Git命令有助于在不同的平台更为高效和通用的使用Git操作，并且只有在命令行模式下你才能执行Git的所有命令，这里做一些使用的相关备忘，因为使用时都是参考文档，所以内容其实大部分都是直接摘录的的官方文档中已经有的，自己用到过的命令(还有一些不属于Git命令，比如echo)Git Bash运行命令后，出现冒号说明当前指令返回过多结果，继续查看可以按回车，或者按向下方向键，直到出现END...", "content": " 使用Git命令有助于在不同的平台更为高效和通用的使用Git操作，并且只有在命令行模式下你才能执行Git的所有命令，这里做一些使用的相关备忘，因为使用时都是参考文档，所以内容其实大部分都是直接摘录的的官方文档中已经有的，自己用到过的命令(还有一些不属于Git命令，比如echo)Git Bash运行命令后，出现冒号说明当前指令返回过多结果，继续查看可以按回车，或者按向下方向键，直到出现END提示符，或者任何时候按Q退出检查配置信息如果想要检查你的配置，可以使用 git config --list 命令来列出所有 Git 当时能找到的配置。$ git config --listuser.name=John Doeuser.email=johndoe@example.comcolor.status=autocolor.branch=autocolor.interactive=autocolor.diff=auto...你可以通过输入 git config &lt;key&gt;： 来检查 Git 的某一项配置$ git config user.nameJohn Doe获取帮助若你使用 Git 时需要获取帮助，有三种等价的方法可以找到 Git 命令的综合手册（manpage）：$ git help &lt;verb&gt;$ git &lt;verb&gt; --help$ man git-&lt;verb&gt;此外，如果你不需要全面的手册，只需要可用选项的快速参考，那么可以用 -h 选项获得更简明的 “help” 输出：在已存在目录中初始化仓库在目标目录中使用：$ git init克隆现有的仓库$ git clone https://github.com/libgit2/libgit2如果你想在克隆远程仓库的时候，自定义本地仓库的名字，你可以通过额外的参数指定新的目录名：$ git clone https://github.com/libgit2/libgit2 mylibgit粘贴快捷键shift+ins检查当前文件状态可以用 git status 命令查看哪些文件处于什么状态。用指定字符串作为内容创建指定名称的文件echo \"new file\" &gt;README.md跟踪新文件使用命令 git add 开始跟踪一个文件：$ git add README这是个多功能命令：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。 将这个命令理解为“精确地将内容添加到下一次提交中”而不是“将一个文件添加到项目中”要更加合适。提交时文件的版本会是最后一次运行 git add 命令时的那个版本，而不是你运行 git commit 时，在工作目录中的当前版本。 所以，运行了 git add 之后又作了修订的文件，需要重新运行 git add 把最新版本重新暂存起来取消跟踪文件取消跟踪文件:git reset HEAD &lt;file&gt;状态简览git status 命令的输出十分详细，但其用语有些繁琐。 Git 有一个选项可以帮你缩短状态命令的输出，这样可以以简洁的方式查看更改。 如果你使用 git status -s 命令或 git status --short 命令，你将得到一种格式更为紧凑的输出。$ git status -s M READMEMM RakefileA lib/git.rbM lib/simplegit.rb?? LICENSE.txt新添加的未跟踪文件前面有 ?? 标记，新添加到暂存区中的文件前面有 A 标记，修改过的文件前面有 M 标记。 输出中有两栏，左栏指明了暂存区的状态，右栏指明了工作区的状态。例如，上面的状态报告显示： README 文件在工作区已修改但尚未暂存，而 lib/simplegit.rb 文件已修改且已暂存。 Rakefile 文件已修，暂存后又作了修改，因此该文件的修改中既有已暂存的部分，又有未暂存的部分。显示文件内容cat filename忽略文件一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件的模式。 来看一个实际的 .gitignore 例子：$ cat .gitignore*.[oa]*~查看已暂存和未暂存的修改如果 git status 命令的输出对于你来说过于简略，而你想知道具体修改了什么地方，可以用 git diff 命令。 稍后我们会详细介绍 git diff，你通常可能会用它来回答这两个问题：当前做的哪些更新尚未暂存？ 有哪些更新已暂存并准备好下次提交？ 虽然 git status 已经通过在相应栏下列出文件名的方式回答了这个问题，但 git diff 能通过文件补丁的格式更加具体地显示哪些行发生了改变。若要查看已暂存的将要添加到下次提交里的内容，可以用 git diff --staged 或者git diff --cached命令( --staged 和 --cached 是同义词)。 这条命令将比对已暂存文件与最后一次提交的文件差异将VS Code设置为Git默认的editor首先，在环境变量中的Path中添加VS Code启动文件所在路径，然后执行：$ git config --global core.editor Code在Git bash中执行 $ Code &lt;文件名&gt; 命令可以使用默认的VS Code编辑器对文件进行编辑使用-w参数表示Git会等待编辑器编辑完成$ git config --global core.editor \"Code -w\"用VS Code 打开.gitconfig文件：git config --global -e在里面加上：[diff] tool = default-difftool[difftool \"default-difftool\"] cmd = code --wait --diff $LOCAL $REMOTE这时候运行git difftool，就是以VS Code作为默认difftool了提交更新现在的暂存区已经准备就绪，可以提交了。 在此之前，请务必确认还有什么已修改或新建的文件还没有 git add 过， 否则提交的时候不会记录这些尚未暂存的变化。 这些已修改但未暂存的文件只会保留在本地磁盘。 所以，每次准备提交前，先用 git status 看下，你所需要的文件是不是都已暂存起来了， 然后再运行提交命令 git commit：$ git commit另外，你也可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行，可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么，以及在本次提交中，有多少文件修订过，多少行添加和删改过。跳过使用暂存区域尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。 Git 提供了一个跳过使用暂存区域的方式， 只要在提交的时候，给 git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤移除文件要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。 可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。如果要删除之前修改过或已经放到暂存区的文件，则必须使用强制删除选项 -f（译注：即 force 的首字母）。 这是一种安全特性，用于防止误删尚未添加到快照的数据，这样的数据不能被 Git 恢复。另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。 换句话说，你想让文件保留在磁盘，但是并不想让 Git 继续跟踪。 当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。 为达到这一目的，使用 --cached 选项：$ git rm --cached READMEgit rm 命令后面可以列出文件或者目录的名字，也可以使用 glob 模式。比如：$ git rm log/\\*.log注意到星号 * 之前的反斜杠 \\， 因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开。 此命令删除 log/ 目录下扩展名为 .log 的所有文件。 类似的比如：$ git rm \\*~该命令会删除所有名字以 ~ 结尾的文件。移动文件不像其它的 VCS 系统，Git 并不显式跟踪文件移动操作。 如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。 不过 Git 非常聪明，它会推断出究竟发生了什么，至于具体是如何做到的，我们稍后再谈。既然如此，当你看到 Git 的 mv 命令时一定会困惑不已。 要在 Git 中对文件改名，可以这么做：$ git mv file_from file_to它会恰如预期般正常工作。 实际上，即便此时查看状态信息，也会明白无误地看到关于重命名操作的说明：$ git mv README.md README$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) renamed: README.md -&gt; README其实，运行 git mv 就相当于运行了下面三条命令：$ mv README.md README$ git rm README.md$ git add README如此分开操作，Git 也会意识到这是一次重命名，所以不管何种方式结果都一样。 两者唯一的区别是，mv 是一条命令而非三条命令，直接用 git mv 方便得多。 不过有时候用其他工具批处理重命名的话，要记得在提交前删除旧的文件名，再添加新的文件名。暂存当前改动$ git stash查看当前已经暂存的内容列表：$ git stash list删除当前暂存列表的指定项（以删除最近一条为例）：$ git stash drop stash@{0}删除所有暂存的内容：$ git stash clear分支相关查看当前本地正在使用的分支列表：$ git branch查看所有分支列表（包括远程分支）:$ git branch -a切换到指定分支：$ git checkout &lt;branchname&gt; 删除本地分支：$ git branch -d &lt;branchname&gt;删除远程分支：$ git push origin --delete &lt;branchname&gt; 新建并切换到一个新的分支上：git checkout -b &lt;branchname&gt;它相当于两条命令的简写：git branch &lt;branchname&gt;git checkout &lt;branchname&gt;推送本地分支到远程并且将远程分支设置为上游分支：git push --set-upstream origin &lt;branchname&gt;Git Commit Message格式规范1&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;// 空一行&lt;body&gt;// 空一行&lt;footer&gt;Header部分只有一行，包括三个字段：type（必需）、scope（可选）和subject（必需）。（1）typetype用于说明 commit 的类别，只允许使用下面7个标识。 feat：新功能（feature） fix：修补bug docs：文档（documentation） style： 格式（不影响代码运行的变动） refactor：重构（即不是新增功能，也不是修改bug的代码变动） test：增加测试 chore：构建过程或辅助工具的变动 在PowerShell中配置Git命令自动补全及显示更多信息 借助官方推荐的工具posh-git实现，按照这些步骤执行完毕之后即可使用相关功能 检查Powershell版本（此工具只能在）pwsh5.x或者pwsh &gt;= v6使用）：$PSVersionTable.PSVersion 检查脚本执行策略（在Windows上，脚本执行策略必须设置为RemoteSigned或Unrestricted）：Get-ExecutionPolicy 设置脚本执行策略（若不是上面提到的两种策略之一）：Set-ExecutionPolicy RemoteSigned -Scope CurrentUser -Confirm 安装posh-git：PowerShellGet\\Install-Module posh-git -Scope CurrentUser -Force（更新：PowerShellGet\\Update-Module posh-git） 引入posh-git模块：Import-Module posh-git（在所有用户以及会话中全局引用posh-git模块：Add-PoshGitToProfile -AllHosts） 检查模块是否成功引入：notepad $profile.CurrentUserAllHosts执行Git命令时排除指定的文件使用:!加文件名，比如：git add . :!FileName1 :!FileName2git difftool :!FileName1 :!FileName2在一台电脑上配置多个SSH key进入SSH key存放目录：cd ~/.ssh创建没有后缀的文件config输入内容(比如这里已经生成了两个私钥文件id_rsa_one和id_rsa_two)：# giteeHost gitee.comHostName gitee.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsa_one# githubHost github.comHostName github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsa_two配置好两个SSH key之后，根据文件夹包含不同的git-config，编辑~/.gitconfig文件内容：[includeIf \"gitdir:**/Github/\"] path = .gitconfig-one[includeIf \"gitdir:**/Kuuga/\"] path = .gitconfig-two其中，.gitconfig-one和.gitconfig-two都是与~/.gitconfig相同目录中的git-config配置文件，使用上面的配置内容，可以使其根据文件夹的不同让不同的配置文件内容被包含到.gitconfig文件(详见https://git-scm.com/docs/git-config#_includes)Github提交记录显示Author为unknown的问题编辑~/.gitconfig文件的内容，添加内容：[user] name = &lt;Github User Name&gt; email = &lt;Github Email&gt;撤销已经reset –hard的commit记录通过git reflog命令可以查看到已经被reset --hard的commit记录，此时就可以使用reset恢复到commit之后的状态获取指定版本的代码git checkout &lt;SHA-1&gt;将git仓库还原到指定版本先使用git reset --hard &lt;SHA&gt;将本地代码退回到想要的版本，然后使用git push -f进行强制push 此部分摘自Commit message 和 Change log 编写指南 - 阮一峰的网络日志 (ruanyifeng.com) &#8617; " }, { "title": "IDEA使用备忘", "url": "/posts/idea-1/", "categories": "编程工具, IDE", "tags": "IntelliJ IDEA", "date": "2020-11-23 00:00:00 +0800", "snippet": " 这里记录一些在使用IDEA的过程中遇到的值得记录的点Debug打断点：Ctrl + F8，或者左键单击代码栏其他操作：在工具栏 - Run - Debugging Actions可以查看格式化代码Ctrl + Alt + L一键格式化代码查看参数提示Ctrl + P快速构建注释输入\\*或者\\**再按回车Evaluate ExpressionAlt + F8快速转换到定义或者实现快速转到定...", "content": " 这里记录一些在使用IDEA的过程中遇到的值得记录的点Debug打断点：Ctrl + F8，或者左键单击代码栏其他操作：在工具栏 - Run - Debugging Actions可以查看格式化代码Ctrl + Alt + L一键格式化代码查看参数提示Ctrl + P快速构建注释输入\\*或者\\**再按回车Evaluate ExpressionAlt + F8快速转换到定义或者实现快速转到定义：Ctrl + F8快速转到实现：Ctrl + Alt + B快速GenerateAlt + Insert，可以快速生成Getter，Setter，toString()等大小写转换Ctrl + Shift + U关闭Inlay Hints在设置栏查找Inlay Hints，选择对应的语言，配置是否显示提示即可" }, { "title": "Identity Server 4原理和实战学习笔记 - OAuth 2.0协议", "url": "/posts/dotnetcore-7/", "categories": "编程框架, ASP.NET Core", "tags": ".NET Core", "date": "2020-11-02 00:00:00 +0800", "snippet": " 学习.NET Core权限认证相关知识，看的是杨旭老师在B站上的教程，先开始了解OAuth 2.0协议什么是OAuth 2.0协议OAuth 2.0协议是一种委托协议，可以让那些控制资源的人允许某个应用代表他们来访问他们控制的资源。这个应用从资源的所有者那里获得授权(Authorization)和access token，随后就可以用这个access token来访问资源这里有两点值得注...", "content": " 学习.NET Core权限认证相关知识，看的是杨旭老师在B站上的教程，先开始了解OAuth 2.0协议什么是OAuth 2.0协议OAuth 2.0协议是一种委托协议，可以让那些控制资源的人允许某个应用代表他们来访问他们控制的资源。这个应用从资源的所有者那里获得授权(Authorization)和access token，随后就可以用这个access token来访问资源这里有两点值得注意的，其一，OAuth 2.0是一种委托协议，什么叫做委托协议呢graph LR;用户--委托--&gt; 客户端应用--访问--&gt;受保护资源委托协议上面的客户端应用可以是WPF，ASP.NET Core MVC等客户端项目，受保护的资源可以是受到保护的ASP.NET Core Web API，当然这里只是举例，主要想说的是对委托协议这个词的解释，一个用户想要访问一些数据资源或者一些功能，必须要使用客户端应用，客户端再去访问这些受保护的资源。这里可以看到，是用户允许了客户端应用去访问这些受保护的资源，客户端代表用户去做这件事情。所以这个代表的过程，也就是委托。注意这里不是假冒或者模仿，什么叫做假冒或者模仿呢，指的是客户端或者应用，复制了一份用户的用户名，密码等凭证，从而获得了相应的授权。在这个过程，用户的用户名，密码等信息就泄露给应用了。而我们在这里说的OAuth 2.0协议是一个委托协议，它不会假冒或者模仿用户，所以客户端并没有得到用户的用户名和密码或其他凭证。这样做是比较合理的，因为有的客户端应用，我们是不一定会信任它的。授权和认证OAuth 2.0协议只是用来做授权的协议，授权的意思就是授予各种应用进行某些操作的权力，它无法做身份认证，身份认证的意思就是让访问的资源知道你是谁，关于这点我们通过OpenId Connect协议实现   授权 认证 协议 OAuth 2.0 OpenId Connect 含义 你能干什么 你是谁 如何进行委托资源所有者(Resource Owner)是如何委派权限给客户端应用(Client)，使其访问受保护的资源(Resource Server)呢，在这里我们就需要一个桥梁，叫做授权服务器(Authorization Server)，其在物理上，可以和我们的资源服务器放到一起，但是通常，是不放在一起的，整个获取数据的过程如图：sequenceDiagram;Client --&gt;&gt; Resource Owner:Authorization RequestResource Owner --&gt;&gt; Client:Authorization GrantClient --&gt;&gt; Authorization Server:Authorization GrantAuthorization Server --&gt;&gt; Client:Access TokenClient --&gt;&gt; Resource Server:Access TokenResource Server --&gt;&gt; Client:Protected Resource流程解释：用户(Resource Owner)在操作客户端软件(Client)的时候，这个软件突然需要访问一个受保护的资源，但是应用程序没有权限，所以应用程序需要先获得这个权限。它可能有两种方式来获得这个权限，其一是从用户处直接获得权限，另外就是让授权服务器(Authorization Server)作为一个中介，客户端软件再间接地获得这个权限。如何获取到权限：想要使用授权服务器这个中介，客户端软件就需要把资源所有者发送到授权服务器。所谓的发送实际上就相当于一个跳转或者重定向，让资源所有者重定向到授权服务器，授权服务器通常会有一个页面，给客户端软件授权，所谓授权，就是授权服务器发布具有特定目的(通常是一部分的功能权限，或者称为Scope，一定范围内的功能)的安全凭据(Access Token)给应用。用户被重定向到资源服务器就可以直接给客户端授权吗，其实还不可以。首先需要进行身份认证，即前面提到过的OpenId Connect协议做的事情授权的类型授权类型(Authorization Grant Type)，首先授权这个过程可以获得一个代表资源所有者权限的凭据，OAuth 2.0中常用的授权类型有： Authorization Code：采用授权服务器作为客户端软件和资源所有者的中介来获取权限，不是直接从资源所有者处获得授权，授权服务器把资源所有者重定向回到应用时，带的这个临时的凭据，就是Authorization Code，或者说授权码，它代表资源所有者委托给客户端应用的权限，通常是通过跳转时前端URL带的参数传回。接着后端使用这个授权码进行客户端身份认证，因为得到的Access Token是直接发送到客户端应用的，不经过资源所有者的浏览器，所以对于ASP.NET Core MVC这种服务器端的Web应用来说是非常适合的，其不会把Aceess Token暴露给包括资源所有者在内的外界角色 Implicit Resource Owner Password Credentials Client Credentials Device Code Refresh Token另外其还定义了一个扩展机制，以便定义其他类型的授权" }, { "title": "SICP课后习题记录", "url": "/posts/foundation-7/", "categories": "编程基础, 程序设计", "tags": "编程基础, SICP", "date": "2020-10-31 00:00:00 +0800", "snippet": " SICP里有很多课后练习题，这里做个记录", "content": " SICP里有很多课后练习题，这里做个记录" }, { "title": "计算机程序的构造和解释 - 程序涉及的基本元素", "url": "/posts/foundation-6/", "categories": "编程基础, 程序设计", "tags": "编程基础, SICP", "date": "2020-10-21 00:00:00 +0800", "snippet": " 这本书是麻省理工学院计算机科学的入门教材，对于看完这本书的目标，前言中是这样描述的：完成了这一科目的学生能对程序涉及的风格要素有一种很好的审美观。他们应该掌握了控制大型系统的复杂性的主要技术。他们应该能够取读50页长的程序，只要该程序是以一种值得模仿的形式写出来的。他们应该知道在什么时候哪些东西不需要取读，哪些东西不需要去理解。他们应该很有把握地去修改一个程序，同时又能保持原来作者的精神...", "content": " 这本书是麻省理工学院计算机科学的入门教材，对于看完这本书的目标，前言中是这样描述的：完成了这一科目的学生能对程序涉及的风格要素有一种很好的审美观。他们应该掌握了控制大型系统的复杂性的主要技术。他们应该能够取读50页长的程序，只要该程序是以一种值得模仿的形式写出来的。他们应该知道在什么时候哪些东西不需要取读，哪些东西不需要去理解。他们应该很有把握地去修改一个程序，同时又能保持原来作者的精神和风格以书中这一段非常出名的文字为起点开始我们的SICP学习之路： 计算机语言并不仅仅是一种让计算机去执行操作的方式，更重要的，它是一种表述有关方法学的思想的新颖的形式化媒介，因此，程序必须写得能够供人们阅读，偶尔地去供计算机执行。其次，我们相信，在这一层次的课程里，最基本的材料并不是特定程序涉及语言的语法，不是高效完成某种功能的巧妙算法，也不是算法的数学分析或者计算机的本质基础，而是一些能够控制大型软件系统的复杂性的技术构造过程抽象在初学程序设计时，我们可以随意试错，而在真实的程序设计中我们则需要极度小心，需要经验和智慧。有时在一个软件中出现的一小点毛病，就可能导致一架飞机或者一座水坝的灾难性损毁，或者一个工业机器人的自我破坏。软件工程大师们能组织好自己的程序，使自己能合理地确信这些程序所产生的计算过程将能完成预期的工作。他们可以事先看到自己系统的行为方式，知道如何去构造程序使得其中出现的意外问题不会导致灾难性的后果，而且，在发生了这种问题时，他们也能排除程序中的错误。设计良好的计算机系统就像设计良好的汽车或者核反应堆一样，具有某种模块化的设计，其中的各个部分都可以独立地构造、替换、排除错误在这本书里面，我们将使用Scheme编程，它是一种Lisp方言(因为Lisp用户社团具有抵制制定这一语言的”官方”定义企图的传统，Lisp以一种试验性的非正式的方式不断演化，以满足用户的需要和实际实现的各种考虑，所以已经形成了一组方言，它们共享着初始语言的大部分特征，也可能有这样或那样的重要差异)，Lisp语言是现今被使用得相对广泛的第二悠久的编程语言(第一是Fortran)，它的名字来自于表处理(List Processing)，其设计是为了提供符号计算的能力，以便能用于解决一些程序设计问题，例如代数表达式的符号微分和积分。它包含了适用于这类目的的一些新数据对象，称为原子和表，这是它与那一时代的所有其他语言之间的最明显的不同之处Lisp并不是一种预留语言，之所以用它作为讨论程序设计的基础是因为这一语言具有许多独有的特征，这些特征使得它称为研究重要程序的设计、构造，以及各种数据结构，并将其关联于支持它们的语言特征的一种极佳媒介。这些特征之中最重要就是：计算过程的Lisp描述本身又可以作为Lisp的数据来表示和操作。程序设计的基本元素一个强有力的程序设计语言，不仅是一种智慧计算机执行任务的方式，它还应该称为一种框架，使我们能够在其中组织自己有关计算过程的思想。这样当我们描述一个语言时，就需要将注意力特别放在这一预言所提供的，能够将简单的认知组合起来形成更复杂认识的方法方面，每一种强有力的语言都为此提供了三种机制： 基本表达形式，用于表示语言所关心的最简单的个体 组合的方法，从较简单的东西出发构造出复合元素的能力 抽象的方法，为符合对象命名，并当作单元去操作的能力表达式开始做程序设计，最简单方式就是去看语言是如何与解释器交互，输出结果的，比如在使用Scheme时，输入一个由数字组成的表达式486，解释器的响应是打印出486可以用表示基本过程的表达形式(例如+或者*)，将表示数的表达式组合起来，形成复合表达式，表示要把这些过程应用于这些数，比如：(+ 137 349)486(- 1000 334)666(* 5 99)495(/ 10 5)2(+ 2.7 10)12.7像这种用一对括号括起一些表达式，形成一个表，用于表示一个过程应用的表达式称为组合式，在表里最左的元素称为运算符，其他元素都称为运算对象。想要得到这种组合式的值，将运算符所刻画的过程应用于那些运算对象即可将运算符放在所有运算对象坐标的形式称为前缀表示，刚开始看到时可能会有些不习惯，这种表达式的有一些优点，其中之一就是它完全适用于可能带有任意个实参的过程，例如：(+ 21 35 12 7)75(* 25 4 12)1000在这里不会出现歧义，因为运算符总是最左边的元素，而整个表达式的范围也由括号界定前缀表示的第二个优点是可以直接扩充，允许组合式嵌套，也就是说，允许组合式的元素本身又是组合式：(+ (* 3 5) (- 10 6))19原则上讲这种深度以及Lisp解释器可以求值的表达式的整体复杂性没有任何限制。倒是我们自己有可能被一些并不很复杂的表达式搞糊涂，例如：(+ (* 3 (+ (* 2 4) (+ 3 5))) (+ (- 10 7) 6))对于这个表达式，解释器可以马上求值出57，但是可以看到，我们一眼求出值没有那么容易，因此，要遵循美观打印的格式规则，即我们平时所说的代码的美观性和可读性，通过将各个运算对象垂直对齐，并添加一些缩进，可以很好地显示出表达式的结构，我们将其写成这样：(+ (* 3 (+ (* 2 4) (+ 3 5))) (+ (- 10 7) 6))命名和环境程序设计语言中一个必不可少的方面是它需要提供一种通过名字去使用计算对象的方式。我们将名字标识符称为变量，它的值也就是它所对应的那个对象在Scheme里，给事物命名通过define(定义)的方式完成，输入：(define size 2)这样解释器就将值2与名字size相关联，我们就可以通过这个名字去引用2了：size2(* 5 size)10define是我们所用的语言里最简单的抽象方法，因为如果每次用到计算得到的对象时都要重复写出它们的细节，是一件很不方便的事情。实际上，构造一个复杂的程序，也就是为了去一步步创建出越来越复杂的计算机对象。解释器使这种逐步的程序构造过程变得方便，让我们可以逐步创建起所需要的名字 - 对象关联。这种特征鼓励人们采用递增的方式去开发和调试程序。我们也可以看到，一个Lisp程序通常总是由一大批相对简单的过程组成的我们将值与符号关联，之后又能提取出这些值，这意味着解释器必须维护某种存储能力。这种存储被称为环境(更精确地说，是全局环境，因为我们以后将看到，一个计算过程中完全可能涉及若干不同环境)组合式的求值为了要把与过程性思维有关的各种问题隔离出来。让我们考虑组合式的求值问题。解释器本身就是按照下面过程工作的。要求值一个组合式，做下面的事情： 求值该组合式的各个子表达式 将作为最左子表达式(运算符)的值的那个过程应用于相应的实际参数，所谓实际参数也就是其他子表达式(运算对象)的值即使是这条简单的规则，也透露出程序设计语言中一个基本的原则，首先，为了对整个表达式求值，我们需要分别对这个表达式的每个元素求值，这是个递归的求值过程在这里应该注意的是，采用递归的思想可以多么简洁地描述深度嵌套的情况，如果不递归，我们需要把这种情况看成相当复杂的计算过程，例如：(* (+ 2 (* 4 6)) (+ 3 5 7))需要将求值规则应用于4个不同的组合式，我们可以用图形来表示这一组合式的求值过程，采用一棵树的形式，把各个运算符和运算对象对应其各个分支，递归就是这样一种处理层次性结构的极强有力的技术。这种”值向上穿行”形式的求值形式更是一类计算过程的一个例子，这种计算过程称为树形积累define是一种特殊形式的求值规则，对(define x 3)的求值并不是将define应用于它的两个实际参数：其中一个是符号x的值，另一个是3。这是因为define的作用就是为x关联一个值(也就是说，(define x 3)并不是一个组合式)。像这样的特殊形式有很多，一般性求值规则(由内部运算符和值或变量组成)的例外称为特殊形式，通常也被称为语法糖复合过程我们已经看到了Lisp里的某些元素，在任何一种强有力的程序设计语言里，肯定也包括这几点： 数和算数运算是基本的数据和过程 组合式的嵌套提供了一种组织起多个操作的方法 定义是一种受限的抽象手段，它为名字关联相应的值现在我们来学习过程定义，这是一种威力更强大的抽象技术，其可以为复合操作提供名字，然后就可以将这一操作作为一个单元使用了比如我们定义一个符合过程，用来计算一个数的平方：(define (square x) (* x x))这一过程表示的是将一个东西乘以它自身的操作，并且将这个求值的过程关联于名字square过程定义的一般形式是：(define (&lt;name&gt; &lt;formal parameters) &lt;body&gt;)接着，我们可以使用它：(square 21)441(square (+ 2 5))49(square (square 3))81我们还可以用square作为基本构件去定义其他过程，比如我们现在基于square来定义\\(x^2+y^2\\)，其表述为：(+ (square x) (square y))我们再用一个过程sum-of-squares来表示上述的过程：(define (sum-of-squares x y))\t(+ (square x) (square y))过程应用的代码模型如果我们用一个过程f来进一步构造上面sum-of-squares的过程：(define (f a))\t(sum-of-squares (+ a 1) (* a 2))假定把基本运算符应用于实参的机制已经在解释器里做好了，对于一个复合过程，过程应用的计算过程是： 将复合过程应用于实际参数，就是在将过程体中的每个形参用相应的实参取代之后，对这一过程体求值比如我们现在对(f 5)求值我们先提取出f的体：(sum-of-squares (+ a 1) (* a 2))然后用实际参数5代换其中的形式参数(sum-of-squares (+ 5 1) (* 5 2))这样，问题就被归约为对另一个组合式的求值，求值这一组合式牵涉三个子问题：必须对其中的运算符求值，以便得到应该去应用的那个过程；还需要求值两个运算对象，以得到过程的实际参数，这里的(+ 5 1)产生6，(* 5 2)产生10，因此我们就需要将sum-of-squares过程用于6和10。用这两个值代换sum-of-squares体中的形式参数x和y，表达式被归约为：(+ (square 6) (square 10))使用square的定义又可以将它归约为：(+ (* 6 6) (* 10 10))通过乘法又能将它进一步归约为：(+ 36 100)最后得到：136上面描述的这种计算过程称为过程应用的代换模型，到目前为止，我们可以将它看作确定过程应用的”意义”的一种模型。但这里还需要强调两点： 代换的作用只是为了帮助我们理解调用中的情况，而不是对解释器实际工作方式的具体描述。通常的解释器都不采用直接操作过程的正文，用值去代换形参的方式去完成对过程调用的求值。在实际中，它们一般采用提供形参的局部环境的方式，产生”代换”的效果 随着本书讨论的进展，我们会接触到关于解释器如何工作的一个又一个模型，并最终在第5章给出一个完整的解释器和一个编译器。这里的代换模型只是这些模型中的第一个——作为形式化地考虑这种求值的起点。从这种简单的不完全的模型出发，随着更细致地检查所考虑的问题，我们将会讨论更复杂的过程应用模型应用序和正则序按照之前给出的有关值的描述，解释器首先对运算符和各个运算对象求值，而后将得到的过程应用于得到的实际参数。之前也提到了，这不是执行求值的唯一可能方式。另一种求值模型是先不求出运算对象的值，直到实际需要它们的值时再去做。在这种求值方式中，我们首先用运算对象表达式去替换形参，直至得到一个只包含基本运算符的表达，然后再去执行求值：(f 5)(sum-of-squares (+ 5 1) (* 5 2))(+ (square (+ 5 1)) (square (* 5 2)))(+ (* (+ 5 1) (+ 5 1)) (* (* 5 2) (* 5 2)))然后进行归约：(+ (* 6 6) (* 10 10))(+ 36 100)136这给出了与前面求值模型同样的结果，但其中的计算过程却是不一样的，可以明显看到，这里对于(+ 5 1)和(* 5 2)的求值各做了两次这种”完全展开而后归约”的求值模型称为正则序求值，与之对应的是现在解释器里实际使用的”先求值参数而后应用”的方式，它称为应用序求值，对那些可以通过替换去模拟，并能产生出合法值的过程应用，正则序和应用序求值将产生出同样的值Lisp采用应用序求值，部分原因在于这样能避免表达式的重复求值，从而提高效率。更重要的是，在超出了可以采用替换方式模拟的过程范围之后，正则序的处理将变得更复杂，不过由于它的一些内在性质，它也能称为很有价值的工具条件表达式和谓词至此我们能定义出的过程的表达能力还非常有限，因为还没办法去做某些推断，而后根据推断的结果去做不同操作。比如计算绝对值，要按照这样的规则：\\(|x|=\\begin{cases}x\\ 如果x&gt;0 \\\\0\\ 如果x=0 \\\\-x\\ 如果x&lt;0\\end{cases}\\)这种结构称为一个分情况分析，在Lisp里，有一种针对这类分情况分析的特殊形式，称为cond：(define (abs x)\t(cond ((&gt; x 0) x) ((= x 0) 0) ((&lt; x 0) (-x)))) 条件表达式的一般性形式为：(cond (&lt;p1&gt; &lt;e1&gt;) (&lt;p2&gt; &lt;e2&gt;) ... (&lt;pn&gt; &lt;en&gt;))在符号cond之后耕者一些称为子句的用括号括起的表达式对偶(&lt;p&gt; &lt;e&gt;)。在每个对偶中的第一个表达式是一个谓词，它的值将被解释成真或者假条件表达式的求值方式是：先求值谓词&lt;p1&gt;，如果它的值是false，就去求值&lt;p2&gt;，如果&lt;p2&gt;的值是false就去求值&lt;p3&gt;。直到发现了某个谓词的值为真为止。此时解释器就返回相应子句中的序列表达式&lt;e&gt;的值，以这个作为政改革条件表达式的值。如果无法找到值为真的&lt;p&gt;，cond的值就没有定义我们用术语谓词指那些返回真或假的过程，也指那种能求出真或者假的值的表达式。求绝对值的过程abs使用了基本谓词&gt;、&lt;、和=，这几个谓词都以两个数为参数，分别检查一个数是否大于、小于或者等于第二个数，并据此分别返回真或者假绝对值函数还有一种写法是：(define (abs x) (cond ((&lt; x 0) (-x)) (else x)))这里的else是一个特殊符号，用在cond的最后一个子句中&lt;p&gt;的位置时，如果该cond前面的所有子句都被跳过，它就会返回最后子句中&lt;e&gt;的值另外一种写法：(define (abs x) (if (&lt; x 0) (- x) x))这里采用的是特殊形式if，它是条件表达式的一种受限形式，适用于分情况分析中只有两种情况的需要。if表达式的一般形式是：(if &lt;predicate&gt; &lt;consequent&gt; &lt;alternative&gt;)在求值一个if表达式时，解释器从求值其&lt;predicate&gt;部分开始，如果&lt;predicate&gt;得到真值，解释器就去求值&lt;consequent&gt;并返回其值，否则它就去求值&lt;alternative&gt;并返回其值除了一批基本谓词如&lt;、=和&gt;之外，还有一些逻辑复合运算符，用来构造出各种复合谓词，最常用的三个复合运算符是：(and &lt;e1&gt; ... &lt;en&gt;)解释器从左到右一个个地求值&lt;e&gt;，如果某个&lt;e&gt;求值得到假，这一and表达式的值就是假，后面的那些&lt;e&gt;也不再求值了。如果前面所有的&lt;e&gt;都求出真值，这一and表达式的值就是最后那个&lt;e&gt;的值(or &lt;e1&gt; ... &lt;en&gt;)解释器从左到右一个个地求值&lt;e&gt;，如果某个&lt;e&gt;求值得到真，or表达式就以这个表达式的值作为值，后面的那些&lt;e&gt;也不再求值了。如果前面所有的&lt;e&gt;都求出假值，这一or表达式的值就是假(not &lt;e&gt;)如果&lt;e&gt;求出的值是假，not表达式的值就是真；否则其值为假注意，and和or都是特殊形式而不是普通的过程，因为它们的子表达式不一定都求值，而not则是一个普通的过程。表示数\\(x\\)的值位于\\(5&lt;x&lt;10\\)之间可以写为：(and (&gt; x 5) (&lt; x 10))定义一个谓词，检测某个数是否大于或者等于另一个数：(define (&gt;= x y) (or (&gt; x y) (= x y)))或者也可以定义为：(define (&gt;= x y) (not (&lt; x y)))实例：采用牛顿法求平方根之前我们讨论的过程都很像常规的数学函数，它们都描述了如何根据一个或者几个参数去确定一个值。然而，在数学的函数和计算机的过程之间有一个重要差异，就是这个过程还必须是有效可行的，所以现在我们来考虑求平方根的问题。我们可以将平方根定义为\\(\\sqrt{x}=那样的y,使得y\\geq0而且y^2=x\\)这就描述了一个完全正统的数学函数，我们可以利用它去判断某个数是否为另一个数的平方根，或者推导出一些有关平方根的一般性事实，但另一方面，这一定义没有描述一个计算过程，因为它确实没有告诉我们，在给定了一个数之后，如何实际地找到这个数的平方根这里的数学函数定义与过程之间的矛盾，是在描述一件事情的特征，与描述如何去做这件事情之间的普遍性差异的一个具体反映。换一种说法，是说明性的知识与行动性的知识之间的差异。在数学里，人们通常关心的是说明性的描述(是什么)，而在计算机科学里，人们则通常关系行动性的描述(怎么做)计算机如何计算出平方根呢？最常用的就是牛顿的逐步逼近方法。即不断对\\(x\\)的平方根\\(y\\)做出猜测，并不断得到更好的猜测：只需要求出\\(y\\)和\\(x/y\\)的平均值(它更接近实际的平方根值)。例如，可以用这种方式去计算2的平方根，假定初始值是1： 猜测 商 平均值 \\(1\\) \\(\\frac{2}{1}=2\\) \\(\\frac{(2+1)}{2}=1.5\\) \\(1.5\\) \\(\\frac{2}{1.5}=1.3333\\) \\(\\frac{(1.3333+1.5)}{2}=1.4167\\) \\(1.4167\\) \\(\\frac{2}{1.4167}=1.4118\\) \\(\\frac{(1.4167+1.4118)}{2}=1.4142\\) \\(1.4142\\) \\(...\\) \\(...\\) 继续这一计算过程，我们就能得到对2的平方根的越来越好的近似值现在，让我们用过程的语言来描述这一计算过程。开始时，我们有一个被开方数的值和一个猜测值，如果这个猜测值已经足够好了，有关工作也就完成了。如果还没有足够好，就重复上述计算过程去改进猜测值，我们把这一整个基本策略写成下面的过程：(define (sqrt-iter guess x) (if (good-enough? guess x) guess (sqrt-iter (improve guess x) x)))改进猜测的方式就是求出它与被开方数除以上一个猜测的平均值：(define (improve guess x) (average guess (/ x guess)))其中(define (average x y) (/ (+ x y) 2))我们还必须说明说明叫做”足够好”。首先我们想到一个办法，将这个猜测的答案的平方与被被开方数只差小于某个实现确定的误差值(这里用了0.001)，于是我们写成(这种方法是有缺点的，之后我们会在练习中来讨论)：(define (good-enough? guess x) (&lt; (abs (- (square guess) x)) 0.001))最后还需要一种方式来启动整个工作，比如用1来作为对任何数的初始猜测值：(define (sqrt x) (sqrt-iter 1.0 x))如果把这些定义都送给解释器，我们就可以使用sqrt了，就像可以使用其他过程一样这个sqrt程序也说明，在用于写纯粹的数值计算程序时，至今已介绍的简单程序设计语言已经足以写出可以在其他语言中写出的任何东西了。即使这一语言中还没有包括任何迭代结构(循环)，只是通过常规的过程调用来实现迭代。过程作为黑箱抽象sqrt是我们用一组手工定义的过程来实现一个计算过程的第一个例子。在这里sqrt-iter的定义是递归的可以看到，对于平方根的计算问题可以自然地分解成若干子问题，每一个都通过一个独立的过程完成，整个sqrt程序可以看做一族过程，它们直接反映了从原问题到子问题的分解。graph TD;sqrt---sqrt-itersqrt-iter---good-enoughsqrt-iter---improvegood-enough---squaregood-enough---absimprove---average这是分解的重要性不仅仅在于它将一个问题分解成了几个部分，最重要的是，分解中的每一个过程完成了一件可以清楚标明的工作，这使它们可以被用作定义其他过程的模块。比如当我们基于square定义过程good-enough?的时候，就是把square看作一个”黑箱”。在这样做的时候，我们无须关注这个过程是如何计算出它的结果的，只需要注意它能计算出平方值的事实。关于平方是如何计算的细节被隐去不提了，可以推迟到后来再考虑。所以如果只看good-enough?过程，与其说square是一个过程，不如说它是一个过程的抽象，即所谓的过程抽象。在这一抽象层次上，任何能计算出平方的过程都同样可以用。一个过程定义应该能隐藏起一些细节。这将使过程的使用者可能不必自己去写这些过程，而是从其他程序员那里作为一个黑箱而接受了它。用户在使用一个过程时，应该不需要去弄清它是如何实现的局部名过程用户不必去关心的实现细节之一，就是在有关的过程里形参的名字，这是由实现者选用的。也就是说，下面两个过程定义应该是无法区分的：(define (square x) (* x x))(define (square y) (* y y))这一原则(过程的意义应该不依赖于其作者为形参所选用的名字)从表面看起来很明显，但其影响却非常深远。最直接的影响是，过程的形参名必须局部于有关的过程体。(define (good-enough? guess x) (&lt; (abs (- (square guess) x)) 0.001))good-enough?作者的意图就是要去确定，函数的第一个参数的平方是否位于第二个参数附近一定的误差范围内。可以看到good-enough?的作者用了guess表示其第一个参数，用x表示第二个参数，而送给square的实际参数就是guess。如果square的作者也用x(上面确实如此)表示参数，那么很显然，good-enough?里的x必须与square里的那个x不同。在过程square运行时，绝不应该影响good-enough?里所用的那个x的值，因为在square完成计算之后，good-enough?里可能还需要用x的值如果参数不是它们所在的过程体里局部的东西，那么square里的x就会与good-enough?里的参数相混淆。如果这样，good-enough?的行为方式就将依赖于我们所用的square的不同版本。这样square也就不是我们所希望的黑箱了过程的形参在过程体扮演着一种非常特殊的角色，在这里，形式参数的具体名字是什么，其实完全没有关系。这样的名字称为约束变量，因此我们说，一个过程的定义约束了它的所有形式参数。如果在一个完整的过程定义里将某个约束变量统一换名，这一过程定义的意义将不会有任何改变。如果一个变量不是被约束的，我们就称它为自由的。一个名字的定义被约束于的那一些表达式的集合被称为这个名字的作用域。在一个过程定义里，被声明为这个过程的形式参数的那些约束变量，就以这个过程的体作为它们的作用域还是用上面的代码举例子，在good-enough?的定义中，guess和x是约束变量，而&lt;、-、abs、和square则是自由的。要想保证good-enough?的意义与我们对guess的x的名字选择无关，只要求它们的名字与&lt;、-、abs、和square都不同就可以了。good-enough?的意义当然与其中的自由变量有关，显然它的意义依赖于(在这一定义之外的)一些事实：要求符号abs是一个过程的名字，该过程能求出一个数的绝对值。如果我们将good-enough?定义里的abs换成cos，就会得到另一个不同的结果了。内部定义和块结构至今才仅仅分离出了一种可用的名字：过程的形式参数是相应过程体里的局部名字。平方根程序还展现出了另一种情况，我们也会希望能控制其中的名字使用。现在这个程序由几个相互分离的过程组成：(define (sqrt x) (sqrt-iter 1.0 x))(define (sqrt-iter guess x) (if (good-enough? guess x) guess (sqrt-iter (improve guess x) x)))(define (good-enough? guess x) (&lt; (abs (- (square guess) x)) 0.001))(define (improve guess x) (average guess (/ x guess)))问题是，在这个程序里只有一个过程对用户是重要的，那就是这里所定义的sqrt确实是sqrt。其他的过程(sqrt-iter、good-enough?和improve)则只会干扰他们的思维，因为他们再也不能定义另一个称为good-enough?的过程作为需要与平方根程序一起使用的其他程序的一部分了，因为现在sqrt需要它。在许多程序员一起构造大系统的时候，这一问题将会变得非常严重。举例来说，在构造一个大型的数值过程库时，许多数值函数都需要计算出一系列的近似值，因此我们就可能希望有一些名字为good-enough?和improve的过程作为其中的辅助过程。由于这些情况，我们也希望将这个种子过程局部化，将它们隐藏到sqrt里面，以使sqrt可以与其他采用 逐步逼近的过程共存，让它们中的每一个都有自己的good-enough?过程。为了使这一方式称为可能，我们要允许一个过程里带有一些内部定义，使它们是局部于这一过程的。例如，在解决平方根问题时，我们可以写：(define (sqrt x) (define (good-enough? guess x) (&lt; (abs (- (square guess) x)) 0.001)) (define (improve guess x) (average guess (/ x guess))) (define (sqrt-iter guess x) (if (good-enough? guess x) guess (sqrt-iter (improve guess x) x))) (sqrt-iter 1.0 x))这种嵌套的定义称为块结构，它是最简单的名字包装问题的一种正确解决方式。实际上，这里还潜藏着一个很好的想法。除了可以将所用的辅助过程定义放到内部，我们还可能简化它们，因为x在sqrt的定义中是受约束的，过程good-enough?、improve和sqrt-iter也都定义在sqrt里面，也就是说，都在x的定义域里。这样，显式地将x在这些过程之间传来传去也就没有必要了。我们可以让x作为内部定义中的自由变量，如下所示。这样，在外围的sqrt被调用时，x由实际参数得到自己的值。这种方式称为词法作用域(define (sqrt x) (define (good-enough? guess) (&lt; (abs (- (square guess) x)) 0.001)) (define (improve guess) (average guess (/ x guess))) (define (sqrt-iter guess) (if (good-enough? guess) guess (sqrt-iter (improve guess)))) (sqrt-iter 1.0))下面将广泛使用这种块结构，以帮助我们将大程序分解成一些容易把握的片段。块结构的思想来自程序设计语言Algol 60，这种结构出现在各种最新的程序设计语言里，是帮助我们组织大程序的结构的一种重要工具过程及其产生的计算我们现在已经考虑了程序设计中的一些要素：使用过许多基本的算数操作，对操作进行组合，通过定义各种复合过程，对复合操作进行抽象。但是，即使是知道了这些，我们还不能说自己理解了如何去编程序。我们现在的情况就像是在学下象棋的过程中的一个阶段，此时已经知道了移动棋子的各种规则，却还不知道典型的开局、战术和策略。就像初学象棋的人们那样，我们还不知道编程领域中各种有用的常见模式，缺少有关各种棋步的价值(值得定义哪些过程)的知识，缺少对所走棋步的后果(执行一个过程的效果)做出预期的经验能够看清所考虑的动作的后果的能力，对于称为程序设计专家是至关重要的，就像这种能力在所有综合性的创造性的活动中的作用一样。想要成为专家，我们就需要学会去看清各种不同种类的过程会产生什么样的计算过程。只有在掌握了这种技能之后，我们才能学会如何去构造可靠的程序，使之能够表现出所需要的行为。一个过程也就是一种模式，它描述了一个计算过程的局部演化方式，描述了这一计算过程中的每个步骤是怎样基于前面的步骤建立起来的。在有了一个刻画过程的过程描述之后，我们当然希望能做出一些有关这一计算过程的整体或全局行为的论断。一般来说这是非常困难的，但我们至少还是可以试着去描述过程演化的一些典型模式在这一节，我们将考察由一些简单过程所产生的计算过程的”形状”，还将研究这些计算过程消耗各种重要计算资源(时间和空间)的速率。这里将要考察的过程都是非常简单的，它们所扮演的角色就像是摄影术中的测试模式，是作为极度简化的摄影模式，而其自身并不是很实际的例子，比如计算\\(6!\\)的线性递归过程(factorial 6)(* 6 (factorial 5))(* 6 (* 5 (factorial 4)))(* 6 (* 5 (* 4 (factorial 3))))(* 6 (* 5 (* 4 (* 3 (factorial 2)))))(* 6 (* 5 (* 4 (* 3 (* 2 (factorial 1))))))(* 6 (* 5 (* 4 (* 3 (* 2 1)))))(* 6 (* 5 (* 4 (* 3 2))))(* 6 (* 5 (* 4 6)))(* 6 (* 5 24))(* 6 120)720线性的递归和迭代首先考虑由下面表达式定义的阶乘函数：\\(n!=n*(n-1)*(n-2)...3*2*1\\)计算阶乘的方式有许多种，一种最简单的方式是利用下述认识：对于一个正整数\\(n\\)，\\(n!\\)就等于\\(n\\)乘以\\((n-1)!\\)从而我们可以把这个认识翻译成一个过程：(define (factorial n) (if (= n 1) 1 (* n (factorial (- n 1)))))利用前面提到过的代换模型，我们可以看到这一过程在计算\\(6!\\)时表现出的行为让我们再用另一种不同的观点来计算阶乘。我们可以将计算阶乘\\(n!\\)的规则描述为：先乘起\\(1\\)和\\(2\\)，而后将得到的结果乘以\\(3\\)，而后再乘以\\(4\\)，这样下去直到达到\\(n\\)。很容易想到，我们需要维持一个变动中的乘积product，以及一个从\\(1\\)到\\(n\\)的计数器counter，这一计算过程可以描述为counter和prodcut的如下变化，从一步到下一步，它们都按照下面规则改变：graph RL;counter*product --&gt; prodcutcounter+1--&gt;counter因此我们又可以将这一描述重构为一个计算阶乘的过程：(define (factorial n) (fact-iter 1 1 n))(define (fact-iter product counter max-count) (if (&gt; counter max-count) product (fact-iter (* counter product) (+ counter 1) max-count)))与前面一样，应用代换模型来查看\\(6!\\)的计算过程：(factorial 6)(fact-iter 1 1 6)(fact-iter 1 2 6)(fact-iter 2 3 6)(fact-iter 6 4 6)(fact-iter 24 5 6)(fact-iter 120 6 6)(fact-iter 720 7 6)720现在对这两个计算过程做一个比较，从一个角度看，它们没有多大差异：两者计算的都是同一个定义域里的同一个数学函数，都需要使用与\\(n\\)正比的步骤数去计算出\\(n!\\)。它们甚至有相同的乘运算序列，得到了同样的部分乘积序列。但另一方面，如果我们考虑这两个计算过程的”形状”，就会发现它们的进展情况大不相同。考虑第一个计算过程。代换模型揭示出一种先逐步展开而后收缩的形状。在展开阶段，这一计算过程构建起一个延迟进行的操作所形成的链条(在这里是一个乘法的链条)，收缩阶段变现为这些运算的实际执行。这种类型的计算过程由一个推迟执行的运算链条刻画，称为一个递归计算过程。要执行这种计算过程，解释器就需要维护好那些以后将要执行的操作的轨迹。在计算阶乘\\(n!\\)时，推迟执行的乘法链条的长度也就是为保存其轨迹需要保存的信息量，这个长度随着\\(n\\)而线性增长(正比于\\(n\\))，就像计算中的步骤数目一样。这样的计算过程称为一个线性递归过程。与之相对应，第二个计算过程里并没有任何增长或者收缩。对于任何一个\\(n\\)，在计算过程中的每一步，在我们需要保存的轨迹里，所有的东西就是变量product、counter和max-count的当前值。我们称这种过程为一个迭代计算过程。一般来说，迭代计算过程就是那种其状态可以用固定数目的状态变量描述的计算过程；与此同时，又存在一套固定的规则，描述了计算过程在从一个状态到下一状态转换时，这些变量的更新方式；还有一个(可能有的)结束检测，它描述这一计算过程应该终止的条件。在计算\\(n!\\)时，所需的计算步骤随着\\(n\\)线性增长，这种过程称为线性迭代过程。从另一个角度来看这两个过程之间的对比。在迭代的情况里，在计算过程中的任何一点，那几个程序变量都提供了有关计算状态的一个完整描述。如果令上述计算在某两个步骤之间停下来，想要重新唤醒这一计算，只需要为解释器提供有关这三个变量的值。而对于递归计算过程而言，这里还存在另外的一些”隐含”信息，它们并未保存在程序变量里，而是由解释器维持着，指明所推迟的运算形成的链条中，”这一计算过程处在何处”。这个链条越长，需要保存的信息也就越多。在比较迭代与递归的时候，我们必须注意，不要搞混递归计算过程和递归过程的概念。当我们说一个过程是递归过程的时候，论述的是一个语法形式上的事实，说明这个过程的定义中(直接或者间接)引用了该过程本身。在说某一计算过程具有某种模式时(例如，线性递归)，我们说的是这一计算过程的进展方式，而不是相应过程书写上的语法形式。当我们说某个递归过程(例如fact-iter)将产生出一个迭代的计算过程时，可能会使人感到不舒服。然而这一计算过程确实是迭代的，因为它的状态能由其中的三个状态变量完全刻画，解释器在执行这一计算过程时，只需要保持这三个变量的轨迹就足够了。区分计算过程和写出来的过程可能使人感到困惑，其中的一个原因在于各种常见语言(包括Ada、Pascal和C)的大部分实现的设计中，对于任何递归过程的解释，所需要消耗的存储量总与过程调用的数目成正比，即使它所描述的计算过程从原理上看是迭代的。作为这一事实的后果，要在这些语言里描述迭代过程，就必须借助特殊的”循环结构”，如do、repeat、until、for和while等等。而Scheme的实现则没有这一缺陷，它将总能在常量空间中执行迭代型计算过程，即使这一计算是用一个递归过程描述的。具有这一特性的实现称为尾递归。有了一尾递归的实现，我们就可以利用常规的过程调用机制表述迭代，这也会使各种复杂的专用迭代结构变成不过是一些语法糖了。树形递归另一种常见计算模式被称为树形递归。作为例子，现在要考虑斐波那契(Fibonacci)数序列的计算，这一序列中的每个数都是前面两个数之和：\\[0,1,1,2,3,5,8,13,21...\\]一般说，斐波那契数由下面规则定义：\\(Fib(n)=\\begin{cases}0\\ 如果n=0\\\\1\\ 如果n=1\\\\Fib(n-1)+Fib(n-2)\\ 否则\\end{cases}\\)我们马上就可以将这个定义翻译为一个计算斐波那契数的递归过程：(define (fib n) (cond ((= n 0) 0) ((= n 1) 1) (else (+ (fib (- n 1)) (fib (- n 2))))))可以看到，为了计算(fib 5)，我们需要计算出(fib 4)和(fib 3)。而为了计算(fib 4)，又需要计算(fib 3)和(fib 2)。这一展开过程看起来像一棵树。每层分裂为两个分支(除了最下面)，反映出对fib过程的每个调用中两次递归调用自身的事实上面的过程作为典型的树形递归具有教育意义，但它却是一种很糟的计算斐波那契数的方法，因为它做了太多的冗余计算。可以看到，重复进行了两次(fib 3)计算。我们可以正， 在这一过程中，计算(fib 1)和(fib 0)的次数(即上面图中树叶的个数)正好是\\(Fib(n+1)\\)证明：首先，要计算\\(Fib(0)\\)，需要计算一次(fib 0)，与之对应的树叶数是\\(Fib(1)=1\\)要计算\\(Fib(1)\\)，需要计算一次fib(1)，与之对应的树叶数是\\(Fib(2)=1\\)要计算\\(Fib(2)\\)，按照我们上面的计算方法，需要计算一次\\(Fib(0)\\)和一次\\(Fib(1)\\)，所以树叶数就是上面两种情况的和，即\\(Fib(1)+Fib(2)=Fin(3)=2\\)要计算\\(Fib(3)\\)，需要计算一次\\(Fib(1)\\)和一次\\(Fib(2)\\)，所以树叶数就是\\(Fib(2)+Fib(3)=Fib(4)=3\\)以此类推可以看到，该过程所用的计算步骤将随着输入增长而指数地增长。在另一方面，其空间需求只是随着输入增长而线性增长。一般来说，树形递归计算过程里所需的步骤数将正比于树中的节点数，其空间需求正比于树的最大深度我们可以规划出一种计算斐波那契数的迭代计算过程，其基本想法就是用一对整数\\(a\\)和\\(b\\)，将它们分别初始化为\\(Fib(1)=1\\)和\\(Fib(0)=0\\)，而后反复地同时使用下面变换规则：\\(\\begin{aligned}&amp;a←a+b\\\\&amp;b←a\\end{aligned}\\)在\\(n\\)此应用了这些变换后，\\(a\\)和\\(b\\)将分别等于\\(Fib(n+1)\\)和\\(Fib(n)\\)。因此，我们可以用下面过程，以迭代方式计算斐波那契数：(define (fib n) (fib-iter 1 0 n))(define (fib-iter a b count) (if (= count 0) b (fib-iter (+ a b) a (- count 1))))计算\\(Fib(n)\\)的这种方法是一个线性迭代。这两种方法在计算中所需的步骤上差异巨大，后一方法相对于\\(n\\)为线性的，前一个增长得像\\(Fib(n)\\)一样快，即使不大的输入也可能造成很大的差异。但是我们也不能说树形递归过程根本没有用。当我们考虑的是在层次结构性的数据上操作，而不是对数操作时，将会发现树形递归计算过程是一种自然的、威力强大的工具。即使是对于数的计算，树形递归计算过程也可能帮助我们理解和设计程序。比如刚刚计算斐波那契数的程序，虽然第一个fib过程远比第二个低效，但它却更加直截了当，基本上就是将斐波那契序列的定义直接翻译为Lisp语言。而要规划出之后的的迭代过程，则需要注意到，这一计算过程可以重新塑造为一个采用三个状态变量的迭代实例：换零钱方式的统计想要得到一个迭代的斐波那契算法需要一点点智慧。与此相对应，现在考虑下面的问题：给了半美元、四分之一美元、10美分、5美分和1美分，将1美元换成零钱，一共有多少种不同方式？或者如果给了任意数量的现金，我们能写出一个程序，计算出所有换零钱方式的种数吗？采用递归过程，这一问题有一种很简单的解法，首先我们考虑按照一定顺序来考虑可用硬币类型种类，那么将现金数\\(a\\)换成n种硬币的不同方式的数目等于： 将现金数\\(a\\)换成除第一种硬币之外的所有其他硬币的不同方式的数目，加上 将现金数\\(a-d\\)换成所有种类的硬币的不同方式数，其中的\\(d\\)是第一种硬币的币值注意这里将零钱分成两组时采用的方式，第一组里完全没有使用第一种硬币，而第二组里都使用了第一种硬币。显然，换成零钱的所有方式数目，就等于完全不用第一种硬币的方式的数目，加上用了第一种硬币的换零钱方式的数目。这样就可以将某个给定现金数的换零钱方式的问题，递归地规约为对更少现金数或者更少种类硬币的同一个问题。如果再让我们考虑： 如果\\(a\\)就是\\(0\\)，算作有\\(1\\)种换零钱的方式 如果\\(a\\)小于\\(0\\)，算作有\\(0\\)种换零钱的方式 如果\\(n\\)是\\(0\\)，应该算作有\\(0\\)种换零钱的方式将这些描述翻译为一个递归过程：(define (count-change amount) (cc amount 5))(define (cc amount kinds-of-coins) (cond ((= amount 0) 1) ((or (&lt; amount 0) (= kinds-of-coins 0)) 0) (else (+ (cc amount (- kinds-of-coins 1)) (cc (- amount (first-denomination kinds-of-coins)) kinds-of-coins)))))(define (first-denomination kinds-of-coins) (cond ((= kinds-of-coins 1) 1) ((= kinds-of-coins 2) 5) ((= kinds-of-coins 3) 10) ((= kinds-of-coins 4) 25) ((= = kinds-of-coins 5) 50)))count-change产生出一个树形的递归计算过程，其中的冗余计算与前面fib的第一种实现类似(时间复杂度较高)，另一方面，如果想设计出一个更好的算法，使其能算出同样结果，就不那么明显了。人们认识到，树形递归计算过程有可能极其低效，但常常很容易描述和理解，这就导致人们提出一个建议，希望能利用这两个最好的东西。人们希望能设计出一种”灵巧编译器”，使之能将一个树形递归的过程翻译为一个能计算出同样结果的更有效的过程。" }, { "title": "Jekyll功能扩展(mermaid,MathJax)", "url": "/posts/jekyll-3/", "categories": "Jekyll相关", "tags": "jekyll", "date": "2020-09-27 00:00:00 +0800", "snippet": " 在使用Jekyll的过程中会用到一些扩展功能，这里把将这些功能添加到自己博客的步骤归纳在这里mermaid流程图首先，mermaid官方文档地址：https://mermaid-js.github.io/mermaid/先在博客文件中添加mermaid.min.js文件(按照官方文档内容，可以在https://unpkg.com/browse/mermaid@8.6.0/获取这个文件)。...", "content": " 在使用Jekyll的过程中会用到一些扩展功能，这里把将这些功能添加到自己博客的步骤归纳在这里mermaid流程图首先，mermaid官方文档地址：https://mermaid-js.github.io/mermaid/先在博客文件中添加mermaid.min.js文件(按照官方文档内容，可以在https://unpkg.com/browse/mermaid@8.6.0/获取这个文件)。接着在博客根目录的_includes/head.html文件中添加对该文件的引用即可，比如我这里将mermaid.min.js放在了/assets/js文件夹，所以这里添加的引用是：&lt;script src=\"/assets/js/mermaid.min.js\"&gt;&lt;/script&gt;然后就可以参照文档内容用mermaid语法绘制各种图了(注意，要用&lt;div class=\"mermaid\"&gt;&lt;div&gt;来包裹)，比如这里写一段：&lt;div class=\"mermaid\"&gt;graph LR\t获取mermaid.min.js --&gt; 引用到博客 --&gt; 使用mermaid语法画图&lt;/div&gt;显示效果：graph LR\t获取mermaid.min.js --&gt; 引用到博客 --&gt; 使用mermaid语法画图其实这里应该有更完美的支持方法，但是这里为了快速有效，就先采用这个方法了支持MathJax数学公式显示1 首先，在博客的config.yml文件中，添加内容： # Build settings markdown: kramdown 然后，在想要支持MathJax的博客上面添加标识： usemathjax: true 最后在博客根目录的_includes/head.html文件中添加引用，这里利用了之前的标识来决定当前页面是否需要支持MathJax &lt;!-- for mathjax support --&gt;{% if page.usemathjax %} &lt;script src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"&gt;&lt;/script&gt; &lt;script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"&gt;&lt;/script&gt;{% endif %}完成上面的步骤之后，我们就可以在添加了标识的博客里面自由使用MathJax为我们带来的公式显示效果了比如这里编写一个勾股定理公式：$$a^2+b^2=c^2$$显示效果：\\[a^2+b^2=c^2\\] 这个具体方法也是参考了网络上其他人的博客以及MathJax官方文档的内容，关于是否使用标识的那一点按自己喜好决定即可 &#8617; " }, { "title": "浅谈WebAssembly", "url": "/posts/webassembly-1/", "categories": "前端知识", "tags": "WebAssembly", "date": "2020-09-21 00:00:00 +0800", "snippet": " WebAssembly作为新的前端标准之一，在前端有着举足轻重的地位，它到底是一种什么技术，它的过去，未来到底是什么样子，在这里做一些总结和介绍，主要介绍思路和相关示例来自于WebAssembly for Web Developers (Google I/O ’19)和Rust, WebAssembly, and the future of Serverless by Steve Kla...", "content": " WebAssembly作为新的前端标准之一，在前端有着举足轻重的地位，它到底是一种什么技术，它的过去，未来到底是什么样子，在这里做一些总结和介绍，主要介绍思路和相关示例来自于WebAssembly for Web Developers (Google I/O ’19)和Rust, WebAssembly, and the future of Serverless by Steve KlabnikWeb前端发展史要了解WebAssembly，就不得不从前端的发展史来讲起。网络的发展是非常漫长的，最开始的时候，我们有了HTML(Tim Berners-Lee和同事Daniel W. Connolly创立于1990 )，可以显示一些静态的文档。但是我们并不满意，所以CSS(Håkon Wium Lie创立于1994)出现了，我们可以给网页添加一些样式。接着，我们想要用一些动作来控制网页，所以JavaScript出现了。graph LR\tHTML--&gt;CSS--&gt;JavaScriptJavaScript说到这里，我们不得不谈论一下JavaScript。Web从来都是野心勃勃的，从纯文本到JavaScript，给了我们无尽的幻想，其发展大大扩展了网络作为一个供我们交互的平台的功能。我们打开电脑，打开浏览器，通过浏览器提供的Web应用和大家进行交流，浏览器就像一个小型的操作系统。一直以来，开发者们穷尽自己的想象力，想把网络推向极限，让我们可以在浏览器上面做更多想做的事情从另一个角度想，实际上，我们现在有那么多的手机端的APP，和各种桌面应用程序，也是因为想象力不够，或者妥协的结果。试想一下，如果所有现有的APP，桌面软件都可以通过Web的形式使用，是否才是网络的最终形态呢，互联网就好像一个USB一样，随时和我们的电脑连接，不需要各种繁琐的安装，注册表，等等一切那么，是什么阻挡了我们的想象力呢，是不思进取的IE，还是一心搞应用商店的苹果？这些都可以算得上是因素之一，但是从技术上来说主要原因，还是性能Javascript ，是1995年Brendan Eich用10天的时间设计出来的，设计这个语言当时只是公司的任务，他也没想到这个语言未来会成为互联网最流行的语言，不然可能会更用心一点设计？Javascript为什么会成功 碰瓷(误)； 设计理念很简单，就是易学易用Javascript的缺点解释型语言，非常慢，随着前端的发展，网页应用越来越复杂，解释型语言在性能方面存在劣势。V8和asm.js随着Google在2008引入了V8引擎，才有了JS现在JIT(Just-in-time)的概念，思想就是，解释型语言，如果要运行多次，肯定就有优化的空间，于是V8就偷偷帮你编译好，在下一次运行的时候，直接执行编译好的代码。但是由于JS动态类型的特点，很多时候反而会造成负优化(JS被编译成错误的字节码，不得不重新编译的情况 )2013年，一个来自Mozilla，也就是那个开发火狐浏览器的公司，发布了asm.js项目，这也是很有野心，也相当成功的尝试之一 asm.js是一个中间语言规范，设计目的是使采用C等编程语言编写的计算机软件可运行为网络应用程序，同时性能特征明显优于标准JavaScript。asm.js通常不直接编写，而是作为一种通过编译器生成的中间语言，该编译器获取C++或其他语言的源代码，然后输出asm.js。例如，提供下列C语言代码：int f(int i) { return i + 1;}Emscripten将输出下列JavaScript代码：function f(i) { i = i|0; return (i + 1)|0;}对人类来说，这些或操作可能是无操作，但是对于编译器来说，这些按位运算符可以说明操作数的类型，并给出整数结果。经过这些转换之后，优化编译器才能提前生成高效的本地代码，保证定义的是32位整数，而不是浮点数(其实不难发现，现在很多人将不同的语言：jsx，ts等编译成js，以此来解决在使用原生js开发的时候可能遇到的问题，js有成为前端汇编语言的趋势，这说法可能有些滑稽，但事实正是在这样发展)。可以看得出，这样的写法很hack，有点像在滥用语义获取整数，而且事实上，只有一小部分代码适用这种优化，但即便如此，js的性能也得到了大幅提升。由于asm.js的诞生，我们有了诸如https://blog.mozilla.org/blog/2014/03/12/mozilla-and-epic-preview-unreal-engine-4-running-in-firefox/z这样的成果，虽然画质在今天看来不算特别好，但仍然是非常了不起的成就，asm.js大幅提高了js的运算能力(画面是通过WebGL来实现的，这是一套JavaScript API，使用它不需要任何插件就能在任何兼容的浏览器上渲染交互式的3D和2D图形，其是OpenGL的一个子集)此时用到的编译器是Emscipten，也是Mozilla做的，当需要一些只能在非Web环境上调用的内容时，比如前面提到的OpenGL，或者fileopen功能等，Emscipten可以用WebGL伪装成OpenGL，也可以通过模拟一个文件系统，使你好像在处理真实的文件(意思是在编译的时候额外编译一些需要使用的文件进去，让执行代码的时候可以读取它们，并不代表可以随意打开本地文件)，几乎相当于是真的模拟了一套POSIX操作系统来让代码运行在Web上 ，而这些代码最开始不是为了Web编写的WebAssemlby所以这次，发展方向改变了，为什么要大费周章用C/C++编译成js，再用JIT去翻译，直接给字节码不好吗？终于有一次，四大浏览器厂商，谷歌、微软、苹果和Mozilla一致决定，不能再这样下去了，从立项开始，花费几年的时间，在2019年的12月5日，W3C宣布，继 HTML、CSS 和 JavaScript 之后，WebAssembly成为 Web 的第四语言，也就是我们今天要谈论的主角当你使用任何语言编写代码并将其编译到WebAssembly时，这些代码会被编译成浏览器可以执行的指令集，然后这些指令集以二进制格式存储到.wasm文件中想象一下，像AutoCAD这样的软件，正在移植到WebAssembly，当你想用它时，可以理解在浏览器上运行它，多么不可思议，另外Unity游戏引擎，还有虚幻引擎，都开始支持WebAssembly，通常这些游戏引擎已经内建了一套抽象，用于编译到PlayStation，XBox或其他游戏平台，现在WebAssembly就可以直接使用这些代码，并且提供所需要的性能，这是在asm.js时期不敢想的还有一个例子，我们做了一个网页，在网页中让用户扫描二维码，并且识别二维码中的内容，识别二维码这个功能(图形检测API)是有些浏览器内置的，当遇到你的浏览器不支持的时候，他们就会把二维码库编译到WebAssembly上，就可以按需加载，实现这一功能，可以看到，通过WebAssembly，我们获得了浏览器本身没有的功能另外还有UI工具包QT宣布，他们现在也支持WebAssembly了https://www.qt.io/qt-examples-for-webassembly当使用C++时，用到的编译器是仍然还是Emscripten，它替代C/C++编译器，不将代码编译成本地机器码，而是直接编译到WebAssembly，大家可能还记得我们在前文提到过它，将C/C++编译成符合asm.js标准的JavaScript代码，这次，Emscripten不用编译成JavaScript，而是直接编译成WebAssembly，此时，有了这一套完整的工具链，我们就能围绕WebAssembly做更多成熟并且令人印象深刻的工具，这也是为什么WebAssembly与C++如此紧密的缘故可能你会说，我就是一个普通的前端开发人员，前端生态已经够让人头大了，我必须要学习C++才能用这个对吗，答案是，No！因为很明显，这两种语言的差别还是挺大的，不从语言的好坏难易来评价，就从编程习惯和思想来说，相差也不是一点。而且即使这两种语言都写得很专业的人，在开发过程中不断切换也是会花费一些成本的，对于Web开发人员来说，更加没有去学习C++的动力了。这样一想，WebAssembly似乎是一个非常小众的技术WebAssembly到底拿来做什么这里我们从两个方面来讨论这个疑惑，首先我们讨论JS应用中微小模块的替换JS生态非常庞大，近些年甚至由于技术栈和一些愿意尝鲜的人的原因，已经出现了很多JS开发的桌面应用，但很明显，不是每个主题和功能的首选都是JavaScript，所以很多时候你可能面临一个问题，你需要库去解决这些问题，你可以在C或者Rust中找到这些答案，但不是在JavaScript中。因此，你要么坐下来编写自己的JavaScript实现，要么通过WebAssembly来使用其他语言的相关实现，比如SQuoosh，这是一个完全在浏览器中运行的图像压缩应用程序，可以在脱机状态下工作，放入图片，然后用不同的编解码器压缩它们，可以从这里观察到不同的编解码器对图片质量产生不同的影响。如果比较了解的话，可以知道现代浏览器已经可以通过Canvas实现这个功能了，但事实证明，实现的效果不尽人意，而且，会受浏览器支持的编解码器的约束，所以一直到很长一段时间，也只有Chrome可以编码为WebP格式，其他浏览器却没有。我们用浏览器搜索，找到了一些使用JS有关的JPEG的编解码器，但是却没有找到专门针对WebP的编码器，所以我们从其他方向查阅了一番，发现C/C++有大量相关编码器，因此，我们选择WebAssembly，将相应的库编译到WebAssembly上，并加载到浏览器中，然后使用我们自己加载的这个编解码器来处理图片，从而完成图像压缩。并且，我们的库提供了更专业或者说更细致化的功能定制，这些显然是浏览器自带的功能不会暴露给我们的。这整个过程的重点是，我们使用了一段旧代码，它绝对不是以Web为目的写的，但是我们还是将它使用在了Web上，并用来改善Web平台具体我们是怎么做的呢，首先我们使用Emscripten来编译这个库，以便之后可以链接到它(注意，图片编解码通常是一个高并发任务，但是由于不论是JS或是WebAssembly都还不支持多线程，所以我们禁用它)， 编译完成后，除了.wasm文件之外，我们还会得到一个.js 桥接代码，用来调用编译好的.wasm文件，这所有的步骤，编译器都会帮你完成另外值得一提的是，这个应用的Resize功能使用的图像缩放算法，实际上是来自于Rust生态，对于Rust程序员来说，可以使用wasm-pack将Rust代码转化为WebAssembly模块，并且生成的文件非常小，在这里比较大小有点有失公平，因为本来它们都是两个不一样的库，但是就平均而言，Rust通常会产生更小的文件，因为Rust没有做任何关于POSIX的文件系统模拟，所以不能在Rust代码中使用文件相关操作(如果想要的话，也可以使用封装好的模块，所以这个功能是可配置的，比较灵活 )从这一整个工具中我们可以看到，我们使用了至少来自两种不同语言的四个不同的库，即使这它们跟Web无关，我们还是在Web上使用了它们，并且工作得很好。所以你看，如果我们在Web平台上发现一个技术上的空白，但是在其它语言已经实现了很多次，你应该想到WebAssembly是一个可能的工具。所以WebAssembly出现的目的，至少到目前为止的目的，不是为了取代JS，而是为了和JS配合，完整Web生态接着让我们关注性能，首先，JavaScript和WebAssembly都有相同的峰值性能，但是在运行已经编译好的比较稳定的代码这点上，使用WebAssembly比Javascript快得多，因为JavaScript是弱类型的，在编译过程中容易出现一些意外情况，是编译器无法捕捉的，并且WebAssembly技术团队正在寻找多线程和SIMD技术的解决方案，由于语言的限制，这些是JavaScript永远无法做到的为了体会什么叫”运行已经编译好的比较稳定的代码”这一点，我们来比较两者的入口Ignition是一个解释器虽然我们不能以偏概全的说机器码永远比解释型语言代码跑得更快，但就大多数情况而言，确实是这样，对于js而言，优化编译器总是只会在最后启动，也就是说只有当JS代码运行的时候才能进行优化，假设编译出来的代码没有包含所有情况，就必须再回到解释器，这被我们称为负优化，有了WebAssembly之后，我们的步骤永远都是从编译器到Turbofan当然这边有一些来自网络的图表数据，来证明相同情况下它们速度的对比，但是我们重点想要说的是，因为js的动态类型特性，导致它速度的不稳定性，而且对于不同的浏览器，其对js的优化可能也不完全相同，在不同浏览器中的表现可能差距很大，而WebAssembly总是能带来我们想要的稳定性，这才是最重要的，这也是我们想说的，最优性能另外，如果前端想要编写WebAssembly程序的话，他们也可以用AssemblyScript，它是完全基于TypeScript语法的，这意味着现有的前端人员也完全不需要学习一门全新的语言来使用WebAssembly他们并不是竞争对手，但是不存在谁取代谁的关系，他们应该协作使用，至少目前是如此Rust带点私心的，让我们谈论一下RustRust：A language empowering everyone to build reliable and efficient software.https://baike.baidu.com/item/Rust%E8%AF%AD%E8%A8%80/9502634?fr=aladdinRust是一种系统级的编程语言，其最早是Mozilla在开发Firefox时用来作为C++的替代品，意在减少语言带来的安全漏洞(大部分来自于内存安全方面，由于错误使用指针)以往在考虑编程语言时，往往要在效率Speed和Safety之间做抉择，以往的编程语言曾经在速度上非常惊人，并且根本不关心安全性，这是因为以前计算机运行缓慢，我们要尽力用完每一部分可以利用的资源微软的CVE(Common Vulnerabilities &amp; Exposures通用漏洞披露)，深蓝色是内存安全相关问题，浅蓝色是所有其它问题，当然这不是针对C/C++，很多高级语言延伸到低级语言以提高速度，所以你还是有很大概率会面对内存安全的问题拿汇编语言来说，汇编太危险了，所以创造了C，其拥有更高的级别，虽然会获得更少的效率上的收益，但是可以增加安全性，让开发者更难编写不正确的程序GC机制让运行时自动为我们完成内存分配和释放相关的工作，但是问题也随之而来，它会让语言的效率降低，所以我们需要在速度和安全性之间进行权衡我们可以选择像Ruby这样很容易安全使用但是效率低下的语言，或者选择相对效率高，但是需要认为考虑很多情况，相对危险的C/C++我们能不能同时拥有两者呢，对于Rust来说，Yes对于Rust来说，权衡的结果是学习起来会更加困难，并且你可能会遇到许多编译器错误，因为编译器非常严格从垃圾收集器，我们得到了一个概念，运行时(浅灰色代表我们自己的代码，深灰色可以看成是运行时代码)，这意味着在程序运行的时候，语言会把实际上没有编写的程序放进程序中，当使用JavaScript的时候，我们用的是V8引擎 Rust 有运行时吗？ 没有像 Java 语言这样典型意义上的运行时。但 Rust 标准库的一部分可以被认为是一个「运行时」，它提供了堆（heap），回溯（backtraces），展开（unwinding）和栈保护（stack guards）。在用户的 main 函数之前只运行很少的初始化代码。Rust 标准库还链接到 C 标准库，执行类似的运行时初始化。 Rust 代码可以在没有标准库的情况下编译，在这种情况下，运行时大概相当于 C。所以很有趣的一点就是，Rust的问题，很多都是编译时候的问题，即使从来没有用过C/C++的人，想编写底层软件，也不会造成那么可怕的后果，所以不难明白，为什么Rust和WebAssembly有着密切的关系了吧。Rust真的非常优秀，作为一名喜欢Rust的程序员，非常希望更多人也来感受Rust带来的安全性和效率WebAssembly的未来随着浏览器的发展，还有WebAssembly生态以及特性(多线程，操作DOM)等不断健壮，我们可以大胆猜测在不久的未来，它会在Web领域占据举足轻重的地位。甚至可以试想，在带宽和电脑性能不断增强的今天，是否以后我们可以不用下载任何其他应用软件，就在浏览器里使用各种WebAssembly编写的工具，甚至直接玩画质更加优秀的游戏呢？这值得期待结尾可能有点草率，哈哈哈，未来趋势这个东西谁也说不好，一个技术未来会不会火也不全取决于它好或者不好，创新性，不可替代性，易用性，所在的生态圈等非常多的因素都会对它未来的发展造成影响。但还是想说，我看好WebAssembly的未来" }, { "title": "五笔输入法学习笔记", "url": "/posts/tips-3/", "categories": "日常技能", "tags": "日常技能", "date": "2020-09-20 00:00:00 +0800", "snippet": " 越来越发现全拼已经适应不了日常的中文打字需要了，所以开始学习五笔输入法，主要学习方式是通过B站的视频五笔简介和原理中国文字发展历史graph LR\t甲骨文 --&gt; 金文 --&gt; 小篆 --&gt; 隶书 --&gt;楷书 --&gt;行书--&gt;草书以上的”甲金篆隶草楷行”七种字体被称为”汉字七体”，经过了6000多年的变化，其演变过程是循序渐进的五笔输入法五笔输入法是1...", "content": " 越来越发现全拼已经适应不了日常的中文打字需要了，所以开始学习五笔输入法，主要学习方式是通过B站的视频五笔简介和原理中国文字发展历史graph LR\t甲骨文 --&gt; 金文 --&gt; 小篆 --&gt; 隶书 --&gt;楷书 --&gt;行书--&gt;草书以上的”甲金篆隶草楷行”七种字体被称为”汉字七体”，经过了6000多年的变化，其演变过程是循序渐进的五笔输入法五笔输入法是1983年王永民发明的一种中文输入法，所以现在我们所说的五笔输入法其实就是”王码五笔”，只是具体到不同的五笔输入法采用了王码的不同版本，它有重码少，简码和词组多，准确度高，便于盲打，输入速度快等优点五笔字型主要分为三个版本：86、98、新世纪，86版使用最广泛，虽然98版和新世纪版拆字更规范，但是因为86版先入为主，使用人数最多，输入法软件也最多，本次学习的版本也主要是基于86五笔来进行的五笔组字原理 汉字都是由笔划或部首组成的，为了输入这些文字，我们把汉字拆成最常用的基本单位，叫做字根，字根可以是汉字的偏旁部首，也可以是部首的一部分，甚至是笔划 取出这些字根后，把它们按照一定的规律分；再把这些字根依据科学原理分配在键盘上 当需要输入汉字时，我们就按照汉字的书写顺序依次按与字根对应的键，组成一个代码；系统根据代码，在五笔输入法的字库中检索出索要的字显示在我们的电脑屏幕上学习五笔需要掌握的知识 知道键盘上每个键对应的字根 学习如何把汉字拆成五笔字根 输入字根对应的字母，必要时键入识别码汉字结构和字根介绍汉字有五种基本结构： 左右型：羽 汉 独 体 树 上下型：泉 字 全 品 复 独体字：本 五 子 已 王 半包围：这 包 同 区 凶 全包围：围 因 困 回 圆五笔中只有三种结构，其中”左右型”和”上下型”和上面一样，3，4，5类型统称”杂合型”汉字有五种基本笔画：横竖撇捺折有几个需要注意的点： 提∈横，点∈捺 土/地 文 左竖钩∈竖 木/条/杀 初左竖钩外任何带拐弯的笔划都是属于折 乙/九/刀/匕/已 有的点的方向是朝左的，不要误认为i是撇 刃/心字根：由几个笔划交叉连接组成的相对不变的结构 字根是组成汉字的基本单元 多数偏旁部首都属于字根 但是有些偏旁部首需要两个及以上字根组成86五笔的字根有130个，如果算上某些字根的变体，约有200个，不要被这个数量所吓到，要有”麻烦一时，方便一世”的观念五笔基础首先，我们要了解几个概念键名汉字(25个)：Q金 W人 E月 R白 T禾 Y言 U立 I水 O火 P之A工 S木 D大 F土 G王 H目 J日 K口 L田X纟C又 V女 B子 N已 M山打法：连续按四次相应的键位介绍：它们是字根图上每个键左上角的黑体字；也是每句口诀的第一个字(X键除外)一级简码(一简，共25个)：Q我 W人 E有 R的 T和 Y主 U产 I不 O为 P这A工 S要 D在 F地 G一 H上 J是 K中 L国X经 C以 V发 B了 N民 M同打法：打一次所在键位，然后按空格介绍：它们是使用频率极高的字，必须记住单笔划：T 丿 Y丶 G一 H丨 N乙介绍：这五个键很重要，是每个区的第一个键，也称单笔画键，在打成字字根时需要用到打法：所在键位*2+LL，然后按空格键成字字根：有相当一部分字根本身就可以被用来作为常用的简单汉字(或偏旁)，它们被称为”成字字根”打法：所在键位+第一笔+第二笔(+最后一笔)特例(这几个字和我们的书写笔划是不一样的)：力(ltn) 乃(etn) 戈(agnt)" }, { "title": "深入理解计算机系统 - 信息的表示和处理", "url": "/posts/foundation-5/", "categories": "编程基础, 操作系统", "tags": "编程基础, 操作系统", "date": "2020-09-15 00:00:00 +0800", "snippet": " 在这一章，我们会了解表示基本数据类型的方法，机器级指令如何操作这样的数据，编译器如何将C程序翻译成这样的指令。接着会研究几种实现处理器的方法，帮助我们更好地了解硬件资源如何被用来执行命令。在深入了解了如何表示和执行应用程序之后，我们将学会一些技巧，用来写出安全、可靠且充分利用计算机资源的程序信息的表示和处理现代计算机存储和处理的信息以二值信号表示。这些二进制数字，或者称为位(bit)，形...", "content": " 在这一章，我们会了解表示基本数据类型的方法，机器级指令如何操作这样的数据，编译器如何将C程序翻译成这样的指令。接着会研究几种实现处理器的方法，帮助我们更好地了解硬件资源如何被用来执行命令。在深入了解了如何表示和执行应用程序之后，我们将学会一些技巧，用来写出安全、可靠且充分利用计算机资源的程序信息的表示和处理现代计算机存储和处理的信息以二值信号表示。这些二进制数字，或者称为位(bit)，形成了数字革命的基础。以前，大家熟悉并使用了1000多年的十进制数字起源于印度，在12世纪被阿拉伯数学家改进，并在13世纪被意大利数学家Leonardo Pisano(更为大家熟知的名字是Fibonacci)带到西方。对于有10个手指的人类，使用十进制表示法是很自然的事情，但是当构造存储和处理信息的机器时，二进制值工作得更好。其可以更容易地被表示、存储和传输，例如可以表示为卡片上有没有孔洞、导线上的高电压或低电压，或者顺时针或逆时针的磁场。对二值信号进行存储和执行计算的电子电路非常简单可靠，制造商能够在一个单独的硅片上集成数百万甚至数十亿个这样的电路。单个的位不是很有用，然而当把位组合在一起，再加上某种解释(interpretation)，就可以赋予它们含义，并用来表示任何有限集合的元素。比如，使用一个二进制数字系统，我们能够用位组来编码非负数。通过标准的字符码，我们能够对文档中的字母和符号进行编码。我们研究三种最重要的数字表示： 无符号(unsigned)编码：表示大于或等于0的数字 补码(two’s-complement)编码：表示有符号整数 浮点数(floating-point)编码：表示实数的科学计数法的以2为基数的版本计算机的表示法是用有限数量的位来对一个数字编码，所以如果结果太大以至不能表示时，某些运算就会溢出(overflow)。例如，32位的int类型不能容纳200*300*400*500的结果浮点运算有不同的数学属性，当其溢出时，会产生特殊的值+∞，由于表示的精度有限，浮点运算是不可结合的，例如，在很多机器上，C表达式\\((3.14+1e20)-1e20\\)求得的值会是0.0，而\\(3.14+(1e20-1e20)\\)求得的值会是3.14这种情况在整数运算中不会出现，因为整数表示的范围虽然小，但是是精确的；而浮点数虽然可以编码较大的数值范围，但是这种表示只是近似的为了使编写的程序能在全部数值范围内正确工作，而且具有可以跨越不同机器、操作系统和编译器组合的可移植性，了解可以表示的数字值的范围、位级表示、算术运算的属性是非常重要的信息存储大多数计算机使用8位的块，或者字节(byte)，作为最小的可寻址的内存单位，而不是访问内存中单独的位。机器级程序将内存视为一个非常大的字节数组，称为虚拟内存(virtual address space)。这个虚拟地址空间只是一个展现给机器级程序的概念性映像，实际的实现结合了动态随机访问存储器(DRAM)、闪存、磁盘存储器、特殊硬件以及操作系统，为程序提供一个看上去统一的字节数组。十六进制表示法一个字节由8位组成。在二进制标识法中，它的值域是00000000 ~ 11111111，看成十进制整数，就是0 ~ 255。两种符号标识发对于描述位模式都不是很方便。二进制标识发太冗长，十进制表示法与位模式的互相转换很麻烦。替代的方法是使用十六进制(hexadecimal)数来表示位模式。十六进制(简写为”hex”)使用数字0 ~ 9以及字符A ~ F来表示16个可能的值。用十六进制来书写，一个字节的值域为00 ~ FF在C语言中，以Ox或OX开头的数字常量常被认为是十六进制的值。字符A ~ F既可以是大写，也可以是小写。例如，我们可以将数字FA1D37B(16进制)写作OxFA1D37B，或者Oxfa1d37b，甚至是大小写混合，在这本书里，是用C表示法来表示十六进制的编写机器级程序的一个常见任务就是在位模式的十进制、二进制和十六进制表示之间人工转换。二进制和十六进制之间的转换比较简单直接，因为可以一次执行一个十六进制数字的转换。比如，一个数字0x173A4C，可以通过展开每个十六进制数字，将其转换成二进制：1:0001 7:0111 3:0011 A:1010 4:0100 C:1100这样就得到了二进制表示：000101110011101001001100反过来，如果给定了一个二进制数字1111001010110110110011，可以通过首先把它分为每4位一组来转换为十六进制。不过要注意，如果总位数不是4的倍数，最左边的一组可以少于4位，前面用0补足11:3 1100:C 1010:A 1101:D 1011:B 0011:3字数据大小每台计算机都有一个字长(word size)，指明指针数据的标称大小(nominal size)。因为虚拟地址是以这样的一个字来编码的，所以字长决定的最重要的系统参数就是虚拟地址空间的最大大小。也就是说，对于以字长为w位的机器而言，虚拟地址的范围为\\(0\\)到\\(2^w-1\\)，程序最多访问\\(2^w\\)个字节最近这些年，出现了大规模从32位字长机器到64位字长机器的迁移。32位字长限制虚拟地址空间位4千兆字节(写作4GB)，而扩展到64位字长使得虚拟地址空间为16EB，大约是\\(1.84*10^{19}\\)字节大多数64位机器也可以运行为32位机器编译的程序，这是一种向后兼容，将程序称为”32位程序”或”64位程序”时，区别在于该程序是如何编译的，而不是其运行的机器类型。为了避免由于依赖”典型”大小和不同编译器设置带来的奇怪行为，ISO C99引入了一类数据类型，其数据大小是固定的，不随编译器和机器设置而变化。其中就有int32_t和int64_t，分别位4个字节和8个字节，使用确定大小的整数类型是程序员准确控制数据表示的最佳途径大部分数据类型都编码为有符号数值，除非有前缀关键字unsigned或对确定大小的数据类型使用了特定的无符号声明。对关键字的顺序以及包括还是省略可选关键字来说，C语言允许存在多种形式，比如，这里所有的声明都是一个意思： unsigned long unsigned long int long unsigned long unsigned int上面的图中还展示了指针(图中使用了一个被声明为类型”char * “的变量)，使用程序的全字长 在C中，任何数据类型T，声明T *p;，表明p是一个指针变量，指向一个类型为T的对象。例如char *p就将一个指针声明为指向一个char类型的变量程序员应该力图使他们的程序在不同的机器和编译器上可移植，可移植的一个方面就是使程序对不同数据类型的确切大小不敏感。许多程序编写都假设为上面图中32位程序的字节分配。随着64位机器的日益普及，在将这些程序移植到新机器上时，比如有许多程序员假设一个声明为int类型的程序对象能被用来存储一个指针。这在大多数32位的机器上能正常功能，但是在一台64位的机器上却会导致问题。寻址和字节顺序对于跨越多字节的程序对象，我们必须建立两个规则：这个对象的地址是什么，以及在内存中如何排列这些字节。在几乎所有机器上，多字节对象都被存储为连续的字节序列，对象的地址为所使用字节中最小的地址。例如，假设一个类型为int的变量x的地址为0x100，也就是说，地址表达式&amp;x的值为0x100。那么，如果x为32位表示，x的4个字节将被存储在内存的0x100、0x101、0x102和0x103位置排列表示一个对象的字节有两个通用的规则，小端法(little endian)和大端法(big endian)，分别表示在内存中按照最低有效字节到最高有效字节顺寻存储和从最高有效字节到最低有效字节的顺序存储。假设变量x的类型位int，位于地址0x100处，它的十六进制值为0x01234567。地址范围0x100 ~ 0x103的字节顺序依赖于机器的类型：在字0x01234567中，高位字节的十六进制位0x01，而低位字节值为0x67大多数Intel兼容机都只用小端模式，另一方面，IBM和Oracle的大多数机器则是按照大端模式操作。许多比较新的微处理器使用的是双端法(bi-endian)，也就是说可以把它们配置成作为打断或者小段的机器运行。实际情况中，一旦选择了特定操作系统，字节顺序就固定了。选择何种字节顺序没有技术上的理由，只要选择了一种规则并且一直遵循，对于哪种字节排序的选择都是任意的。对于大多数应用程序员来说，其机器所使用的字节顺序是完全不可见的。不过有时候，字节顺序会成为问题。在不同类型的机器之间通过网络传送二进制数据时，一个常见的问题是当小端法机器产生的数据被发送到大端法机器或者反过来时，接受程序发现里面的字节成了反序的。为了避免这类问题，网络应用程序的代码编写必须遵守已建立的关于字节顺序的规则，以确保发送方机器将它的内部表示转换成网络标准，而接收方机器则将网络标准转换为它的内部表示当阅读小端法机器生成的机器级程序表示时，经常会将字节按照相反的顺序显示。因为按照小端法，最低有效位在右边，所以会从右边开始排，这值得注意还有一种情况是当编写规避正常的类型系统的程序时。在C语言中，可以通过强制类型转换(cast)或联合(union)来允许一种数据引用一个对象，而这种数据类型与创建这个对象时定义的数据类型不同。虽然很多应用编程都强烈不推荐这种编码技巧，但是它们对系统及编程来说是非常有用的看这段代码：# include &lt;stdio.h&gt;typedef unsigned char *byte_pointer;void show_bytes(byte_pointer start, size_t len){ size_t i; for (i = 0; i &lt; len; i++) printf(\" %.2x\", start[i]); printf(\"\\n\");}void show_int(int x){ show_bytes((byte_pointer) &amp;x, sizeof(int));}void show_float(float x){ show_bytes((byte_pointer) &amp;x, sizeof(float));}void show_pointer(void *x){ show_bytes((byte_pointer) &amp;x, sizeof(void *))}这段代码使用强制类型转换来访问和打印不同程序对象的字节表示。我们用typedef将数据类型byte_pointer定义为一个指向类型为unsigned char的对象的指针。这样一个字节指针引用一个字节序列，每个字节都被认为是一个非负整数。上面的代码中show_bytes函数传入了一个字节序列的地址(传入了字节指针和字节数)，字节数的数据类型是size_t，表示数据结构大小的首选数据类型。show_bytes打印出每个以十六进制表示的字节。C格式化指令%.2x表明整数必须用至少两个数字的十六进制格式输出show_bytes之后的三个函数分别用show_bytes来输出了类型为int、float和void *的C程序对象的字节表示。在调用show_bytes时，传入的是被强制转换为unsigned char *类型的指向它们参数x的指针&amp;x，这种强制类型转换告诉编译器，程序应该把这个指针看成指向一个字节序列，而不是指向一个原始数据类型的对象。然后，这个指针会被看成是对象使用的最低字节地址。注意这里使用了sizeof运算符来确定对象使用的字节数。一般来说，sizeof(T)返回存储一个类型为T的对象锁需要的字节数。使用sizeof而不是固定值，也有利于之后程序的移植。上图是在不同的机器/操作系统调用前面代码的输出结果，可以看到，除了数值类型因为小端法与大端法造成的字节输出顺序的不同之外，指针值也是完全不同的，不同的机器/操作系统使用不同的存储分配规则。另一个值得注意的特性是上面除了Linux 64使用8字节地址之外，其他操作系统都是使用4字节地址。 C语言小技巧：typeof声明提供了一种给数据类型命名的方式。这能极大改善代码的可读性，因为深度嵌套的类型声明很难读懂；·printf(以及fprintf和sprintf)提供了一种打印信息的方式，在第一个参数格式串(format string)里，每个以%开始的字符序列都表示如何格式化下一个参数，比较典型的有%d是输出一个十进制整数，而%c是输出一个字符，其编码由参数给出，指定确定大小数据类型的格式，如int32_t，要更复杂一些，之后会提到 在函数show_bytes中，我们看到指针和数组之间紧密的关系，之后会详细介绍这一点。在代码中，我们还可以看到取地址运算符&amp;，这分别创建了指向三种不同类型的x的指针，在这里三个指针的类型分别为int*、float*和void **(数据类型void *是一种特殊类型的指针，没有相关联的类型信息) 强制类型转换运算符可以将一种数据类型转换为另一种，比如(byte_pointer)&amp;x表明无论指针&amp;x以前是什么类型，它现在就是一个指向数据类型为unsigned char的指针。这里给出的强制类型转换不会改变真实的指针，它们只是告诉编译器以新的数据类型来看代被指向的数据。表示字符串C语言中字符串被编码为一个以null(其值为0)字符结尾的字符数组。每个字符都由某个标准编码来表示，最常见的是ASCII字符码。如果我们以参数\"12345\"(包括终止符)来运行上面的代码，我们得到的结果是31 32 33 34 35 00，注意，十进制数字x的ASCII码正好是0x3x，而终止字节的十六进制表示为0x00。在使用ASCII码作为字符码的任何系统上都得到相同的效果，与字节顺序喝字大小规则无关。所以，文本数据比二进制数据具有更强的平台独立性。布尔代数简介二进制是计算机编码、存储和操作信息的核心。源于1850年前后乔治布尔(George Boole，1815-1864)的工作，产生了丰富的数学知识体系，所以也被称为布尔代数(Boolean algebra)。布尔注意到通过将逻辑值TRUE(真)和FALSE(假)编码为二进制值1和0，能够设计出一种代数，以研究逻辑推理的基本原则。 布尔代数在数字系统的设计和分析中扮演着重要的角色，四个布尔运算符(&amp;，|，^，~)可以扩展到位向量的运算，位向量就是固定长度为w、由0和1组成的串。位向量的运算可以定义成参数的每个对应元素之间的运算。假如a和b分别代表两个长度均为w的位向量，我们将a&amp;b也定义为一个长度为w的位向量，其中第i个元素等于ai&amp;bi，0&lt;=i&lt;w。可以用类似的方式将运算 、^和~扩展到位向量上。 比如w=4，参数a=[0110]，b=[1100]，那么4种运算a&amp;b、a b、a^b和~b分别得到以下结果 这里有一道练习题：答案：10010110、10101010、01000001、01111101、00111100 布尔代数和整数运算有很多相似之处，比如，乘法对加法的分配律，写为a*(b+c)=(a*b)+(a*c)，而布尔运算&amp;对|的分配律，写为a&amp;(b|c)=(a&amp;b)|(a&amp;c)。此外，布尔运算|对&amp;也有分配律，写为a|(b&amp;c)=(a|b)&amp;(a|c) 当考虑长度为w的位向量上的^，&amp;和~运算时，会得到一种不同的数学形式，我们称之为布尔环(Boolean ring)，布尔环与整数运算有很多相同的属性。比如，整数运算的一个属性是每个值x都有一个加法逆元(additive inverse)-x使得x+(-x)=0。布尔环也有类似的属性，这里的”加法”运算是^，不过这时每个元素的加法逆元是它自己本身。也就是说，对于任何值a来说，a^a=0，这里我们用0来表示全0的位向量。可以看到对单个位来说这是成立的，即0^0=1^1=0，将这个扩展到位向量也是成立的。当我们重新排列组合顺序，这个属性也仍然成立，因此有(a^b)^a=b1。这个属性会引起一些很有趣的结果和聪明的技巧，在后面的练习题中会探讨。位向量一个很有用的应用就是表示有限集合。比如我们用位向量a:[01101001]表示集合A={0,3,5,6}，而b:[01010101]表示集合B={0,2,4,6}(注意我们是从位向量的右边往左边看)。使用这种编码集合的方法，布尔运算|和&amp;分别对应于集合的并和交，而~对应集合的补集。比如在前面的例子里，运算a&amp;b得到位向量[01000001]，而A∩B={0，6}，在大量实际应用中，我们都能看到用位向量来对集合编码，在之后也会接触到。这里有一道练习题答案：A.~黑色 = 白色，~红色 = 蓝绿色，~蓝色 = 黄色，~红紫色 = 绿色，反过来也是一样B.蓝色|绿色 = 001|010 = 011 = 蓝绿色，黄色&amp;蓝绿色 = 110&amp;011 = 010 = 绿色，红色^红紫色 = 100^101 = 001 = 蓝色C语言中的位级运算C语言的一个很有用的特性就是它支持按位布尔运算。事实上，我们在布尔运算中使用的那些符号就是C语言所使用的：|就是OR(或)，&amp;就是AND(与)，~就是NOT(取反)，^就是EXCLUSIVE-OR(异或)。这些运算能运用到任何”整型”的数据类型上，这里有一张图，是一些对char数据类型表达式求值的例子：正如图上表示的那样，确定一个位级表达式的结果最好的方法，就是将十六进制的参数扩展成二进制表示并执行二进制运算，然后转换回十六进制这里还有几道练习题：答案：第一步：a a^b第二步：b a^b第三步：b a答案：Ａ.从first是0，last是2k的时候开始循环，一直到first&lt;=last的时候结束，假设到最后first的值为n，则最后n=2k-n的时候结束，所以到最后first和last的值都是kB.因为此时两个数相同，异或运算的结果均为0C.把first&lt;=last改为first&lt;last位级运算的几个常见算法就是实现掩码运算，这里的掩码指的是一个位模式，表示从一个字中选出的位的集合。比如用掩码0xFF表示一个字的低位字节。位级运算x&amp;0xFF生成一个由x的最低有效字节组成的值，其他的字节就被置为0，比如，对于x=0x89ABCDEF，其表达式得到0x000000EF，即我们得到了其最低的八位的值。答案：bis(x,y) bis(bic(x,y),bic(y,x))bis和OR等价，如果x或y对应的位为1，则最后的结果相应的位会是1，所以得到第一个答案，另外，bic(x,m)等价于x&amp;~m，只有当x对应的位为1且m对应的位为0的时候，最后的结果的对应位才等于1，因为x^y等价于(x&amp;~y)|(~x&amp;y)，所以得到第二个答案关于这个答案，首先一定要仔细审题，理解bis和bic指令的作用，然后要理解这些操作的等价关系，特别是对于这里的bic操作，在m为1的每个位置，将z对应的位设置为0，也就是说和上面解释的一样，m对应的位为0且x对应的位不为0，最后的结果的对应位才为1C语言中的逻辑运算C语言还提供了一组逻辑运算符||、&amp;&amp;和!，分别对应命题逻辑中的OR、AND和NOT运算。逻辑运算很容易和位级运算相混淆，但是它们的功能是完全不同的。逻辑运算认为所有非零的参数都表示TRUE，而参数0表示FALSE。它们返回1或者0，分别表示结果为TRUE或者为FALSE。这里是一些示例：可以观察到，按位运算只有在特殊条件下，即参数被限制为0或者1时，才与其对应的逻辑运算有相同的行为。逻辑运算符&amp;&amp;和||与 它们对应的位级运算&amp;和|之间第二个重要的区别是，如果对第一个参数求值就能确定表达式的结果，那么逻辑运算符就不会对第二个参数求值。这里直接做第二题：!(x^y)C语言中的移位运算C语言还提供了一组移位运算，向左或者向右移动位模式。对于一个位表示为\\([x_{w-1},x_{w-2},…,x_0]\\)的操作数\\(x\\)，C表达式x&lt;&lt;k会生成一个值，其位表示为\\([x_{w-k-1},x_{w-k-2},…,x_0,0,…,0]\\)。也就是说，x向左移动k位，丢弃最高的k位，并在右端补k个0。移位量应该是一个0~w-1之间的值。移位运算是从左至右可结合的，所以x&lt;&lt;j&lt;&lt;k等价于(x&lt;&lt;j)&lt;&lt;k有一个相应的右移运算x&gt;&gt;k，但是它的行为有点微妙。一般来说，机器支持两种形式的右移：逻辑右移和算数右移。逻辑右移在左端补k个0，得到的结果是\\([0,…,0,x_{w-1},x_{w-2},…,x_k]\\)。算数右移是在左端补k个最高有效位的值，得到的结果是\\([x_{w-1},…,x_{w-1},x_{w-1},x_{w-2},…,x_k]\\)。这种做法看上去可能有点奇特，但是我们会发现它对有符号整数数据的运算非常有用让我们看一个例子，这个例子对一个8位参数x的两个不同的值做了不同的移位操作：图中斜体数字表示的是因为移位运算而填充的值，可以看到除了算数右移[10010101]时，其他情况填充的值都是0，因为其最高位是1，所以算数右移之后填充的也是1C语言标准没有明确定义有符号数应该使用哪种类型的右移，即算数右移或逻辑右移都可以，所以也意味着可能会出现可以执行问题。在实际情况中，几乎所有的编译器/机器都对有符号数使用算数右移，且虚度哦程序员也都假设机器会使用这种右移。而对于无符号数来说，右移必须是逻辑的。而Java中对右移的具体方式有明确的定义，比如x&gt;&gt;k会将x算数右移k个位置，而x&gt;&gt;&gt;k会对x做逻辑右移 C语言标准小心地规避了当位移量大于等于待移位值的位数的情况，实际上位移量会通过计算k mod w得到，不过这种行为对于C程序来说是没有保证的，所以应该保持位移量小于待移动位值的位数 因为加法(和减法)的优先级比移位运算要高。所以表达式1&lt;&lt;2+3&lt;&lt;4等价于1&lt;&lt;(2+3)&lt;&lt;4，答案是512 思考移位运算的最好方式是使用二进制表示，将最初的值转换为二进制，执行移位运算，然后再转换回十六进制整数表示接着，我们来学习用位来编码整数的两种不同方式：一种只能表示非负数，而另一种能够表示负数、零和正数。后面我们会看到它们在数学属性和机器级实现方面密切相关，并且还会研究扩展或者收缩一个已编码整数以适应不同长度表示的效果。这里会涉及到一些数学术语，用于精确定义和描述计算机如何编码和操作整数，这里先把相关的图放在以便之后参考整数数据类型C语言支持多种整型数据类型——表示有限范围的整数。每种类型都能用关键字来指定大小，这些关键字包括char、short、long，同时还可以指示被表示的数字是非负数(声明为unsigned)，或者可能是负数(默认)。为这些类型分配的字节数根据程序编译为32位还是64位也会有所不同，根据字节分配，不同的大小所能表示的值的范围是不同的。这里唯一一个与机器相关的取值范围是long类型的，大多数64位机器使用8个字节的表示，比32位机器上使用的4个字节的表示的取值范围大很多这里有一个很值得注意的特点是取值范围是不对称的——负数的范围比正数的范围大1，当我们考虑如何考虑负数的时候，会看到为什么会这样C语言标准定义了每种数据类型必须能够表示的最小的取值范围。它们的取值范围和之前图上的典型实现一样或者小一些。除了固定大小的数据类型是例外，我们看到它们只要求正数和负数的取值范围是对称的。另外int可以用2个字节的数字来实现，long可以用4个字节的数字来实现 C和C++都支持有符号(默认)和无符号数。Java只支持有符号数无符号数的编码假设有一个整数数据类型有w位。我们可以将位向量写成\\(\\vec{x}\\)，表示整个向量，或者写成\\([x_{w-1},x_{w-2},…,x_0]\\)，表示向量中的每一位。把\\(\\vec{x}\\)看作一个二进制表示的数，就获得了\\(\\vec{x}\\)的无符号表示。在这个编码中，每个位\\(x_i\\)都取值为0或1，后一种取值意味着数值\\(2^i\\)应为数字值的一部分。我们用一个函数\\(B2U_w\\)(Binary to Unsigned的缩写，长度为w)来表示在这个等式中，符号”≐”表示左边被定义为等于右边。函数\\(B2U_w\\)将一个长度为w的0、1串映射到非负整数，比如下面几种情况：在图中，我们用\\(2^i\\)的指向右侧箭头的条表示每个位的位置i，每个位向量对应的数值都等于所有值为1的位对应的长度之和所以，当这个串的长度为w时的取值范围是在它的内容为全0到全1之间的，也就是整数值\\(UMax_w≐\\sum^{w-1}_{i=0}2^i=2^w-1\\)以4位情况为例，\\(UMax_4=B2U_4([1111])=2^4-1=15\\)。因此，函数\\(B2Uw\\)能够被定义为一个映射\\(B2U_w:\\{0,1\\}^w→\\{0,…,2^w-1\\}\\)无符号的二进制表示有一个很重要的属性，也就是每个介于\\(0\\)到\\(2^w\\)-1之间的数都有唯一一个w位的值编码。例如，十进制值11作为无符号数，只有一个四位的表示，即\\([1011]\\)。我们用数学原理来重点讲述它，先表述原理再解释。原理：无符号数编码的唯一性函数\\(B2U_w\\)是一个双射，所谓双射是一个数学术语，意思是一个函数\\(f\\)有两面：它将数值\\(x\\)映射为数值\\(y\\)，即\\(y=f(x)\\)，但它也可以反向操作，因为对每一个\\(y\\)而言，都有唯一一个数值\\(x\\)使得\\(f(x)=y\\)。这可以用反函数\\(f^{-1}\\)来表示，即\\(x=f^{-1}(y)\\)，在本例中也是如此，函数\\(B2U_w\\)将每一个长度为\\(w\\)的位向量都映射为\\(0\\)到\\(2^w-1\\)之间的一个唯一值；反过来，我们称其为\\(U2B_w\\)(即”无符号数到二进制”)，在\\(0\\)到\\(2^w-1\\)之间的每一个整数都可以映射为一个唯一的长度为\\(w\\)的位模式补码编码对于许多应用，我们还希望表示负数值。最常见的有符号数的计算机表示方法就是补码(two’s-complement)形式。在这个定义中，将字的最高有效位解释为负权(negative weight)。我们用函数\\(B2T_w\\)(Binary to Two’s-complement的缩写，长度为\\(w\\))来表示：原理：补码编码的定义对向量\\(\\vec{x}=[x_{w-1},x_{w-2},…,x_0]\\)：\\[B2T_w(\\vec{x})≐-x_{w-1}2^{w-1}+\\sum^{w-2}_{i=0}x_i2^i\\]最高有效位\\(x_{w-1}\\)也称为符号位，它的”权重”为$-2^{w-1}$，是无符号表示中权重的负数。符号位被设置为1时，表示值为负，而当设置为0时，值为非负。这里来看几个示例：\\[B2T4([0001])=-0*2^3+0*2^2+0*2^1+1*2^0=0+0+0+1=1\\]\\[B2T4([0101])=-0*2^3+1*2^2+0*2^1+1*2^0=0+4+0+1=5\\]\\[B2T4([1011])=-1*2^3+0*2^2+1*2^1+1*2^0=-8+0+2+1=-5\\]\\[B2T4([1111])=-1*2^3+1*2^2+1*2^1+1*2^0=-8+4+2+1=-1\\]从图上可以看出，与一个位向量相关联的数值是由可能的向左指的条和向右直的条加起来决定的可以看到，这张图的位模式和之前展示的无符号整数的位模式是一样的，但是当最高有效位是1时，数值是不同的，这是因为在第一种情况中，最高有效位的权重是+8，而在这里，它的权重是-8所以我们可以想到\\(w\\)位补码所能表示的值的范围。它能表示的最小值是位向量\\([10…0]\\)(也就是设置这个位为负权，但是清楚其他所有的位)，其整数值为\\(TMin_w≐-2^{w-1}\\)。而最大值是位向量\\([01…1]\\)(清除具有负权的位，而设置其他所有的位)，其整数值为\\(TMin_w≐-2^{w-1}\\)，其整数值为\\(TMax_w≐\\sum^{w-2}_{i=0}2^i=2^{w-1}-1\\)。以长度为4为例，我们有\\(TMin_4=B2T_4([1000])=-2^3=-8\\)，而\\(TMax_4=B2T_4([0111])=2^2+2^1+2^0=4+2+1=7\\)我们可以看出\\(B2T_w\\)是一个从长度\\(w\\)的位模式到\\(TMin_w\\)和\\(TMax_w\\)之间的数字的映射，写作\\(B2T_w:{0,1}^w→{TMin_w,…,TMax_w}\\)。同无符号表示一样，在可表示的取值范围内的每个数字都有一个唯一的\\(w\\)位的编码编码。这就导出了与无符号数相似的补码数原理：原理：补码编码的唯一性函数\\(B2T_w\\)是一个双射我们定义函数\\(T2B_w\\)(即”补码到二进制”)作为\\(B2T_w\\)的反函数。也就是说，对于每个数\\(x\\)，满足\\(TMin_w\\leq{x}\\leq{TMax_w}\\)，即\\(T2B_w(x)\\)是\\(x\\)的(唯一的)\\(w\\)位模式观察上图可以发现： 补码的范围是不对称的：$$ TMin = TMax +1\\(，也就是说，\\)TMin$$没有与之对应的正数，这导致了补码运算中某些特殊的属性，并且容易造成程序中细微的错误。之所以有这样的不对称性，是因为一半的位模式(符号位设置为1的数)表示负数，而另一半(符号位设置为0的数)表示非负数。因为0是非负数，也就意味着能表示的整数比负数少一个 最大的无符号数值正好比补码的最大值的两倍大一点：\\(UMax_w=2TMax_w+1\\)。补码表示中所有表示负数的位模式在无符号表示中都编程了正数 \\(-1\\)和\\(UMax\\)有同样的位表示，即一个全1的串，数值0在两种表示方法中都是全0的串C语言标准并没有要求要用补码形式来表示有符号整数，但是几乎所有的机器都是这么做的。程序员如果希望代码具有最大可移植性，能够在所有可能的机器上运行，那么除了上图中的那些范围，我们不应该假设任何可表示的数值范围，也不应该假设有符号数回使用何种特殊的表示方式。另一方面，许多程序的书写都假设用补码来表示有符号数，并且具有上面描述的那些”典型的”取值范围，这些程序也能够在大量的机器和编译器上移植。C库中的文件&lt;limits.h&gt;定义了一组常量来限定编译器运行的这台机器的不同整型数据类型的取值范围。比如，其定义了常量INT_MAX、INT_MIN和UNIT_MAX，它们描述了有符号和无符号整数的范围。对于一个补码的机器，数据类型int有\\(w\\)位，这些常量就对应于\\(TMax_w\\)、\\(TMin_w\\)和\\(UMax_w\\)的值有符号数和无符号数之间的转换C语言允许在各种不同的数字数据类型之间做强制类型转换。例如，假设变量x声明为int，u声明为unsigned。表达式(unsigned)x会将x的值转换成一个无符号数值，而(int)u将u的值转换成一个有符号整数。将有符号整数强制类型转换成无符号数，或者反过来，会得到什么结果呢。很明显，我们是希望这些值保持不变的，可以想象将负数转换成无符号数可能回得到0，如果转换的无符号数太大以至于超出了补码能够表示的范围，可能会得到\\(TMax\\)。不过，对于大多数C语言的实现来说，对这个问题的回答都是从位级角度来看的，而不是数的角度比如说，考虑下面的代码：short int v = -12345;unsigned short uv = (unsigned short)v;printf(\"v = %d, uv = %u\\n\", v, uv);在一台使用补码的机器上，上述代码会产生如下输入：v = -12345, uv = 53191我们看到，强制类型转换的结果保持位值不变，只是改变了解释这些位的方式。-12345的16位补码表示与53191的16位无符号表示是完全一样的。将short强制类型转换为unsigned short改变数值，但是不改变位表示。类似地，考虑这段代码：unsigned u = 4294967295u; /* UMax */int tu = (int)u;printf(\"u = %u, tu = %d\\n\", u, tu);在一台采用补码的机器上，会产生如下输出：u = 4294967295, tu = -1因为对于32位字长来说，无符号形式的4294967295(\\(UMax_{32}\\))和补码形式的-1的位模式是完全一样的。将unsigned强制类型转换成int，底层的位表示保持不变。对于打输出C语言的实现，处理同样字长的有符号数和无符号数之间相互转换的一般规则是：数值可能会改变，但是位模式不变。可以用更数学化的方法表示：\\(T2U_w(x)≐B2U_w(T2B_w(x))\\)和\\(U2T_w(x)≐B2T_w(U2B_w(x))\\)都是成立的通过前面的所有例子，我们还可以看到，位模式相同的补码与无符号数之间的关系可以表示为函数\\(T2U\\)的一个属性：原理：补码转换为无符号数对满足\\(TMin_w\\leq{x}\\leq{TMax_w}\\)的\\(x\\)有：\\[T2U_w(x)=\\begin{cases}x+2^w,x&lt;0\\\\x,x\\geq0\\end{cases}\\]比如，我们看到\\(T2U_{16}(-12345)=-12345+2^{16}=53191\\)，\\(T2U_w(-1)=-1+2^w=UMax_w\\)推导过程：补码转换为无符号数因为对于位模式\\(\\vec{x}\\)，如果我们计算\\(B2U_w(\\vec{x})-B2T_w\\vec{(x)}\\)的差，从0到w-2的位的加权和互相抵消掉，剩下一个值：\\[B2U_w(\\vec{x})-B2T_w(\\vec{x})=x_{w-1}(2^{w-1}-(-2^{w-1}))=x_{w-1}2^w\\]这就得到一个关系：\\(B2U_w(\\vec{x})=x_{w-1}2^w+B2T_w(\\vec{x})\\)，因此就有：\\[B2U_w(T2B_w(x))=T2U_w(x)=x+x_{w-1}2^w\\]如何理解上面两个式子的关系呢，首先\\(T2B_w(x)\\)把当前补码数转换成二进制表示，再通过\\(B2U_w(\\vec{x})\\)转换成无符号整数，所以这里的\\(B2U_w(T2B_w(x))\\)和\\(B2U_w(\\vec{x})\\)是等效的，即从补码数到无符号数的转换操作\\(T2U_w(x)\\)。再根据上面的关系\\(B2U_w(\\vec{x})=x_{w-1}2^w+B2T_w(\\vec{x})\\)，现在\\(B2T_w(\\vec{x})\\)的值就是\\(x\\)，所以推导出了最后的公式这张图说明了函数\\(T2U\\)的一般行为，当将一个有符号数映射为相应的无符号数时，负数会被转换成大的正数，非负数会保持不变接着，我们来考虑将一个无符号数转换为补码原理：无符号数转换为补码对满足\\(0\\leq{u}\\leq{UMax_w}\\)的\\(u\\)有：\\(U2T_w(u)=\\begin{cases}u,u\\leq{TMax_w}\\\\u-2^w,u&gt;TMax_w\\end{cases}\\)该原理证明如下：推导：无符号数转换为补码设\\(\\vec{u}=U2B_w(u)\\)，并且这个位向量也是\\(U2T_w{u}\\)的补码表示，根据无符号数编码和补码编码的定义，即\\(B2U_w(\\vec{x})≐\\sum^{w-1}_{i=0}x_i2^i\\)和\\(B2T_w(\\vec{x})≐-x_{w-1}2^{w-1}+\\sum^{w-2}_{i=0}x_i2^i\\)我们将其结合起来，所以得到了\\(U2T_w(u)=-u_{w-1}2^w+u\\)可以看到，位\\(u_{w-1}\\)决定了\\(u\\)是否大于\\(TMax_w=2^{w-1}-1\\)总结：当\\(0\\leq{x}\\leq{TMax_w}\\)之内的值\\(x\\)而言，我们得到\\(T2U_w{x}=x\\)和\\(U2T_w{x}=x\\)，即在这个范围内的数字的无符号和补码表示的值是相同的。在这个范围以外的数值，转换需要加上或者减去\\(2^w\\)C语言中的有符号数与无符号数尽管C语言标准没有指定有符号数要采用某种表示，但是几乎所有的机器都使用补码。通常，大多数数字都默认为是有符号的。例如，声明一个像12345或者0x1A2B这样的常量时，这个值就被认为是有符号的。加上后缀字符U或者u，例如12345U或0x1A2BuC语言允许无符号数有符号数的转换，虽然C标准没有精确规定要如何进行这种转换，但大多数系统遵循的原则是底层的位表示不变。即之前提到过的那些函数的规则(\\(U2T_w\\)，\\(T2U_w\\)等)显式的强制类型转换会导致转换发生，比如：int tx, ty;unsigned ux, uy;tx = (int) ux;uy = (unsigned) ty;另外，当一种类型的表达式被赋值给另一种类型的变量时，转换是隐式的，比如：int tx, ty;unsigned ux, uy;tx = ux; /* Cast to signed */uy = ty; /* Cast to unsigned */当用printf输出数值时，用指示符%d、%u和%x以有符号十进制、无符号十进制和十六进制格式输出一个数字。注意其可以用指示符%u来输出类型为int的数值，也可以用指示符%d输出类型为unsigned的数值，比如：int x = -1;unsigned u = 2147483648; /* 2 to the 31st */printf(\"x = %u = %d\\n\", x, x);printf(\"u = %u = %d\\n\", u, u);在一个32位机器上运行时，其输出：x = 4294967295 = -1u = 2147483648 = -2147483648提示：结合前面的函数\\(T2U_w(x)=x+x_{w-1}2^w\\)，所以\\(T2U_{32}(-1)=-1+2^{32}=UMax_{32}\\)\\(U2T_w(u)=-u_{w-1}2^w+u\\)，所以\\(U2T_{32}(2^{31})=-2^{32}+2^{31}=-2^{31}=TMin_{32}\\)由于C语言同时包含有符号和无符号数表达式的处理方式，所以会出现一些奇特的行为。当执行一个运算时，如果它的一个运算数是有符号的而另一个是无符号的，那么C语言会隐式地将有符号参数强制类型转换为无符号数，并假设这两个数都是非负的，来执行这个运算。这里的运算主要是说的对于像&lt;和&gt;这样的关系运算符，可以看这张图，由于发生了隐式转换，所以会产生没那么直观的结果：注意：这里为什么没有直接用\\(-2147483648\\)或者\\(0x80000000\\)来表示\\(TMin_{32}\\)呢，这是由于补码的不对称性和C语言的转换规则之间奇怪的交互。虽然理解这个问题需要我们去关注C语言标准的一些比较隐晦的角落，但是它能帮助我们充分领会整数数据类型及其表示的一些细微之处扩展一个数字的位表示一个常见的操作是要在不同字长的整数之间做转换，同时又保持数值不变。当目标数据类型太小，以至于根本表示不了想要的值时，这根本就是不可能的，而从一个较小的数据类型转换到一个较大的类型时，应该总是可能的。要将一个无符号数转换成一个更大的数据类型，只需要简单地在表示的开头添加0，这种运算被称为零扩展(zero extension)原理：无符号数的零扩展定义宽度为\\(w\\)的位向量\\(\\vec{u}=[u_{w-1},u_{w-2},…,u_0]\\)以及宽度为\\(w^′\\)的位向量\\(\\vec{u′}=[0,…,0,u_{w-1},u_{w-2},…,u_0]\\)，其中\\(w′&gt;w\\)。则\\(B2U_w(\\vec{u})=B2U_{w′}(\\vec{u′})\\)这个原理相当于是直接遵循了无符号数编码定义的结果要将一个补码数字转换成一个更大的数据类型，可以执行一个符号扩展(sign extension)，在表示中添加最高有效位的值，表示为如下原理：原理：补码数的符号扩展定义宽度为\\(w\\)的位向量\\(\\vec{x}=[x_{w-1},x_{w-2},…,x_0]\\)和宽度为\\(w\\)的位向量\\(\\vec{x′}=[x_{w-1},…,x_{w-1},x_{w-1},x_{w-2},…,x_0]\\)，其中\\(w′&gt;w\\)。则\\(B2T_w(\\vec{x})=B2T_{w′}(\\vec{x′})\\)例如这段代码：short sx = -12345; /* -12345 */unsigned short usx = sx; /* 53191 */int x = sx; /* -12345 */unsigned ux = usx; /* 53191 */printf(\"sx = %d:\\t\", sx);show_bytes((byte_pointer) &amp;sx, sizeof(short));printf(\"usx = %u:\\t\", usx);show_bytes((byte_pointer) &amp;usx, sizeof(unsigned short));printf(\"x = %d:\\t\", x);show_bytes((byte_pointer) &amp;x, sizeof(int));printf(\"ux = %u:\\t\", ux);show_bytes((byte_pointer) &amp;ux, sizeof(unsigned));在采用补码表示的32位大端法机器上运行这段代码，输出：sx = -12345: cf c7usx = 53191: cf c7x = -12345: ff ff cf c7ux = 53191: 00 00 cf c7可以看到，尽管\\(-12345\\)的补码表示和\\(53191\\)的无符号表示在16位字长是相同的，但是在32位字长时却是不同的。比如这里\\(-12345\\)的十六进制表示为\\(0xFFFFCFC7\\)，而\\(53191\\)的十进制表示为\\(0x0000CFC7\\)。前者使用的是符号扩展，即最开头加了16位，都是最高有效位1，表示为十六进制就是\\(0xFFFF\\)。后者开头使用16个0来扩展，表示为十六进制就是\\(0x0000\\)比如一个位向量\\([101]\\)表示值\\(-4+1=-3\\)。对其应用符号扩展，得到位向量\\([1101]\\)，表示的值\\(-8+4+1=-3\\)。我们可以看到，对于\\(w=4\\)，最高两位的组合值是\\(-8+4=-4\\)，与\\(w=3\\)时符号位的值相同。类似地，位向量\\([111]\\)和\\([1111]\\)都表示值\\(-1\\)有了这个直觉，我们现在可以展示保持补码值的符号扩展推导：补码数值的符号扩展令\\(w′=w+k\\)，我们想要证明的是\\[B2T_{w+k}([x_{w-1},x_{w-1},x_{w-2},…,x_0])=B2T_w([x_{w-1},x_{w-2},…,x_0])\\]如果我们能证明符号扩展一位保持了数值不变，那么符号扩展任意位都能保持这种属性。因此，证明的任务就变为了：\\[B2T_{w+1}([x_{w-1},x_{w-1},x_{w-2},…,x_0])=B2T_w([x_{w-1},x_{w-2},…,x_0])\\]根据补码编码的定义展开左边的表达式，得到：\\[\\begin{aligned}B2T_{w+1}([x_{w-1},x_{w-1},x_{w-2},…,x_0])&amp;=-x_{w-1}2^w+\\sum^{w-1}_{i=0}x_i2^i\\\\&amp;=-x_{w-1}2^w+x_{w-1}2^{w-1}+\\sum^{w-2}_{i=0}x_i2^i\\\\&amp;=-x_{w-1}(2^w-2^{w-1})+\\sum^{w-2}_{i=0}x_i2^i\\\\&amp;=-x_{w-1}2^{w-1}+\\sum^{w-2}_{i=0}x_i2^i\\\\&amp;=B2T_w([x_{w-1,x_{w-2},…,x_0}])\\end{aligned}\\]从上面的推算过程可以看出，有没有新加的位，得到的结果都是相同的，运算的结果会得到相同的数值截断数字假设我们不用额外的位来扩展一个数值，而是减少表示一个数字的位数。例如下面代码中这种情况：int x = 53191;short sx = (short) x; /* -12345 */int y = sx;当我们把x强制类型转换为short时，我们就将32位的int截断为了16位的short int。就像前面看到的，这个16位的位模式就是-12346的补码表示。当我们把其强制转换为int时，符号扩展把高16位设置为1，从而生成-12345的32位补码表示当将一个\\(w\\)位的数\\(\\vec{x}=[x_{w-1},x_{w-2},…,x_0]\\)截断为一个k位数字时，我们会丢弃掉高w-k位，得到一个位向量\\(\\vec{x′}=[x_{k-1}，x_{k-2},…,x_0]\\)。截断一个数字可能会改变它的值，这是溢出的一种形式，对于一个无符号数，我们可以很容易得出其数值结果原理：截断无符号数令\\(\\vec{x}\\)等于位向量\\([x_{w-1,x_{w-2},…,x_0}]\\)，而\\(\\vec{x′}\\)是将其截断为k位的结果：\\(\\vec{x′}=[x_{k-1},x_{k-2},…,x_0]\\)。令\\(x=B2U_w(\\vec{x})\\)，\\(x′=B2U_k(\\vec{x′})\\)，则\\(x′=xmod 2^k\\)该原理背后的直觉是所有被截取的位其权重形式都是\\(2^i\\)，其中$i\\geq{k}$，因此，每一个权在取模操作下结果都为零推导：截断无符号数\\[\\begin{aligned}B2U_w([x_{w-1},x_{x-2},…,x_0]) mod 2^k&amp;=[\\sum^{w-1}_{i=0}x_i2^i]mod2^k\\\\&amp;=[\\sum^{k-1}_{i=0}x_i2^i]mod2^k\\\\&amp;=\\sum^{k-1}_{i=0}x_i2^i\\\\&amp;=B2U_k([x_{k-1},x_{k-2},…,x_0])\\end{aligned}\\]这段推导主要利用了属性：对于任何\\(i\\geq{k}\\)，\\(2^imod2^k=0\\)补码截断也具有相似的属性，只不过要将最高位转换为符号位：原理：截断补码数值因为之前得到了无符号数截断的公式，所以现在将其转换为补码即可，则补码数字的截断结果是：\\[B2T_k[x_{k-1},x_{k-2},…,x_o]=U2T_k(B2U_w([x_{w-1},x_{w-2},…,x_o])mod2^k)\\]关于有符号数与无符号数的建议可以看到，有符号数到无符号数的强制类型转换导致了某些非直观的行为。这些非直观的特性经常导致程序错误，并且这种包含隐式强制类型转换的细微差别的错误很难被发现。因为这种强制转换是在代码中没有明确指示的时候发生的，程序员经常忽视了它的影响这边来看两道题：首先我们在之前了解到执行一个运算时，如果它的一个运算数是有符号的而另一个是无符号的，那么C语言会隐式地将有符号参数强制类型转换为无符号数，并假设这两个数都是非负的，来执行这个运算。所以这里当length为0时，把length-1看成无符号的0加上有符号的-1，又因为我们知道补码转换成有符号数的转换公式是\\(T2U_w(x)=x+x_{w-1}2^w\\)，所以这里的结果相当于\\(-1+1×2^{32}=4,294,967,295\\)，所以会遇到错误，这里有很多种改法，只要避免了这种情况就行了，比如在这里先判断length的值，如果等于0，直接return resultA. 在strlen(t)大于strlen(s)时会出现步正确的结果B. 因为两个无符号数相减，最后的结果也是无符号数，而此时本来应该输出一个负数，所以这里会用得到相应补码数对应的无符号数，答案会不直观C. 改成直接比较，把return strlen(s) - strlen(t) &gt; 0;改成return strlen(s) &gt; strlen(t)整数运算许多刚入门的程序员会惊奇地发现，两个正数相加会得出一个负数，而比较表达式\\(x&lt;y\\)和比较表达式\\(x-y&lt;0\\)会产生不同的结果。这是由于计算机运算的有限性造成的。理解计算机运算的细微之处可以帮助程序员编写更可靠的代码无符号加法考虑两个非负整数\\(x\\)和\\(y\\)，满足\\(0\\leq{x},y&lt;2^w\\)。每个数都能表示为\\(w\\)位无符号数字。如果计算它们的和，我们就有一个可能的范围\\(0\\leq{x+y}\\leq2^{w+1}-2\\)。表示这个和可能需要\\(w+1\\)位。例如，这张图展示了当\\(x\\)和\\(y\\)有4位表示时，函数\\(x+y\\)的坐标图。可以看出参数(显示在水平轴上)取值范围为0到15，但是和的取值范围0到30。函数的形状是一个有坡度的平面(在两个维度上，函数都是线性的)，如果保持和为一个\\(w+1\\)位的数字，并且把它加上另外一个数值，我们可能需要\\(w+2\\)个位，以此类推。这种持续的”字长膨胀”意味着，想要完整表示算数运算的结果，我们不能对字长做任何限制。一些编程语言，例如Lisp，就支持无限精度的运算，允许任意的(当然，要在机器的内存限制之内)整数运算。更常见的是，编程语言支持固定精度的运算，因此像”加法”和”乘法”这样的运算不同于它们在整数上的相应运算。让我们为参数\\(x\\)和参数\\(y\\)定义运算\\(+^u_w\\)，其中\\(0\\leq{x},y&lt;2^w\\)，该操作是把整数和\\(x+y\\)截断为\\(w\\)位得到的结果，再把这个结果看作是一个无符号数。这可以被视为一种形式的模运算，对\\(x+y\\)的位级表示，简单丢弃任何权重大于\\(2^{w-1}\\)的位就可以计算出和模\\(2^w\\)。比如，考虑一个4位数字表示，\\(x=9\\)和\\(y=12\\)的位表示分别为\\([1001]\\)和\\([1100]\\)，它们的和是21，5位的表示为\\([10101]\\)。但是如果舍弃最高位，我们就得到\\([0101]\\)，也就是说，十进制值的5。这就和值\\(21mod16=5\\)一致我们可以将操作\\(+^u_w\\)描述为：原理：无符号数加法对满足\\(0\\leq{x},y&lt;2^w\\)的\\(x\\)和\\(y\\)有：\\(x+^u_wy=\\begin{cases}x+y,x+y&lt;2^w 正常\\\\x+y-2^w,2^w\\leq{x+y}&lt;2^{w+1}溢出\\end{cases}\\)推导：无符号数加法一般而言，我们可以看到，如果\\(x+y&lt;2^w\\)，和的\\(w+1\\)位标识中的最高位会等于0，因此丢弃它不会改变这个数值。另一方面，如果\\(2^w\\leq{x+y}&lt;2^{w+1}\\)，和的\\(w+1\\)位表示中的最高位会等于1，因此丢弃它就相当于从和中减去了\\(2^w\\)说一个算数运算溢出，是指完整的整数结果不能放到数据类型的字长限制中去。如图展示了字长\\(w=4\\)的无符号加法函数的坐标图。这个和是按模\\(2^4=16\\)计算的。当\\(x+y&lt;16\\)时，没有溢出，并且\\(x+^u_4y\\)就是\\(x+y\\)。这对应图中标记为”正常”的斜面。当\\(x+y\\geq{16}\\)时，加法溢出，结果相当于从和中减去16。这对应图中标记为”溢出”的斜面当执行C程序时，不会将溢出作为错误而发信号。不过有的时候，我们可能希望判定是否发生了溢出。原理：检测无符号数加法中的溢出对在范围\\(0\\leq{x},y\\leq{UMax_w}\\)中的\\(x\\)和\\(y\\)，令\\(s\\doteq{x}+^u_wy\\)。则对计算\\(s\\)，当且仅当\\(s&lt;x\\)或者\\(s&lt;y\\)时，发生了溢出作为说明，我们可以看到\\(9+^u_412=5\\)。由于\\(5&lt;9\\)，我们可以看出发生了溢出。推导：检测无符号数加法中的溢出通过观察发现\\(x+y\\geq{x}\\)，所以如果\\(s\\)没有溢出，我们能够肯定\\(s\\geq{x}\\)。另一方面，如果\\(s\\)确实溢出了，我们就有\\(s=x+y-2^w\\)。假设\\(y&lt;2^w\\)，我们就有\\(y-2^w&lt;0\\)，因此\\(s=x+(y-2^w)&lt;x\\)模数加法形成了一种数学结构，称为阿贝尔群(Abelian group)，这是以丹麦数学家Niels Henrik Abel(1802~1829)的名字命名。它是可交换的(这就是叫”abelian”的原因)和可结合的。它有一个单位元0，并且每个元素有一个加法逆元。让我们考虑\\(w\\)位的无符号数的集合，执行加法运算\\(+^u_w\\)，对于每个值\\(x\\)，必然有某个值\\(-^u_wx\\)满足\\(-^u_wx+^u_wx=0\\)，该加法的逆操作可以表述如下：原理：无符号数求反对满足\\(0\\leq{x}&lt;2^w\\)的任意\\(x\\)，其\\(w\\)位的无符号逆元\\(-^u_wx\\)由这个式子给出：\\(-^u_wx=\\begin{cases}x,x=0\\\\2^w-x,x&gt;0\\end{cases}\\)该结果可以很容易地通过案例分析推导出来：推导：无符号数求反当\\(x=0\\)时，加法逆元显然是0。对于\\(x&gt;0\\)，考虑值\\(2^w-x\\)。我们观察到这个数字在\\(0&lt;2^w-x&lt;2^w\\)范围之内，并且\\((x+2^w-x)mod2^w=2^wmod2^w=0\\)。因此，它就是\\(x\\)在\\(+^u_w\\)下的逆元补码加法对于补码加法，我们必须确定当结果太大(为正)或者太小(为负)时，应该做些什么。给定在范围\\(-2^{w-1}\\leq{x},y\\leq{2}^{w-1}-1\\)之内的整数值\\(x\\)和\\(y\\)，它们的和就在范围\\(-2^w\\leq{x}+y\\leq{2}^w-2\\)之内，想要准确表示，可能需要\\(w+1\\)位。就像以前一样，我们通过将表示截断到\\(w\\)位，来避免数据大小的不断扩张。然而，却不像模数加法那样在数学上感觉很熟悉。定义\\(x+^t_wy\\)为整数和\\(x+y\\)被截断为\\(w\\)位的结果，并将这个结果看做是补码数。原理：补码加法对满足\\(-2^{w-1}\\leq{x},y\\leq{2}^{w-1}-1\\)的整数\\(x\\)和\\(y\\)，有：\\(x+^t_wy=\\begin{cases}x+y-2^w,2^{w-1}\\leq{x+y}正溢出\\\\x+y,-2^{w-1}\\leq{x+y}&lt;2^{w-1}正常\\\\x+y+2^w,x+y&lt;-2^{w-1}负溢出\\end{cases}\\)推导：补码加法因为补码加法与无符号数加法有相同的位级表示，所以可以按照如下步骤表示运算\\(+^t_w\\)，将其参数转换为无符号数，执行无符号数加法，再将结果转换为补码：\\[x+^t_wy\\doteq{U}2T_w(T2U_w(x)+^u_wT2U_w(y))\\]因为根据之前的推断，我们可以把\\(T2U_w(x)\\)写成\\(x_{w-1}2^w+x\\)，把\\(T2U_w(y)\\)写成\\(y_{w-1}2^w+y\\)，使用属性\\(+^u_w\\)是模\\(2^w\\)的加法，以及模数加法的属性，我们就能得到：\\(\\begin{aligned}x+^t_wy&amp;=U2T_w(T2U_w(x)+^u_wT2U(y))\\\\&amp;=U2T_w[(x_{w-1}2^w+x+y_{w-1}2^w+y)\\ mod\\ 2^w]\\\\&amp;=U2T_w[(x+y)\\ mod\\ 2^w]\\end{aligned}\\)消除了\\(x_{w-1}2^w\\)和\\(y_{w-1}2^w\\)这两项，因为它们模\\(2^w\\)等于\\(0\\)为了更好地理解这个数量，定义整数\\(z\\)为整数和\\(z\\doteq{x+y}\\)，\\(z'\\)为\\(z'\\doteq{z\\ mod\\ 2^w}\\)，而\\(z''\\)为\\(z''\\doteq{U2T_w(z')}\\)。数值\\(z''\\)等于\\(x+^t_wy\\)。我们分成4种情况分析首先，我们记得无符号数转换为补码的公式，对满足\\(0\\leq{u}\\leq{UMax_w}\\)的\\(u\\)有：\\(U2T_w(u)=\\begin{cases}u,\\ u\\leq{TMax_w}\\\\u-2^w,\\ u&gt;TMax_w\\end{cases}\\) \\(-2^w\\leq{z}&lt;-2^{w-1}\\)。然后，我们会有\\(z'=z+2^w\\)。这就得出\\(0\\leq{z'}&lt;-2^{w-1}+2^w=2^{w-1}\\)，因为这个数字满足上面所示无符号数转换为补码的第一个区间，所以\\(z''=z'\\)，这种情况称为负溢出(negative overflow)。我们将两个负数相加(这是我们能得到\\(z&lt;-2^{w-1}\\)的唯一方式)，得到一个非负的结果\\(z''=x+y+2^w\\) \\(-2^{w-1}\\leq{z}&lt;0\\)。那么，我们又将有\\(z'=z+2^w\\)，得到\\(-2^{w-1}+2^w=2^{w-1}\\leq{z'}&lt;2^w\\)。我们看到\\(z'\\)在满足\\(z''=z'-2^w\\)的范围之内，因此\\(z''=z'-2^w=z+2^w-2^w=z\\)。也就是说，我们的补码和\\(z''\\)等于整数和\\(x+y\\) 关于这里的异或运算，一开始可能不太理解，首先要明白，异或，就是找出两个位向量里面不同的元素，这里因为每个元素的加法逆元这个属性即使交换之后也成立，所以这里其实相当于(a^a)^b，即b与0相异或，值还是b &#8617; " }, { "title": "深入理解计算机系统 - 计算机系统漫游", "url": "/posts/foundation-4/", "categories": "编程基础, 操作系统", "tags": "编程基础, 操作系统", "date": "2020-09-11 00:00:00 +0800", "snippet": " 《深入理解计算机系统》这本书，按照书本的前言，主要读者是计算机科学家、计算机工程师，以及那些想通过学习计算机系统的内在运作而能写出更好程序的人，想要更多的了解计算机系统相关的知识，并且想要成为这样的人，所以我们开始了本书的学习计算机系统漫游 计算机系统是由硬件和系统软件组成的，系统的具体实现方式随时间不断变化，但是内在的概念是不变的。所有计算机系统由相似的硬件和软件组成，并执行相似的功...", "content": " 《深入理解计算机系统》这本书，按照书本的前言，主要读者是计算机科学家、计算机工程师，以及那些想通过学习计算机系统的内在运作而能写出更好程序的人，想要更多的了解计算机系统相关的知识，并且想要成为这样的人，所以我们开始了本书的学习计算机系统漫游 计算机系统是由硬件和系统软件组成的，系统的具体实现方式随时间不断变化，但是内在的概念是不变的。所有计算机系统由相似的硬件和软件组成，并执行相似的功能。通过一个hello程序被创建，到在系统上运行，输出消息，然后终止，这一整个生命周期，我们开始对计算机系统的学习信息就是位+上下文首先，我们在编辑器中创建了一个文本文件hello.c，hello程序的生命周期从这里开始：#include &lt;stdio.h&gt;int main(){ printf(\"hello, world\\n\"); return 0;}这个源程序(或者说源文件)实际上就是由0和1组成的位(又称为比特)序列，8个位被组织成一组，称为字节。每个字节表示程序中某些文本字符。比如上面的hello.c代码，其ASCII码1表示的内容为像这样符合某种文字编码规范的文件称为文本文件，所有其他文件都称为二进制文件，书中提到了这样的区别，其实广义的二进制文件包括了文本文件，二者只是在逻辑上经常被做了区分，在查阅资料后我认为，没有必要过于深入探究这两者之间的区别，只要记住符合某种文字编码规范的就是文本文件就可以了这个文件的表示方法说明了一个基本思想：所有的文件，包括磁盘中的文件，内存中的程序，内存中的用户数据以及网络上传输的数据，都是由一串位(比特)表示的，区分不同数据的唯一方法是根据读到它们时它们的上下文来判断，因为在不同的上下文中，一个同样的字节序列可能表示一个整数、浮点数、字符串或者机器指令 小知识：C语言的起源 —— C语言是贝尔实验室的Dennis Ritchie在1969年 - 1973年之间创建的。美国国家标准学会(American National Standards，ANSI)在1989年颁布了ANSI C的标准，后来C语言的标准化成了国际标准化组织International Standards Organization，ISO)的责任。 这些标准定义了C语言和一系列函数库，即C标准库。Kernighan和Ritchie在它们的经典著作中描述了ANSI C，这本书大家满怀感情地称为”K&amp;R”。 C语言会取得成功的原因有： C语言与Unix操作系统关系密切。C从一开始就是作为用于Unix系统的程序语言被开发出来的，由于20世纪70年代到80年代初Unix在高校中的流行，很多人开始接触C并且喜欢上它 C语言小而简单。C语言最初的设计是由一个人而非一个协会掌握的，因此简洁明了，没有什么冗赘的设计。这让C语言相对易于学习，也易于移植到不同的计算机 C语言是系统及编程的首选，同时也很适合编写应用级程序。不过其也存在一些不足，比如容易造成程序员困惑和程序错误的C语言指针。以及缺乏对类，对象等的显式抽象能力。程序被其他程序翻译成不同的格式之前我们编写的hello.c程序是用高级语言来表述的，容易被人读懂。为了在系统上运行它，这些语句必须被其他程序转化为相对低级的机器语言指令，然后按照一种称为可执行目标程序的格式被打好包，并且保存为二进制磁盘文件，也被称为可执行目标文件在Unix系统上，从源文件到目标文件的转换是由编译器驱动程序完成的：linux&gt; gcc -o hello hello.c以GCC编译器驱动程序2编译过程为例，整个编译分为四个阶段，而执行这四个阶段的程序共同构成了编译系统(complilation system)graph LR\tA&gt;\"hello.c&lt;br/&gt;源程序(文本)\"]--&gt;B[\"预处理器&lt;br/&gt;(cpp)\"]\tB--\"hello.i&lt;br/&gt;修改了的源程序(文本)\"--&gt;C[\"编译器&lt;br/&gt;(ccl)\"]\tC--\"hello.s&lt;br/&gt;汇编程序(文本)\"--&gt;D[\"汇编器&lt;br/&gt;(as)\"]\tD--\"hello.o&lt;br/&gt;可重定位目标程序(二进制)\"--&gt;E[\"链接器&lt;br/&gt;(ld)\"]\tsubgraph 建立链接 Id1((printf.o))--&gt;E end\tE--&gt;F(\"可执行目标程序&lt;br/&gt;(二进制)\")可以看到，四个阶段分别为： 预处理阶段：预处理器(cpp)根据以字符#开头的命令修改原始的C程序，比如第一行的#include &lt;stdio.h&gt;，预处理器会读取系统头文件，并且直接插入到程序文本中，得到另一个C程序，以.i作为扩展名 编译阶段：编译器(ccl)把文本文件hello.i翻译成文本文件hello.s，其包含一个汇编语言程序，内容为： main:\tsubq $8, %rsp\tmovl $.LCO, %edi\tcall puts\tmovl $0, %eax\taddq $8, %rsp\tret 汇编语言用文本格式描述了低级机器语言指令。汇编语言的作用在于，其为不同的高级语言的不同编译器提供了通用的输出语言。 汇编阶段：接下来，汇编器(as)把hello.s翻译成机器语言指令，并把指令打包成可重定位目标程序(relocatable object program)，保存在目标文件hello.o中，这是一个二进制文件，用文本编辑器打开它时，我们将看到一堆乱码 链接阶段：因为hello程序调用了printf函数，它是每个C编译器都提供的标准C库中的一个函数，该函数位于一个已经预编译好了的printf.o文件中，所以这个文件必须以某种方式合并到我们的hello.o程序中，链接器(ld)负责处理这种合并。最后得到hello文件(在Windows系统中，通常会编译成以.exe为扩展名的文件)，它是一个可执行目标文件 小知识：GCC是GNU(GUN’s Not Unix)项目开发出来的众多有用工具之一，这个项目是1984年由Richard Stallman发起的一个慈善项目。项目的目标是开发出一个完整的类Unix的系统，并且该系统的源码能不受限制地被修改和传播。GNU项目已经开发出了一个包含Unix操作系统的所有主要部件的环境，除了内核，内核是由Linux项目独立发展而来的。学了上面的小知识，才终于知道原来Linux本身只是一个内核，但是因为Linux内核和GNU项目的软件都是成套出现的，所以就被人简称为Linux，其全称为GNU/Linux，光有一个Linux内核是没办法使用的，没有软件也没有交互。再把软件加进来还是不能用，因为这些软件都是以源代码的形式发布的，需要编译成二进制程序，而且需要做调配选择，这些工作是发行版制作者的工作。比较异类的基于Linux内核的操作系统有Android，因为除了内核，其他运行的软件基本都是Google自己的，而不是GNU项目的；另外还有比较异类的如Debian的GNU/Hurd，其实Hurd才是GNU自己的内核，不过因为Richard无止境寻找完美内核，而忘记了Hurd主要目的是为了提供一个可用的操作系统内核，给了Linux机会。弄得GNU项目的人只能让自己的软件运行在Linux内核上3 GUN环境包括EMACS编辑器、GCC编译器、GDB调试器、汇编器、链接器、处理二进制文件的工具以及一些其他部件。GCC编译器已经发展到支持不同的语言，包括C、C++、Fortran、Java、Pascal、Objective-C和Ada GNU项目取得了非凡的成绩，但是却常常被忽略。现代开放源码运动(通常和Linux联系在一起)的思想起源是GNU中自由软件(free software)的概念，可想而知GNU项目对于开源的奠基地位了解编译系统工作原理的好处作为一名程序员，有许多理由不去了解编译系统是如何工作的，但我们还是有必须知道其工作原理的原因： 优化程序性能：了解编译原理能让程序员在写代码时有做出更好的编码选择的能力，比如，如果了解了编译器将不同的C语言转化为机器代码的方式，就能搞清楚在实现效果一样的情况下，如何在swich和一连串的if-else之间，在while和for之间做选择。以及了解一个函数调用的开销有多大，为什么循环求和时把结果放到本地变量比放到一个通过引用传递过来的参数速度更快 理解链接时出现的错误：有助于让程序员避开那些非常令人困扰的链接器操作 避免安全漏洞：一个稳定的，不容易出问题的软件需要程序员具有对程序做限制的能力，不仅有业务上的一些限制，更包括程序运行时对系统资源调用的限制。学习安全编程的第一步就是理解数据和控制信息存放在程序栈上的方式会引起的后果，了解程序的内部原理有助于避免这些安全问题处理器读取并解释内存中的命令此时，我们已经有被编译系统翻译完成的hello文件，并被存放在磁盘上，现在我们使用名为shell的应用程序来运行它linux&gt; ./hellohello, worldlinux&gt;系统的硬件组成书里会分阶段对一个典型系统的硬件组织进行介绍，但是在这一章会带我们做一个了解，以便让我们知道运行hello程序时发生了什么 总线 总线是贯穿整个系统的一组电子管道，其携带字节并负责在各个部件间传递。通常被设计成传送定长的字节块，也可以说成字(word)。其中的字节数(字长)在各个系统中都不一样，要么是4个字节(32位)，要么是8个字节(64位) I/O设备 I/O(输入/输出)设备是系统和外部世界的通道，之后的示例中会有四个I/O设备：键盘鼠标，显示器，磁盘。最开始，我们的这个程序就是放在磁盘上的。每个I/O设备都通过一个控制器或者适配器4与I/O总线相连。 主存 主存是一个临时存储设备，在处理器执行程序时用来存放程序和程序处理的数据。从物理上来说，其是由一组动态随机存储器(DRAM)芯片组成的。从逻辑上来说，其是一个线性的字节数组，每个字节都有唯一的地址(数组索引)，一般来说，组成程序的每条机器指令都由不同数量的字节构成。与C程序变量相对应的数据项的大小是根据类型变化的。比如，在运行Linux的x86-64机器上，short类型需要2个字节，int和float类型需要4个字节，而long和double类型需要8个字节 处理器 中央处理单元(CPU)，是解释(或执行)存储在主存中指令的引擎。其核心是大小为一个字(前文在总线那里提到过这个概念)的存储设备(或寄存器)，称为程序计数器(PC)，在任何时刻，PC都指向主存中某条机器语言指令(即含有该条指令的地址) 从系统通电到断电，处理器一直在不断执行程序计数器指向的指令，并更新计数器，使其指向下一条指令 处理器按照一个非常简单的指令模型来操作，这个模型由指令集架构决定。在这个模型中，指令按照严格的顺序执行，而每条的执行又包含一定的步骤。 处理器从程序计数器指向的内存读取指令，解释指令中的位，执行该指令指示的简单操作，然后更新PC，使其指向下一条指令，这条指令和在内存中刚刚执行的指令不一定是相邻的 这些操作围绕着主存、寄存器文件(register file)和算数/逻辑单元(ALU)进行。寄存器文件是一个小的存储设备，由一些单个字长的寄存器5组成，每个寄存器都有唯一的名字。ALU计算新的数据和地址值，CPU在指令的要求下可能会执行的操作有： 加载：从主存赋值一个字节或者一个字到寄存器，以覆盖寄存器原来的内存 存储：从寄存器赋值一个字节或者一个字到主存的某个位置，覆盖掉这个位置原来的内容 操作：把两个寄存器的内容赋值到ALU，ALU对这两个字做算数运算，并将结果放到一个寄存器中，覆盖该寄存器中原来的内容 跳转：从指令本身中抽取一个字，并将这个字赋值到程序计数器(PC)，覆盖PC中原来的值 看上去处理器简单实现了它的指令集架构，但是实际上现代处理器为了加速程序执行，使用了非常复杂的机制。所以我们这里把指令集架构和处理器的为体系结构区分讨论，指令集架构描述的是每条机器代码指令的效果，具有一定的抽象性。而微体系结构描述的是实际上是如何实现的。 运行hello程序首先我们在键盘上输入字符串./hello时，shell程序将字符逐一读入寄存器，再把它放到内存中当在键盘上敲回车键时，shell程序知道了我们已经结束了指令的输入，于是其加载可执行的hello文件，这些指令将hello目标文件的代码和数据(包括最后会被输出的字符串”hello, world\\n”)从磁盘复制到主存利用直接存储器存取(DMA，书本后面会讨论)技术，数据可以不通过处理器而直接从磁盘到达主存当目标文件hello中的代码和数据被加载到主存后，处理器就开始执行hello程序的main程序中的机器语言指令。这些指令将”hello, world\\n”字符串中的字节从主存复制到寄存器文件，再从寄存器文件复制到显示设备，最后显示在屏幕上高速缓存的重要性从这个示例可以看出，系统花费了大量的时间把信息从一个地方挪到另一个地方。这些复制作为开销，减慢了程序”真正”的工作。因此系统设计者的一个主要目标是让这些复制操作尽快完成根据机械原理，较大的存储设备比较小的存储设备运行得慢，对处理器而言，从磁盘驱动器上读取一个字的时间开销要比从主存中读取的开销大1000万倍，从寄存器文件中读数据比主存中读取几乎要快100倍，而且这个差距随着半导体技术的进步还在持续增大针对这种处理器与主存之间的差异，系统设计这使用了更小更快的高速缓存存储器(cache memory，简称为cache或高速缓存)作为暂时的集结区域，存放处理器近期可能会需要的信息。一个典型系统中通常有位于处理器芯片上的L1高速缓存器，容量可以达到数万字节，访问速度几乎和访问寄存器一样快。L2缓存器通过一条特殊的总线连接到处理器。高速缓存是用一种叫做静态随机访问存储器(SRAM)的硬件技术实现的。比较新，处理能力更强大的系统还可能有三级高速缓存，L1，L2和L3。利用高速缓存的局部性原理，即程序具有访问局部区域里的数据和代码的趋势，系统可以获得一个很大的存储器，同时访问速度也很快。存储设备形成层次结构在处理器和一个较大较慢的设备(如内存)之间插入一个更小更快的存储设备(如高速缓存)的想法已经成为一个普遍的观念。每个计算机中的存储设备被组织成一个存储器层次结构，在这个层次结构中，从上到下，设备的访问速度越来越慢、容量越来越大，每字节的造价也越来越便宜存储器的层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存。在某些具有分布式文件系统的网络系统中，本地磁盘就是存储在其他系统中磁盘上的数据的高速缓存利用对整个存储器层次结构的理解，可以提高程序性能。本书后面会更详细讨论这个问题操作系统管理硬件当shell加载和运行hello程序，以及hello程序输出自己的消息时，shell和hello程序都没有直接访问键盘、显示器或者主存。它们依靠操作系统提供的服务来完成这个过程。可以把操作系统看作是应用程序和硬件之间的一层软件，所有应用对硬件的操作尝试都必须通过操作系统，操作系统有两个基本功能： 防止硬件被时空的应用程序滥用； 向应用程序提供简单一致的机制来控制复杂而又通常大不相同的低级硬件设备。通过几个基本的抽象概念(进程、虚拟内存和文件)来实现这两个功能。进程当hello程序运行时，操作系统会提供一种假象，好像系统上只有这个程序在运行(在linux系统中，界面上只能观察到这个程序在运行)。就好像它独占了所有的硬件设备，处理器在不间断地执行程序中的指令，而该程序的代码和数据是系统内存中唯一的对象。这种现象是通过进程的概念来实现的。进程是操作系统对一个正在运行的程序的一种抽象。并发运行，指的是一个进程的指令和另一个进程的指令是交错的。无论是单核还是多核系统，一个CPU看上去都像是在并发地执行多个进程，这通过处理器在进程间切换来实现。操作系统中实现这种交错执行的机制被称为上下文切换。操作系统保持跟踪进程运行需要的所有状态信息，这种状态，也就是上下文，里面包含了许多信息，比如PC和寄存器文件的当前值，以及主存的内容。在任何一个时刻，单处理器系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程，就会进行上下文切换，即保存当前进程的上下文、恢复新进程的上下文，然后将控制权传递到新进程，新进程从上次停止的地方继续。从一个进程到另一个进程的转换是由操作系统内核(kernel)管理的。控制权在进程A -&gt; 内核 -&gt; 进程B ……来回传递。内核不是一个独立的进程，它是系统管理全部进程所用代码和数据结构的集合。线程一个进程可以由多个称为线程的执行单元组成，线程在进程的上下文中共享同样的代码和全局数据，因为多线程之间比多进程之间更容易共享数据，而且一般比进程更高效。所以有多处理器可用的时候，多线程也是一种使得程序可以运行得更快的方法。虚拟内存虚拟内存是一个抽象概念，每个进程看到的内存都是一致的，称为虚拟空间地址，地址最上面的区域是保留给操作系统中的代码和数据的，对所有进程来说都是一样的。地址空间的底部区域存放用户自定义的进程的代码和数据。地址是从下往上增大的。从最低的内存地址开始，简单了解一下虚拟内存的各个区： 程序代码和数据：对所有进程来说，代码是从同一个固定地址开始，紧接着是和C全局变量相对应的数据位置，这个区域是直接按照可执行目标文件的内容初始化的 堆：代码和数据区后面紧跟着运行时堆。和代码和数据区不一样，这个区不是固定大小的，而是可以动态地扩展和收缩 共享库：地址空间的空间部分有一块用来存放C标准库，数学库等共享库的代码和数据的区域 栈：位于用户虚拟地址空间顶部，编译器用它实现函数调用。其也可以动态地扩展和收缩。当我们调用一个函数时，其会增长；从一个函数返回时，栈就会收缩 内核虚拟地址：地址空间顶部的区域，是为内核保留的，不允许应用程序独写这个区域的内容或者直接调用内核代码定义的函数，它们必须通过内核来执行这些操作虚拟内存的运作需要硬件和操作系统之间精密复杂的交互。文件文件就是字节序列，仅此而已。每个I/O设备，磁盘、键盘、显示器，甚至网络，都可以看成是文件。系统中所有输入输出都通过一小组称为Unix I/O的系统函数调用读写文件来实现文件这个简单而精致的概念非常强大。它向应用程序提供了一个统一的视图，来看待系统中可能含有的所有各式各样的I/O设备系统之间通过网络通信现代系统经常通过网络和其他系统连接到一起。从一个单独的系统看，网络可视为一个I/O设备。当系统从主存复制一串字节到网络适配器，数据流经过网络到达另一台机器，而不是到达本地磁盘驱动器。同样，也可以读取从其他机器发送来的数据，并把数据复制到自己的主存重要主题通过前面所有的漫游内容，我们可以得出一个很重要的观点，那就是系统不仅仅只是硬件。而是硬件和系统软件互相交织的集合体，它们必须共同协作以达到运行应用程序最终的目的。通过之后对这些知识的深入学习，可以帮助我们写出更快速、更可靠、更安全的程序。Amdahl定律Gene Amdahl，对提升系统某一部分性能所带来的效果做出了观察，这个观察被称为Amdahl定律(Amdahl’s law)。该定律主要思想是：当我们对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。 假如原本执行某应用程序需要的时间为Told。假设系统某部分所需执行时间与该时间的比例为a，该部分的性能提升比例为k。则该部分初始所需时间为aTold，现在所需时间为(a*Told)/k，因此，总的执行时间应为上面是书里对Amdahl定律的解释，看完之后是不是觉得还有一点不明白是什么意思，特别是这里是两个比例这里再详细了解一下这个定律，首先这个定律在中文中通常被音译成阿姆达尔定律，阿姆达尔曾致力于并行处理系统的研究。把a看作并行计算部分所占比例，k为并行处理节点个数，假设a占100%，即1-a=0，整个程序都是并行执行时，k带来的收益是最高的。当a占0%，即整个程序都是串行执行时，无论如何增加k，都不会提高加速比。还有一种情况，考虑k趋向于∞时的效果，可以看出，此时a/k几乎可以忽略不计，于是我们得到：如果百分之60%的计算可以加速到几乎不花时间的程度，我们获得的加速比仍然只有1/0.4=2.5X6阿姆达尔定律描述了改善任何过程的一般原则，其主要观点是：想要显著加速整个系统，必须提升全系统中相当大的部分的速度。这个定律除了可以用在加速计算机系统方面，还可以用在公司降低制造成本，或者学生提高绩点平均值等方面。可以看出，如果我们想提高一个程序的运行效率提高2倍或更高的比例，只有通过很大一部分系统的组件才能得到书中有两道练习题：贴上答题过程：这也证明阿姆达尔定律不仅仅适用于计算机系统并发和并行如果处理器能够同时做更多的事情，可想而知，计算机就可以运行做更多的事情，并且能做更多的事情。并发(concurrency)指一个同时具有多个活动的系统，并行(parallelism)则指的是用并发来使一个系统运行更快。并行可以在计算机的多个层次上使用。 线程级并发 在单处理器系统中，并发只是模拟出来的，是通过一台计算机在正在执行的进程间快速切换来实现的，称之为时间共享。随着多核处理器和超线程(hyperthreading)的出现，这种系统才变得常见 多核处理器是将多个CPU(称为”核”)集成到一个集成电路芯片上 比如上面的微处理器芯片有4个核，每个核都有自己的L1和L2高速缓存，其中L1高速缓存分两部分：一个保存最近取到的指令，另一个存放数据。这些核共享更高层次的高速缓存，以及到主存的接口。工业界专家认为它们最后能把几十个甚至上百个核做到一个芯片上。 超线程，有时被称为同时多线程(simultaneous multi-threading)，是一项允许一个CPU执行多个控制流的技术。在应用了超线程技术的CPU中，某些硬件，比如程序计数器和寄存器文件有多个备份，其他硬件部分只有一份。常规的处理器需要大约20,000个时钟周i做线程间的转换，而超线程的处理器在单个周期的基础上可以决定要执行哪一个线程。比如，假设一个线程必须等到某些数据被装载到高速缓存中，那CPU就可以继续去执行另一个线程。比如Intel Core i7处理器可以让每个核执行两个线程，所以一个4核的系统实际上可以并行地执行8个线程 当程序是以多线程方式来书写的时候，多处理器的使用可以加快程序的运行，因为多个线程可以并行地高效执行。所以虽然并发原理的形成和研究已经超过50年的时间了，但是多核和超线程系统的出现，才激发了利用硬件开发线程级并行程序的应用程序的愿望。 指令级并行 在较低的抽象层次，现代处理器可以同时同时执行多条指令的属性称为指令级并行。现代处理器使用了很多聪明的技巧来同时处理多达100条指令。在书中之后的内容中，会讨论流水线(pipelining)的使用，它通过将执行一条指令需要的活动划分为不同的步骤，让处理器对指令的处理分为多个阶段，并行进行操作。 如果处理器可以达到比一个周期一条指令更快的执行速率，就称之为超标量(superscalar)处理器。大多数现代处理器都支持超标量操作。 单指令、多数据并行 在最低层次上，许多现代处理器有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式被称为单指令、多数据，即SIMD并行。大多数时候提供这些SIMD指令多是为了提高处理影像、声音和视频数据应用的执行速度。 计算机系统中抽象的重要性抽象是计算机科学中最为重要的概念之一，比如为一组函数规定一个简单的应用接口(API)，程序员可以忽略它内部的工作便可以使用这些代码。对于计算机系统来说，底层的硬件远比抽象描述要复杂精细，在本章我们旋风式地对这些知识进行了了解，在后续的章节，会具体介绍这些抽象小结计算机系统由硬件和系统软件组成，它们共同协作以运行应用程序。计算机内部的信息被表示为一组组的位，它们根据上下文有不同的解释方式。程序被其他程序翻译成不同的形式，先到ASCII文本，然后被编译器翻译成二进制可执行文件。处理器读取并解释主存里的二进制指令。应为计算机花费了大量的时间在内存、I/O设备和CPU寄存器之间复制数据，所以将系统中的存储设备分成层次结构，顶部是CPU寄存器，接着是多层的硬件高速缓存存储器、DRAM主存和磁盘存储器。位于更高层次的存储设备比底层存储设备要快，单位比总造价更高。层次结构中较高层次的存储设备可以作为较低层次设备的高速缓存。通过理解和运用这种存储层次结构的知识，程序员可以优化程序的性能。操作系统内核是应用层序和硬件之间的媒介。它提供三个基本的抽象： 文件是对I/O设备的抽象； 虚拟内存是对主存和磁盘的抽象； 进程是处理器、主存和I/O设备的抽象最后，网络提供了计算机系统之间通信的手段，从特殊的角度来看，网络就是一种I/O设备 ASCII码是用一个唯一的单字节大小的整数值来表示每个字符，还有许多其他编码方式用于表示非英语类语言文本，比如UTF-8标准，根据书中指引，本书后面会学习到 &#8617; 编译器驱动程序不止一种，相同的驱动程序在不同的系统上的行为过程大体是相同的，传统编译器的工作原理基本上都符合三段式：1.用于解析源码，检查语法错误，并将其抽象为语法树(Abstact Syntax Tree)的前端(Frontend)；2.对中间代码进行优化的优化器(Optimizer)；3.负责将优化后的中间代码转换为目标机器的机器码的后端(Backend)。现在用得比较多的LLVM编译器则与其具有一些区别，这个以后会在学习编译原理的时候学习，这里只是为了说明用GCC进行编译的过程在Unix和Windows上大体是相同的 &#8617; 关于这里有个网络上的梗：1990 年人们希望有一个可用的开源系统：Linux 可以用，Hurd 还不可以用；2000 年人们希望有一个稳定的开源系统：Linux 很稳定，Hurd 还很不稳定；2010 年人们希望有一个生态系统成熟的开源系统：Linux 生态系统很成熟，Hurd 还没有生态系统。Hurd 不成气候的原因，网友也分析出了这几点：1.RMS 的技术决定错误。微内核的优势是学术理论的结果，而不是从实际应用得出的经验。它的实现难度和设计难度也被低估，导致无法有效实施开发工作。2.和其他 GNU 项目不同，Hurd 的发展计划太长，实际执行更长。过于宏大长远的开源项目都很难成功。自由软件的成功之道是，大始于小，积土成堆。 3.GNU 没有搞出一款可用的操作系统。反而是 Redhat，Slackware，SUSE 和 Debian 这些后起之秀，短短几年就搞出了可用的开源操作系统。在此之上，前辈们迅速补齐了一个操作系统所需的各个部分，从包管理器，图形桌面到办公软件。之后人们就不再期待传说中的 GNU 操作系统了。4.GNU 的开发模式问题，虽是开源，但很集中。而 Linux 和 Mozilla 则受益于海纳百川的开放模式。可以参考《大教堂和集市》这本书。5.GNU 对自由软件的绝对洁癖。Linux 里面是有非开源的固件的，通常是由硬件厂商提供的。然而 GNU 是绝对不能认同这一实用主义做派的。因此 Hurd 如果要自己实现硬件驱动，那工作量就是无底洞，永远填不满。 &#8617; 控制器和适配器之间区别主要在于它们的封装方式。控制器是I/O设备本身或者系统的主印刷电路板(主板)上的芯片组。而适配器则是一块插在主板上的卡。无论如何，它们的功能都是在I/O总线和I/O设备之间传递信息 &#8617; 这里的寄存器要和前面提到的PC不是同一种东西，这里的寄存器是实实在在的寄存器。首先要明确，PC可以是实实在在的寄存器，也可以不是一个寄存器，书里提到这个概念只是想让人们明白在CPU体系里有一个用来存放指令地址的东西，在不同的指令集架构(x86，x64等)里面，它的称呼或者说法也可能不一样。这里不需要用太严格的理论来套实际的设计 &#8617; 书里用X来表示加速比的单位，没有找到比较详细的介绍，这里也直接用X来表示 &#8617; " }, { "title": "Rust学习笔记(3) - 结构体", "url": "/posts/rust-3/", "categories": "编程语言, Rust", "tags": "Rust", "date": "2020-09-09 00:00:00 +0800", "snippet": " struct，或者 structure，是一个自定义数据类型，允许命名和包装多个相关的值，从而形成一个有意义的组合，就像面向对象语言中，一个对象中的各个属性定义、实例化、使用结构体这里展示如何定义并且实例化一个结构体，然后对结构体的字段内容进行调整，并输出到控制台(这里演示了#[derive(Debug)]注解的用法和如何调用println!()打印结构体)。另外还演示了如何用函数处理具...", "content": " struct，或者 structure，是一个自定义数据类型，允许命名和包装多个相关的值，从而形成一个有意义的组合，就像面向对象语言中，一个对象中的各个属性定义、实例化、使用结构体这里展示如何定义并且实例化一个结构体，然后对结构体的字段内容进行调整，并输出到控制台(这里演示了#[derive(Debug)]注解的用法和如何调用println!()打印结构体)。另外还演示了如何用函数处理具有重复字段值的结构体的初始化，以及使用一个已有的结构体实例的字段来快速初始化一个新的结构体实例：#[derive(Debug)]struct User { username: String, email: String, sign_in_count: u64, active: bool,}fn build_user(email: String, username: String) -&gt; User { User { email, username, active: true, sign_in_count: 1, }}fn main() { let mut new_user1 = build_user( String::from(\"narancia@86.outlook.com\"), String::from(\"用户名\"), ); let new_user2 = User { sign_in_count: 66, ..new_user1 }; new_user1.username = String::from(\"用户名\"); new_user1.email = String::from(\"narancia@86.outlook.com\"); println!(\"{:#?}\", new_user1); // User { // username: \"用户名\", // email: \"narancia@86.outlook.com\", // sign_in_count: 1, // active: true, // } println!(\"{:#?}\", new_user2); // User { // username: \"用户名\", // email: \"narancia@86.outlook.com\", // sign_in_count: 66, // active: true, // }}没有命名字段的元组结构体fn main() { #[derive(Debug)] struct Color(i32, i32, i32); let black = Color(0, 0, 0); println!(\"{:?}\", black); // Color(0, 0, 0)}元组结构体(tuple structs)有结构体名称提供的含义，但没有具体的字段名，只有字段的类型，当想给整个元组起一个名字时，这是很有用的结构体数据的所有权可以看到，我们定义结构体时，都用了自身拥有所有权的String类型而不是字符串slice类型&amp;str，因为我们想让这个结构体拥有它所有的数据，而不被其他对象拥有的数据的引用，如果想要那要做的话需要用上生命周期(lifetimes)，这在之后会学习到，生命周期确保结构体引用的数据的有效性跟结构体本身保持一致方法语法这里演示了如何在impl块中定义方法和关联函数（associated functions），以及如何使用它们。所谓关联函数，它们不作用于一个结构体的实例，我们已经用过String::from关联函数了，另外值得注意的是，对于同一个结构体，可以定义多个impl块#[derive(Debug)]struct User { username: String, email: String, sign_in_count: u64, active: bool,}impl User { fn introduce(&amp;self) -&gt; String { \"My Name is \".to_string() + &amp;self.username + \", email is \" + &amp;self.email } fn new_man() -&gt; User { User { username: \"new_man\".to_string(), email: \"new@email.com\".to_string(), sign_in_count: 12, active: true, } }}fn build_user(email: String, username: String) -&gt; User { User { email, username, active: true, sign_in_count: 1, }}fn main() { let mut new_user1 = build_user( String::from(\"narancia@86.outlook.com\"), String::from(\"用户名\"), ); println!(\"{}\", new_user1.introduce()); // My Name is 用户名, email is narancia@86.outlook.com println!(\"{:#?}\", User::new_man()); // User { // username: \"new_man\", // email: \"new@email.com\", // sign_in_count: 12, // active: true, // }}" }, { "title": "制作一个基于.NET原生Socket的WEB API转发工具(2) - 工具实现", "url": "/posts/socket-2/", "categories": "编程基础, 计算机网络", "tags": "Socket", "date": "2020-08-14 00:00:00 +0800", "snippet": " 因为要实现的功能很容易就能说清楚，这篇主要是介绍实现思路和相关代码，因为Socket基本用法，实现端与端连接的部分没有特别需要总结的，这里主要说明关于协议解析部分功能介绍最近了解了TCP协议以及Socket编程的相关知识，这次用.NET平台提供的原生Socket类库实现一个简单的WEB API转发工具，功能示意：使用方法：首先在内网客户端定义好对外服务端的IP地址(ServerIP)，自...", "content": " 因为要实现的功能很容易就能说清楚，这篇主要是介绍实现思路和相关代码，因为Socket基本用法，实现端与端连接的部分没有特别需要总结的，这里主要说明关于协议解析部分功能介绍最近了解了TCP协议以及Socket编程的相关知识，这次用.NET平台提供的原生Socket类库实现一个简单的WEB API转发工具，功能示意：使用方法：首先在内网客户端定义好对外服务端的IP地址(ServerIP)，自身的项目ID(GID)，要转发到的内网API地址(NATIP)等内容打开服务端，开启监听，在客户端点击连接服务器即可。之后所有对于服务端的Header带有对应GID的HTTP请求都会被转发到对应内网API，并原路转发回去实现思路首先，客户端接收到来自第三方服务器的HTTP报文的字节流HTTP协议因为要转发HTTP请求，所以必须了解HTTP协议1，另外因为本工具制定的自定义协议也是仿HTTP协议的，所以这里先重点介绍一下HTTP协议GET /getdata HTTP/1.1User-Agent: PostmanRuntime/7.26.2Accept: */*Host: 192.168.31.236:100GID:00000001Accept-Encoding: gzip, deflate, brConnection: keep-aliveContent-Type: application/x-www-form-urlencodedContent-Length: 1230Data一个完整的HTTP请求报文如图所示 内容 范围 含义 请求行 上面第一行 从左到右标识这次请求的方法，url，HTTP协议版本 请求头 从User-Agent开始，一直到Data上面的回车换行结束 包含若干个属性，接收方根据这些属性获取请求方的信息 数据体 Data的内容 数据部分，请求时携带的数据，可能是一些函数的参数，或者图片数据等 在Data上面的部分，即请求行和请求头部分是用\\r\\n，即回车符和换行符来分隔的报文解析都收到了报文了，直接转发不就行了，为什么要了解报文并解析呢，首先要了解一个概念TCP粘包众所周知，TCP协议是基于连接的，流式(STREAM)的传输层协议，数据在通信双方以字节进行传输，TCP是传输层协议 ，它不会关心报文携带的数据在应用层的具体含义，所以对于接收方的应用层来说，每次接收之后，缓冲区里的内容可能是多个有意义的应用层报文的集合，也可能是一个有意义的应用层的报文的一部分，即在我们看来，包可能被“粘”在一起，也可能接收到不完全的包，这就是粘包关于TCP粘包是不是中式伪科学的问题，因为任何专业的教科书，以及官方文档，从来没有说过TCP会存在“粘包”的问题。在网上有很多讨论，主要关注点在于，TCP是传输层协议，所以这里的粘包，到底能不能称为“TCP粘包”，我认为没有必要纠结这个说法，只要知道这里指的是基于TCP协议的应用层协议，在业务逻辑上发生的粘包就行了使用代码解析报头如何解决粘包问题，答案很简单，就是让接收方知道报文的边界在哪里，知道每一个报文在什么时候结束。在HTTP协议中是这样做的，通常2在报文中有一个Content-Length属性，指示了Data部分的字节长度，知道这个长度，就知道这次报文的数据部分有多少个字节项目代码中，位于MessageFactory.cs文件的InitMessageFromData函数体现了HTTP协议在代码中是如何解析的，因为前面也提到了，本工具的其它协议也是在这里解析的，直接看代码如果比较混乱的话，了解思路就行代码先将通过Socket接收到的字节流转换成本文，因为HTTP协议是用\\r\\n来分隔的，所以这里主要用了StringReader类来逐行读取报文数据，主要目的是得到请求头携带的GID和Content-Length，又因为请求头到正文之间有一个空白行的间隔，所以当读到一个空字符串的时候，就代表请求头读完了，这时候就可以知道这次HTTP请求的项目ID，以及数据体的长度了主要代码 对于报文头的解析，在工具中大体都是基于这个套路来进行的，这里写几句示例，展示如何读到HTTP报头中的Content-Length属性// 将接收到的报文内容转换成字符串var textContent = Encoding.UTF8.GetString(data);// 实例化StringReader，用于逐行读取数据StringReader stringReader = new StringReader(textContent);int contentLength = 0;string line = \"\";// 开始解析头部while (line != null){ // 读到当前行 line = stringReader.ReadLine(); // 当读到null表示后面一行都没了 if (line != null) { if (line == \"\") { break; } else { var lineSplit = line.Split(':'); if (lineSplit.Length &gt;= 2) { // 获取头部长度 if (lineSplit[0].ToUpper() == \"CONTENT-LENGTH\") { int.TryParse(lineSplit[1].Trim(), out contentLength); } } } }}解析报头的作用其实关于报头的作用，在前面已经说得很明白了，这里再进行总结一次，通过解析报头，可以知道报文的边界，从而拆分得到的字节流，方便进行后续操作业务逻辑前期准备 与第三方的约定：第三方HTTP报头需要携带项目ID(GID)属性来请求，否则我们无法判断要发往的客户端 与客户端的约定：客户端要使用正确的协议发送登录指令到服务端，从而标识自己的身份，让服务端在接收到第三方请求之后有地方可发服务端收到报文的后续处理(最开始功能图的详细实现) 获取第三方HTTP报文：通过解析第三方HTTP请求报头，判断是否需要截取或者拼接字节流，此时，我们得到了完整的，正确的HTTP报文 构建服务端报文并转发：判断第三方HTTP报文头是否携带了项目ID(GID)，并且当前连接服务端的客户端中有没有与之对应的，如果找到，使用服务端协议来再次包装这个HTTP报文，在其前面加上特定的服务端报头，标识了发送方的IP地址和端口号 客户端接收并转发：客户端接收到来自服务端的报文之后，解析出HTTP报文，转发给界面上设置的内网API 客户端转发API响应：客户端得到内网API的响应报文之后，解析并且用客户端协议来再次包装这个响应体，在前面加上特定的客户端报头，标识了要响应的目标IP地址和端口号 服务端转发客户端响应：服务端接收到来自客户端的报文之后，解析出HTTP响应报文，找到当前连接中IP和端口号与客户端响应报头上相同的，转发回去其它要点客户端和服务端均是用Winform构建，除了解析报文部分之外，主要用到了自定义的Session类来管理连接，Session是Socket的扩展，在Socket的基础上加了业务需要的属性和函数，程序通过管理一个Session列表来管理所有连接在客户端和服务端通过心跳机制来维持连接，默认每分钟客户端向服务端发送心跳，当超过2分钟没有发送心跳时，连接断开自定义协议内容 协议的形式都是和HTTP协议一样的，以最上面一行请求行作为每个报文的开始位置，按照一样的模式来解析就行了TCP客户端的登录报文：2136@208140@8111GID:00000001TCP客户端=&gt; 外网Server报文18587!303&amp;315434IP:127.0.0.1:80Content-Lenght:1000data(长度1000)TCP客户端心跳包32906%9041@89176外网Server =&gt; TCP客户端报文18587!303&amp;315434IP:127.0.0.1:80Content-Lenght:1000data(长度1000) 如果对于协议一词还有疑惑，又不想深究的话，可以理解成，协议是网络通信双方约定好的一种发送数据的规范，就好像是人与人之间对话用的语言，只有用对方听得懂的语言，听的人才知道说出来的一堆音节组成的一句话在什么时候说完，具体含义是什么，从而做出回应。双方默认以这个规范构建和解析信息，从而可以正确处理消息的内容，判断后续操作(截取，转发，断开连接等) &#8617; 在HTTP报文中，当然也存在不携带Content-Length属性的情况，当不携带时，可能是Data部分不携带任何数据，也有可能是分包发送的Chunked报文，这些在代码里也有考虑，这里只讨论一般情况 &#8617; " }, { "title": "Rust学习笔记(2) - 认识所有权", "url": "/posts/rust-2/", "categories": "编程语言, Rust", "tags": "Rust", "date": "2020-08-04 00:00:00 +0800", "snippet": " 所有权机制是Rust最与众不同的特性，它让Rust无需垃圾回收(garbage collector)就能保障内存安全什么是所有权(ownership)？所有运行的程序都必须管理其使用计算机内存的方式，有一些语言具有GC机制，在程序运行时不断寻找不再使用的内存；还有一些语言，需要程序员亲自分配和释放内存。而在Rust中，是通过所有权机制来管理内存的，编译器在编译时会根据一系列规则进行检查，...", "content": " 所有权机制是Rust最与众不同的特性，它让Rust无需垃圾回收(garbage collector)就能保障内存安全什么是所有权(ownership)？所有运行的程序都必须管理其使用计算机内存的方式，有一些语言具有GC机制，在程序运行时不断寻找不再使用的内存；还有一些语言，需要程序员亲自分配和释放内存。而在Rust中，是通过所有权机制来管理内存的，编译器在编译时会根据一系列规则进行检查，在运行时，所有权系统内部的所有功能都不会减慢程序在了解所有权之前，我们要先了解栈(Stack)与堆(Heap)的概念 栈（Stack）与堆（Heap） 在很多语言中，你并不需要经常考虑到栈与堆。不过在像 Rust 这样的系统编程语言中，值是位于栈上还是堆上在更大程度上影响了语言的行为以及为何必须做出这样的抉择。我们会在本章的稍后部分描述所有权与栈和堆相关的内容，所以这里只是一个用来预热的简要解释。 栈和堆都是代码在运行时可供使用的内存，但是它们的结构不同。栈以放入值的顺序存储值并以相反顺序取出值。这也被称作 后进先出（last in, first out）。想象一下一叠盘子：当增加更多盘子时，把它们放在盘子堆的顶部，当需要盘子时，也从顶部拿走。不能从中间也不能从底部增加或拿走盘子！增加数据叫做 进栈（pushing onto the stack），而移出数据叫做 出栈（popping off the stack）。 栈中的所有数据都必须占用已知且固定的大小。在编译时大小未知或大小可能变化的数据，要改为存储在堆上。堆是缺乏组织的：当向堆放入数据时，你要请求一定大小的空间。操作系统在堆的某处找到一块足够大的空位，把它标记为已使用，并返回一个表示该位置地址的 指针（pointer）。这个过程称作 在堆上分配内存（allocating on the heap），有时简称为 “分配”（allocating）。将数据推入栈中并不被认为是分配。因为指针的大小是已知并且固定的，你可以将指针存储在栈上，不过当需要实际数据时，必须访问指针。 想象一下去餐馆就座吃饭。当进入时，你说明有几个人，餐馆员工会找到一个够大的空桌子并领你们过去。如果有人来迟了，他们也可以通过询问来找到你们坐在哪。 入栈比在堆上分配内存要快，因为（入栈时）操作系统无需为存储新数据去搜索内存空间；其位置总是在栈顶。相比之下，在堆上分配内存则需要更多的工作，这是因为操作系统必须首先找到一块足够存放数据的内存空间，并接着做一些记录为下一次分配做准备。 访问堆上的数据比访问栈上的数据慢，因为必须通过指针来访问。现代处理器在内存中跳转越少就越快（缓存）。继续类比，假设有一个服务员在餐厅里处理多个桌子的点菜。在一个桌子报完所有菜后再移动到下一个桌子是最有效率的。从桌子 A 听一个菜，接着桌子 B 听一个菜，然后再桌子 A，然后再桌子 B 这样的流程会更加缓慢。出于同样原因，处理器在处理的数据彼此较近的时候（比如在栈上）比较远的时候（比如可能在堆上）能更好的工作。在堆上分配大量的空间也可能消耗时间。 当你的代码调用一个函数时，传递给函数的值（包括可能指向堆上数据的指针）和函数的局部变量被压入栈中。当函数结束时，这些值被移出栈。 跟踪哪部分代码正在使用堆上的哪些数据，最大限度的减少堆上的重复数据的数量，以及清理堆上不再使用的数据确保不会耗尽空间，这些问题正是所有权系统要处理的。一旦理解了所有权，你就不需要经常考虑栈和堆了，不过明白了所有权的存在就是为了管理堆数据，能够帮助解释为什么所有权要以这种方式工作。记住Rust所有权的规则： Rust 中的每一个值都有一个被称为其 所有者（owner）的变量。 值在任一时刻有且只有一个所有者。 当所有者（变量）离开作用域，这个值将被丢弃。通过String类型来认识所有权首先，我们来看简单情况，我们都知道，所有编程语言都有变量作用域(scope)的概念，Rust也不例外，我们来看一段代码：fn main() { { let mut num = 2; } // not found in this scope num = 4; println!(\"{}\", num);}可以看到，注释部分表示了上面代码在编译的时候会注明的error，提示在当前作用域中不存在num这个变量，到这里为止，Rust的作用域相关特征都还和其他编程语言类似，num是一个基本类型的变量，其储存在栈上，当离开作用域时被移出栈在介绍更复杂的所有权规则之前，我们先来介绍一种比之前都要复杂的数据类型，String类型，它和之前我们用let s = \"hello, world!\"定义的字符串字面值不一样，字符串字面值是不可变的，而String类型是可变的来看两段代码：fn main() { let mut s = \"hello\"; // cannot add `&amp;str` to `&amp;str` s = s + \", world! \";}fn main() { let mut s = String::from(\"hello\"); s = s + \", world!\"; println!(\"{}\", s);}在第一段代码中，我们定义了一个字符串字面量，当我们试图在其后面添加新的内容时，出现了编译错误，而在第二段代码中，我们定义了一个String类型的变量，就可以在后面添加新的内容了，那么，第二段代码是什么意思呢对于字符串字面量，我们在编译时就知道其内容，它被直接硬编码进最后的可执行文件中。而我们在第二段代码中用了String::from(\"hello\")来定义了一个字符串变量(String::from这样的写法会在以后学习到)，可以存储在编译时未知大小的字符串内容，它可能会随着程序的运行而改变，所以不能硬编码进二进制文件，需要在对上分配一块在编译时未知大小的内容来存放这个变量被分配到堆上，意味着： 必须在运行时向操作系统请求内存 当处理完这个变量时，我们要将内存返回给操作系统第一点当我们在调用String::from时就已经完成了，在许多编程语言中，都是这么做的，对于第二点，每种编程语言就有区别了，在有GC的语言中，GC记录并清除不再使用的内存，在没有GC的语言中，手动释放不再使用的内存就是我们的责任。正确处理内存回收是一个困难的编程问题，如果忘记回收了会浪费内存。如果过早回收了，将会出现无效变量。如果重复回收，这也是个 bug。为此，Rust的设计者为每一个内存的分配配对了一个释放规则，这个规则由所有权来保证fn main() { { let s = String::from(\"hello, world!\"); }}上面的代码中，当s离开其作用域，Rust为我们调用一个特殊的函数drop，在这里会执行String的释放内存的代码变量与数据的交互方式(一)：移动let x = 5;let y = x;上面的代码将x的值赋值给了y，因为整数是已知固定大小的简单值，所以这两个５被放入了栈再来看看String版本let s1 = String::from(\"hello\");let s2 = s1;让我们观察在String的底层会发生什么，String由左侧的三部分组成，分别是一个指向存放字符串内容内存的指针，一个长度，以及一个容量，这一组数据存储在栈上。右侧则是在堆上存放内容的内存部分当我们将s1赋值给s2，String的数据被复制了，我们复制了其在栈上的指针，长度和容量，并没有复制指针指向的堆上的数据，所以内存中数据的表现如图：如果其同时也拷贝了其在堆上的数据，如图所示，可以看出如果堆上数据比较大，其会对性能造成较大的影响之前提过，当变量离开作用域时，Rust会自动调用drop函数清理内存，可以想象到，如果两个变量的指针指向同一个位置，当其离开作用域时，会尝试释放相同的内存，这可能会导致潜在的安全漏洞为了确保内存安全，Rust做的处理是这样的：当s1被赋值给s2时，Rust认为s1不再有效，所以如下代码会出现问题：fn main() { let s1 = String::from(\"hello\"); let s2 = s1; // borrow of moved value: `s1` println!(\"{}\", s1);}这里当let s2 = s1时，s1已经是一个moved value了，在其它语言里面，你可能听说过浅拷贝（shallow copy）和 深拷贝（deep copy），在Rust里，当把s1的指针，长度和容量拷贝到s2时，Rust还使s1无效了，这个操作被称为移动(move)，而不是浅拷贝所以这里只有s2依然有效，当其离开作用域，就释放自己的内存变量与数据交互的方式（二）：克隆当确实需要深拷贝String位于堆上的数据时，可以用一个叫做clone的通用函数fn main() { let s1 = String::from(\"hello\"); let s2 = s1.clone(); println!(\"s1 = {}, s2 = {}\", s1, s2);}像整形这样实现了Copytrait的类型(关于trait会在之后的学习中学到)，在被赋值给其它变量之后仍然可用，Rust不允许其自身或其任何部分实现了Droptrait的类型使用Copytrait，Copy类型包括但不限于： 所有整数类型，比如 u32。 布尔类型，bool，它的值是 true 和 false。 所有浮点数类型，比如 f64。 字符类型，char。 元组，当且仅当其包含的类型也都是 Copy 的时候。比如，(i32, i32) 是 Copy 的，但 (i32, String) 就不是。所有权与函数将值传递给函数在语义上与给变量赋值相似。向函数传递值可能会移动或者复制，就像赋值语句一样，比如如下代码会出现问题：fn main() { let s = String::from(\"hello\"); // s 进入作用域 takes_ownership(s); // s 的值移动到函数里 ... // ... 所以到这里不再有效 // borrow of moved value: `s` println!(\"{}\", s);} // 这里, x 先移出了作用域，然后是 s。但因为 s 的值已被移走， // 所以不会有特殊操作fn takes_ownership(some_string: String) { // some_string 进入作用域 println!(\"{}\", some_string);} // 这里，some_string 移出作返回值与作用域如下代码在第二次使用s2时出现错误，因为那时s2的值已经被移动到takes_and_gives_back，然后将返回指移动到s3了fn main() { let s1 = gives_ownership(); // gives_ownership 将返回值 // 移给 s1 let s2 = String::from(\"hello\"); // s2 进入作用域 let s3 = takes_and_gives_back(s2); // s2 被移动到 // takes_and_gives_back 中, // 它也将返回值移给 s3 // borrow of moved value: `s2` println!(\"{}\", s2);} // 这里, s3 移出作用域并被丢弃。s2 也移出作用域，但已被移走， // 所以什么也不会发生。s1 移出作用域并被丢弃fn gives_ownership() -&gt; String { // gives_ownership 将返回值移动给 // 调用它的函数 let some_string = String::from(\"hello\"); // some_string 进入作用域. some_string // 返回 some_string 并移出给调用的函数}// takes_and_gives_back 将传入字符串并返回该值fn takes_and_gives_back(a_string: String) -&gt; String { // a_string 进入作用域 a_string // 返回 a_string 并移出给调用的函数}当想要函数使用一个值但不获取所有权，可以通过元组的方式或者使用引用(references)通过元组：fn main() { let s1 = String::from(\"hello\"); // s1 进入作用域 let (s1, s2) = takes_and_gives_back(s1); // s1 被移动到 // takes_and_gives_back 中, // 它也将返回值移给 s2 println!(\"{} length is {}\", s1, s2);} // 这里, s3 移出作用域并被丢弃。s2 也移出作用域，但已被移走， // 所以什么也不会发生。s1 移出作用域并被丢弃// takes_and_gives_back 将传入字符串并返回该值fn takes_and_gives_back(a_string: String) -&gt; (String, usize) { // a_string 进入作用域 let a_length = a_string.len(); (a_string, a_length) // 返回 a_string 并移出给调用的函数}可以看到，通过元组的方法过于形式主义，所以我们需要使用引用来做这件事引用与借用使用&amp;符号可以使用引用，允许使用值但不获取其所有权(对应的，使用*符号可以进行解引用)fn main() { let s1 = String::from(\"hello\"); let len = calculate_length(&amp;s1); println!(\"The length of '{}' is {}.\", s1, len);}fn calculate_length(s: &amp;String) -&gt; usize { s.len()}&amp;String s指向String s1示意图当引用离开作用域时，其指向的值也不会被丢弃，此时我们不再需要返回指来交换所有权，因为所有权没有发生过转移获取引用的过程被称为 借用(borrowing)，和变量默认是不可变的一样，引用的值也默认不可变比如上面的代码，因为我们没有获得s1的所有权，所以当引用离开作用域时其指向的值也不会被丢弃可变引用将引用调整成mut可以使其可变，比如，这段代码最后会输出hello, the world!fn main() { let mut s = String::from(\"hello, world!\"); let s1 = &amp;mut s; s1.clear(); s1.push_str(\"hello, the world!\"); println!(\"{}\", s);}不过可变引用是有限制的：在特定作用域的特定数据只能有一个可变引用，所以，下列代码不能编译通过： fn main() { let mut s = String::from(\"hello\"); let s1 = &amp;mut s; let s2 = &amp;mut s; println!(\"{}, {}\", s1, s2);}这个限制可以有效的防止数据竞争（data race），数据竞争会导致未定义行为，难以在运行时追踪，其可由这三个行为造成： 两个或更多指针同时访问同一数据。 至少有一个指针被用来写入数据。 没有同步数据访问的机制。Rust不会让存在数据竞争的代码编译通过，也就不会发生数据竞争也不能在拥有不可变引用的同时拥有可变引用，如：fn main() { let mut s = String::from(\"hello, world!\"); let s1 = &amp;s; // cannot borrow `s` as mutable because it is also borrowed as immutable let s2 = &amp;mut s; println!(\"{}\", s1);}这个“同时拥有”的概念，或者说是引用的作用域的概念，用下面的代码可以很好理解：fn main() { let mut s = String::from(\"hello\"); let s1 = &amp;mut s; let s2 = &amp;mut s; println!(\"{}\", s2);}fn main() { let mut s = String::from(\"hello\"); let s1 = &amp;s; let s2 = &amp;s; println!(\"{},{}\", s1, s2); let s3 = &amp;mut s; println!(\"{}\", s3);}一个引用的作用域，从其被创建的时候开始，到其最后一次被使用为之，所以上面的代码在编译时不会产生错误，因为这些引用的作用域没有重叠悬垂引用在具有指针的语言中，很容易因为释放内存时还保留了指向它的指针而错误地生成一个悬垂指针（dangling pointer），即其指向的内存可能已经被分配给其它持有者，在Rust中，永远也不会出现这种情况，编译器会保证数据不会在其引用之前离开作用域// this function's return type contains a borrowed value, but there is no value for it to be borrowed fromfn dangle() -&gt; &amp;String { let s = String::from(\"hello\"); return &amp;s;}上面的代码除了一个和生命周期(lifetimes)有关的错误外(生命周期之后会学到)，还会提示由于被借用的值已经没了，所以没办法返回这个引用引用的规则总结上面引用的规则，可以做一个概括： 在任意给定时间，要么只能有一个可变引用，要么只能有多个不可变引用。 引用必须总是有效的。Slice类型可以用slice类型引用集合中一段连续的元素序列，而不引用整个集合，写法是..语法，引用集合中从..左边的索引开始，到右边的索引之前一个位置的内容(类似Python里面range()函数的范围)字符串slicefn main() { let s = String::from(\"abcdefghijklmn\"); println!(\"{}\", &amp;s[0..3]); // abc println!(\"{}\", &amp;s[0..6]); // abcdef println!(\"{}\", &amp;s[2..6]); // cdef println!(\"{}\", &amp;s[..]); // abcdefghijklmn println!(\"{}\", &amp;s[2..]); // cdefghijklmn println!(\"{}\", &amp;s[..s.len()]); // abcdefghijklmn}之前提到过的字符串字面值就是slice，其类型是&amp;str，它是一个指向二进制程序特定位置的slice，是一个不可变引用，所以字符串字面量也不可变其他类型的slice其他类型比如数组，也有slice，比如这段代码，把一个数组分成两个可变的数组slice，并分别调整它们的值，其中split_at_mut()函数可以把一个数组从指定mid位置分成两部分，分出来的两部分分别是[0,mid)，[mid,len)：fn main() { let mut a = [1, 2, 3]; let (part1, part2) = a.split_at_mut(2); part1[1] = 222; part2[0] = 333; for elem in a.iter() { println!(\"{}\", elem); } // 1 // 222 // 333}" }, { "title": "制作一个基于.NET原生Socket的WEB API转发工具(1) - TCP协议", "url": "/posts/socket-1/", "categories": "编程基础, 计算机网络", "tags": "编程基础", "date": "2020-07-29 00:00:00 +0800", "snippet": " Socket编程是网络编程中的重中之重，.NET为我们提供了丰富，详细的类库为我们使用C#进行Socket编程提供帮助，这里作为学习，会尽可能使用相对基础的Socket类库，来完成整个程序的构建，首先我们来了解Socket，因为是直接学习Socket，对于更底层的协议不会推进得那么深入彻底，主要会介绍一些相对重要的概念，先了解TCP协议了解TCP协议先看结论TCP协议是面向连接的，可靠的...", "content": " Socket编程是网络编程中的重中之重，.NET为我们提供了丰富，详细的类库为我们使用C#进行Socket编程提供帮助，这里作为学习，会尽可能使用相对基础的Socket类库，来完成整个程序的构建，首先我们来了解Socket，因为是直接学习Socket，对于更底层的协议不会推进得那么深入彻底，主要会介绍一些相对重要的概念，先了解TCP协议了解TCP协议先看结论TCP协议是面向连接的，可靠的传输层协议什么是连接这里的连接不是指我们用网线进行的物理的连接，而是指一种逻辑上的连接，双方可以通过某种方式，访问到对方的资源，就称之为连接。那么为什么说这个连接是可靠的呢，为了了解，或者说印证这个结论，先让我们了解TCP的报文格式TCP报文报文(message)，用百度百科上的话来说 报文(message)是网络中交换与传输的数据单元，即站点一次性要发送的数据块。报文包含了将要发送的完整的数据信息，其长短很不一致，长度不限且可变。通俗的说，就是通信双方在通信中每次要发送的数据，这个整体，我们称之为报文，我们先来看一个TCP报文的格式从左上部分到右下部分依次开始了解：Source Port &amp; Destination Port：端口号 - 源计算机上应用程序的端口号和目标计算机上应用程序的端口号，都分别占16位Sequence Number：序列号 - 32位无符号整数，在TCP传输中，传输的字节流中的每个字节都会被编号，当SYN(后面会介绍什么是SYN)为1时，即建立连接时，这个字段的值是一个初始值，也被称为ISN(initialization sequence number)，当SYN不为1时，是传输数据段中第一个字节的序列号Acknowledgement Number：确认号 - 也是32位无符号整数，表示接受方期望收到发送方下一个报文数据段的第一个字节数据的编号，其值是接收计算机即将接收到的下一个序列号Data Offset：数据偏移量 - 占4位，指数据段中的需要的数据部分起始处距离TCP数据段的字节偏移量，告诉接收端的应用程序，数据从何处开始Reserved：保留字段，占4位，为TCP将来的发展预留空间，目前必须全部为0标志位字段(关于标志位字段的定义这里是完全从网络资料复制的，因为对前面三个标志位体会还不是很深)： CWR（Congestion Window Reduce）：拥塞窗口减少标志，用来表明它接收到了设置 ECE 标志的 TCP 包。并且，发送方收到消息之后，通过减小发送窗口的大小来降低发送速率。 ECE（ECN Echo）：用来在 TCP 三次握手时表明一个 TCP 端是具备 ECN 功能的。在数据传输过程中，它也用来表明接收到的 TCP 包的 IP 头部的 ECN 被设置为 11，即网络线路拥堵。 URG（Urgent）：表示本报文段中发送的数据是否包含紧急数据。URG=1 时表示有紧急数据。当 URG=1 时，后面的紧急指针字段才有效。 ACK：表示前面的确认号字段是否有效。ACK=1 时表示有效。只有当 ACK=1 时，前面的确认号字段才有效。TCP 规定，连接建立后，ACK 必须为 1。 PSH（Push）：告诉对方收到该报文段后是否立即把数据推送给上层。如果值为 1，表示应当立即把数据提交给上层，而不是缓存起来。 RST：表示是否重置连接。如果 RST=1，说明 TCP 连接出现了严重错误（如主机崩溃），必须释放连接，然后再重新建立连接。 SYN：在建立连接时使用，用来同步序号。当 SYN=1，ACK=0 时，表示这是一个请求建立连接的报文段；当 SYN=1，ACK=1 时，表示对方同意建立连接。SYN=1 时，说明这是一个请求建立连接或同意建立连接的报文。只有在前两次握手中 SYN 才为 1。 FIN：标记数据是否发送完毕。如果 FIN=1，表示数据已经发送完成，可以释放连接。窗口大小字段窗口大小（Window Size）：占 16 位。它表示从 Ack Number 开始还可以接收多少字节的数据量，也表示当前接收端的接收窗口还有多少剩余空间。该字段可以用于 TCP 的流量控制。TCP 校验和字段校验位（TCP Checksum）：占 16 位。它用于确认传输的数据是否有损坏。发送端基于数据内容校验生成一个数值，接收端根据接收的数据校验生成一个值。两个值必须相同，才能证明数据是有效的。如果两个值不同，则丢掉这个数据包。Checksum 是根据伪头 + TCP 头 + TCP 数据三部分进行计算的。紧急指针字段紧急指针（Urgent Pointer）：仅当前面的 URG 控制位为 1 时才有意义。它指出本数据段中为紧急数据的字节数，占 16 位。当所有紧急数据处理完后，TCP 就会告诉应用程序恢复到正常操作。即使当前窗口大小为 0，也是可以发送紧急数据的，因为紧急数据无须缓存。可选项字段选项（Option）：长度不定，但长度必须是 32bits 的整数倍。讲到这里，大家肯定还是对这些报文在TCP连接中有什么用，它们为什么使TCP连接变得可靠有疑惑，接下来我们会对这个过程进行详细分析，在分析之前，先让我们简单了解一个概念，HTTP协议HTTP协议(摘自知乎回答)HTTP协议即超文本传送协议(Hypertext Transfer Protocol )，是Web联网的基础，也是手机联网常用的协议之一，HTTP协议是建立在TCP协议之上的一种应用。HTTP连接最显著的特点是客户端发送的每次请求都需要服务器回送响应，在请求结束后，会主动释放连接1。从建立连接到关闭连接的过程称为“一次连接”。抓包分析根据前文的知识，我们已经知道，HTTP是一个基于TCP的应用层协议，在一次正常的HTTP请求的开始到结束，都会完成建立连接，数据传输，释放连接这一完整的过程，那么我们只需要分析一个完整的HTTP请求，再进行分析，就可以得出相应的结论了抓包分析，顾名思义，就是对网络传输过程中的一些数据包进行抓取分析，为了用尽量简单的工具和尽量快捷的步骤来完成这个分析过程，我们在一台CentOS的服务器上完成这个抓包分析的过程首先，我们使用tcpdump命令，这是一个可以帮助我们对网络数据包进行抓取分析的命令tcpdump -nn -X -S -i eth0 port 80命令中用到的参数：-nn：在展示结果中显示目标IP地址和端口号，-X：tcpdump 会打印每个包的头部数据, 同时会以16进制和ASCII码形式打印出每个包的数据，-S：在抓包的内容中会显示绝对序列号而不是相对序列号，-i：指定要监视的网卡，默认只会监听第一个网卡，port：指定抓取源或者目的端口是80的包使用这条命令后，会进入到抓取监视界面，此时我们打开一个新的窗口，使用curl命令，这个命令帮助我们对www.douban.com发出一次GET请求curl www.douban.com此时，查看tcpdump抓包结果(这边直接贴上来应该会看得眼花，如果看不清，建议粘贴到VSCode等可以全屏显示的地方，或者自己操作一遍，也能体会得更深刻)01:40:16.950097 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [S], seq 470463866, win 29200, options [mss 1460,sackOK,TS val 120066337 ecr 0,nop,wscale 7], length 0 0x0000: 4500 003c a45b 4000 4006 b7e0 c0a8 0024 E..&lt;.[@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b57a 0000 0000 .......P...z.... 0x0020: a002 7210 deae 0000 0204 05b4 0402 080a ..r............. 0x0030: 0728 1121 0000 0000 0103 0307 .(.!........01:40:16.979743 IP 154.8.131.171.80 &gt; 192.168.0.36.41968: Flags [S.], seq 1101183244, ack 470463867, win 43440, options [mss 1440,sackOK,TS val 599874893 ecr 120066337,nop,wscale 9], length 0 0x0000: 4500 003c 0000 4000 2f06 6d3c 9a08 83ab E..&lt;..@./.m&lt;.... 0x0010: c0a8 0024 0050 a3f0 41a2 b90c 1c0a b57b ...$.P..A......{ 0x0020: a012 a9b0 b604 0000 0204 05a0 0402 080a ................ 0x0030: 23c1 5d4d 0728 1121 0103 0309 #.]M.(.!....01:40:16.979758 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [.], ack 1101183245, win 229, options [nop,nop,TS val 120066367 ecr 599874893], length 0 0x0000: 4500 0034 a45c 4000 4006 b7e7 c0a8 0024 E..4.\\@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b57b 41a2 b90d .......P...{A... 0x0020: 8010 00e5 dea6 0000 0101 080a 0728 113f .............(.? 0x0030: 23c1 5d4d #.]M01:40:16.979812 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [P.], seq 470463867:470463945, ack 1101183245, win 229, options [nop,nop,TS val 120066367 ecr 599874893], length 78: HTTP: GET / HTTP/1.1 0x0000: 4500 0082 a45d 4000 4006 b798 c0a8 0024 E....]@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b57b 41a2 b90d .......P...{A... 0x0020: 8018 00e5 def4 0000 0101 080a 0728 113f .............(.? 0x0030: 23c1 5d4d 4745 5420 2f20 4854 5450 2f31 #.]MGET./.HTTP/1 0x0040: 2e31 0d0a 5573 6572 2d41 6765 6e74 3a20 .1..User-Agent:. 0x0050: 6375 726c 2f37 2e32 392e 300d 0a48 6f73 curl/7.29.0..Hos 0x0060: 743a 2077 7777 2e64 6f75 6261 6e2e 636f t:.www.douban.co 0x0070: 6d0d 0a41 6363 6570 743a 202a 2f2a 0d0a m..Accept:.*/*.. 0x0080: 0d0a ..01:40:17.009390 IP 154.8.131.171.80 &gt; 192.168.0.36.41968: Flags [.], ack 470463945, win 85, options [nop,nop,TS val 599874923 ecr 120066367], length 0 0x0000: 4500 0034 e586 4000 2f06 87bd 9a08 83ab E..4..@./....... 0x0010: c0a8 0024 0050 a3f0 41a2 b90d 1c0a b5c9 ...$.P..A....... 0x0020: 8010 0055 8d90 0000 0101 080a 23c1 5d6b ...U........#.]k 0x0030: 0728 113f .(.?01:40:17.009393 IP 154.8.131.171.80 &gt; 192.168.0.36.41968: Flags [P.], seq 1101183245:1101183620, ack 470463945, win 85, options [nop,nop,TS val 599874923 ecr 120066367], length 375: HTTP: HTTP/1.1 301 Moved Permanently 0x0000: 4500 01ab e587 4000 2f06 8645 9a08 83ab E.....@./..E.... 0x0010: c0a8 0024 0050 a3f0 41a2 b90d 1c0a b5c9 ...$.P..A....... 0x0020: 8018 0055 4fb5 0000 0101 080a 23c1 5d6b ...UO.......#.]k 0x0030: 0728 113f 4854 5450 2f31 2e31 2033 3031 .(.?HTTP/1.1.301 0x0040: 204d 6f76 6564 2050 6572 6d61 6e65 6e74 .Moved.Permanent 0x0050: 6c79 0d0a 4461 7465 3a20 5375 6e2c 2030 ly..Date:.Sun,.0 0x0060: 3220 4175 6720 3230 3230 2031 373a 3430 2.Aug.2020.17:40 0x0070: 3a31 3620 474d 540d 0a43 6f6e 7465 6e74 :16.GMT..Content 0x0080: 2d54 7970 653a 2074 6578 742f 6874 6d6c -Type:.text/html 0x0090: 0d0a 436f 6e74 656e 742d 4c65 6e67 7468 ..Content-Length 0x00a0: 3a20 3136 320d 0a43 6f6e 6e65 6374 696f :.162..Connectio 0x00b0: 6e3a 206b 6565 702d 616c 6976 650d 0a4b n:.keep-alive..K 0x00c0: 6565 702d 416c 6976 653a 2074 696d 656f eep-Alive:.timeo 0x00d0: 7574 3d33 300d 0a4c 6f63 6174 696f 6e3a ut=30..Location: 0x00e0: 2068 7474 7073 3a2f 2f77 7777 2e64 6f75 .https://www.dou 0x00f0: 6261 6e2e 636f 6d2f 0d0a 5365 7276 6572 ban.com/..Server 0x0100: 3a20 6461 650d 0a0d 0a3c 6874 6d6c 3e0d :.dae....&lt;html&gt;. 0x0110: 0a3c 6865 6164 3e3c 7469 746c 653e 3330 .&lt;head&gt;&lt;title&gt;30 0x0120: 3120 4d6f 7665 6420 5065 726d 616e 656e 1.Moved.Permanen 0x0130: 746c 793c 2f74 6974 6c65 3e3c 2f68 6561 tly&lt;/title&gt;&lt;/hea 0x0140: 643e 0d0a 3c62 6f64 793e 0d0a 3c63 656e d&gt;..&lt;body&gt;..&lt;cen 0x0150: 7465 723e 3c68 313e 3330 3120 4d6f 7665 ter&gt;&lt;h1&gt;301.Move 0x0160: 6420 5065 726d 616e 656e 746c 793c 2f68 d.Permanently&lt;/h 0x0170: 313e 3c2f 6365 6e74 6572 3e0d 0a3c 6872 1&gt;&lt;/center&gt;..&lt;hr 0x0180: 3e3c 6365 6e74 6572 3e6e 6769 6e78 3c2f &gt;&lt;center&gt;nginx&lt;/ 0x0190: 6365 6e74 6572 3e0d 0a3c 2f62 6f64 793e center&gt;..&lt;/body&gt; 0x01a0: 0d0a 3c2f 6874 6d6c 3e0d 0a ..&lt;/html&gt;..01:40:17.009406 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [.], ack 1101183620, win 237, options [nop,nop,TS val 120066396 ecr 599874923], length 0 0x0000: 4500 0034 a45e 4000 4006 b7e5 c0a8 0024 E..4.^@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b5c9 41a2 ba84 .......P....A... 0x0020: 8010 00ed dea6 0000 0101 080a 0728 115c .............(.\\ 0x0030: 23c1 5d6b #.]k01:40:17.009480 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [F.], seq 470463945, ack 1101183620, win 237, options [nop,nop,TS val 120066396 ecr 599874923], length 0 0x0000: 4500 0034 a45f 4000 4006 b7e4 c0a8 0024 E..4._@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b5c9 41a2 ba84 .......P....A... 0x0020: 8011 00ed dea6 0000 0101 080a 0728 115c .............(.\\ 0x0030: 23c1 5d6b #.]k01:40:17.039006 IP 154.8.131.171.80 &gt; 192.168.0.36.41968: Flags [F.], seq 1101183620, ack 470463946, win 85, options [nop,nop,TS val 599874953 ecr 120066396], length 0 0x0000: 4500 0034 e588 4000 2f06 87bb 9a08 83ab E..4..@./....... 0x0010: c0a8 0024 0050 a3f0 41a2 ba84 1c0a b5ca ...$.P..A....... 0x0020: 8011 0055 8bdc 0000 0101 080a 23c1 5d89 ...U........#.]. 0x0030: 0728 115c .(.\\01:40:17.039013 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [.], ack 1101183621, win 237, options [nop,nop,TS val 120066426 ecr 599874953], length 0 0x0000: 4500 0034 a460 4000 4006 b7e3 c0a8 0024 E..4.`@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b5ca 41a2 ba85 .......P....A... 0x0020: 8010 00ed dea6 0000 0101 080a 0728 117a .............(.z 0x0030: 23c1 5d89 #.].来，让我们先冷静一下，我们可以看到，这些消息是分段的，每一个片段以时间，IP开头，每一段就是我们刚刚介绍的TCP报文，从上往下看，我们先看这一部分01:40:16.950097 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [S], seq 470463866, win 29200, options [mss 1460,sackOK,TS val 120066337 ecr 0,nop,wscale 7], length 0 0x0000: 4500 003c a45b 4000 4006 b7e0 c0a8 0024 E..&lt;.[@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b57a 0000 0000 .......P...z.... 0x0020: a002 7210 deae 0000 0204 05b4 0402 080a ..r............. 0x0030: 0728 1121 0000 0000 0103 0307 .(.!........01:40:16.979743 IP 154.8.131.171.80 &gt; 192.168.0.36.41968: Flags [S.], seq 1101183244, ack 470463867, win 43440, options [mss 1440,sackOK,TS val 599874893 ecr 120066337,nop,wscale 9], length 0 0x0000: 4500 003c 0000 4000 2f06 6d3c 9a08 83ab E..&lt;..@./.m&lt;.... 0x0010: c0a8 0024 0050 a3f0 41a2 b90c 1c0a b57b ...$.P..A......{ 0x0020: a012 a9b0 b604 0000 0204 05a0 0402 080a ................ 0x0030: 23c1 5d4d 0728 1121 0103 0309 #.]M.(.!....01:40:16.979758 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [.], ack 1101183245, win 229, options [nop,nop,TS val 120066367 ecr 599874893], length 0 0x0000: 4500 0034 a45c 4000 4006 b7e7 c0a8 0024 E..4.\\@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b57b 41a2 b90d .......P...{A... 0x0020: 8010 00e5 dea6 0000 0101 080a 0728 113f .............(.? 0x0030: 23c1 5d4d #.]M首先，每一段的开头的形如IP 192.168.0.36.41968 &gt; 154.8.131.171.80这样格式的内容，包含了我们之前在报文中提到的源端口和目标端口，这里还显示了IP地址，不过我们需要知道的是，真实的TCP报文中是不会携带IP地址的，这是属于网络层的IP数据报包含的内容。这里这段话告诉我们，这个TCP报文，是从IP地址192.168.0.36的41968端口发往154.8.131.171的80端口，即从我们的客户端发往豆瓣上面贴出来的内容分三段，我们主要解析从Flags开始的内容： 首先Flags中的中括号代表每次传输时的标志位，这里是标志位是SYN2，即SYN = 1，ACK = 03，代表发起了一次新建连接的请求，seq是序列号，在首次传输时，这里初始化了一个随机序列号4470463866，也就是我们之前提到的ISN 接着，豆瓣向我们返回了一个报文，标志位是SYN + ACK，SYN表示豆瓣也和我们建立起一个连接，ACK表示我们之前的报文已经确认送达了，这里的seq是豆瓣那边初始化的随机序列号1101183244，并且报文中ack，即确认号，为之前我们携带的那个序列号 + 1，即470463866 + 1 = 4704638675 最后，我们这边向豆瓣回复了一个报文，标志位为ACK，确认号为1101183244 + 1 = 1101183245，确认收到了来自豆瓣的连接请求，连接建立 以上的过程，就是我们经常说的，TCP的三次握手，用一张图来表示再来看中间的内容：01:40:16.979812 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [P.], seq 470463867:470463945, ack 1101183245, win 229, options [nop,nop,TS val 120066367 ecr 599874893], length 78: HTTP: GET / HTTP/1.1 0x0000: 4500 0082 a45d 4000 4006 b798 c0a8 0024 E....]@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b57b 41a2 b90d .......P...{A... 0x0020: 8018 00e5 def4 0000 0101 080a 0728 113f .............(.? 0x0030: 23c1 5d4d 4745 5420 2f20 4854 5450 2f31 #.]MGET./.HTTP/1 0x0040: 2e31 0d0a 5573 6572 2d41 6765 6e74 3a20 .1..User-Agent:. 0x0050: 6375 726c 2f37 2e32 392e 300d 0a48 6f73 curl/7.29.0..Hos 0x0060: 743a 2077 7777 2e64 6f75 6261 6e2e 636f t:.www.douban.co 0x0070: 6d0d 0a41 6363 6570 743a 202a 2f2a 0d0a m..Accept:.*/*.. 0x0080: 0d0a ..01:40:17.009390 IP 154.8.131.171.80 &gt; 192.168.0.36.41968: Flags [.], ack 470463945, win 85, options [nop,nop,TS val 599874923 ecr 120066367], length 0 0x0000: 4500 0034 e586 4000 2f06 87bd 9a08 83ab E..4..@./....... 0x0010: c0a8 0024 0050 a3f0 41a2 b90d 1c0a b5c9 ...$.P..A....... 0x0020: 8010 0055 8d90 0000 0101 080a 23c1 5d6b ...U........#.]k 0x0030: 0728 113f .(.?01:40:17.009393 IP 154.8.131.171.80 &gt; 192.168.0.36.41968: Flags [P.], seq 1101183245:1101183620, ack 470463945, win 85, options [nop,nop,TS val 599874923 ecr 120066367], length 375: HTTP: HTTP/1.1 301 Moved Permanently 0x0000: 4500 01ab e587 4000 2f06 8645 9a08 83ab E.....@./..E.... 0x0010: c0a8 0024 0050 a3f0 41a2 b90d 1c0a b5c9 ...$.P..A....... 0x0020: 8018 0055 4fb5 0000 0101 080a 23c1 5d6b ...UO.......#.]k 0x0030: 0728 113f 4854 5450 2f31 2e31 2033 3031 .(.?HTTP/1.1.301 0x0040: 204d 6f76 6564 2050 6572 6d61 6e65 6e74 .Moved.Permanent 0x0050: 6c79 0d0a 4461 7465 3a20 5375 6e2c 2030 ly..Date:.Sun,.0 0x0060: 3220 4175 6720 3230 3230 2031 373a 3430 2.Aug.2020.17:40 0x0070: 3a31 3620 474d 540d 0a43 6f6e 7465 6e74 :16.GMT..Content 0x0080: 2d54 7970 653a 2074 6578 742f 6874 6d6c -Type:.text/html 0x0090: 0d0a 436f 6e74 656e 742d 4c65 6e67 7468 ..Content-Length 0x00a0: 3a20 3136 320d 0a43 6f6e 6e65 6374 696f :.162..Connectio 0x00b0: 6e3a 206b 6565 702d 616c 6976 650d 0a4b n:.keep-alive..K 0x00c0: 6565 702d 416c 6976 653a 2074 696d 656f eep-Alive:.timeo 0x00d0: 7574 3d33 300d 0a4c 6f63 6174 696f 6e3a ut=30..Location: 0x00e0: 2068 7474 7073 3a2f 2f77 7777 2e64 6f75 .https://www.dou 0x00f0: 6261 6e2e 636f 6d2f 0d0a 5365 7276 6572 ban.com/..Server 0x0100: 3a20 6461 650d 0a0d 0a3c 6874 6d6c 3e0d :.dae....&lt;html&gt;. 0x0110: 0a3c 6865 6164 3e3c 7469 746c 653e 3330 .&lt;head&gt;&lt;title&gt;30 0x0120: 3120 4d6f 7665 6420 5065 726d 616e 656e 1.Moved.Permanen 0x0130: 746c 793c 2f74 6974 6c65 3e3c 2f68 6561 tly&lt;/title&gt;&lt;/hea 0x0140: 643e 0d0a 3c62 6f64 793e 0d0a 3c63 656e d&gt;..&lt;body&gt;..&lt;cen 0x0150: 7465 723e 3c68 313e 3330 3120 4d6f 7665 ter&gt;&lt;h1&gt;301.Move 0x0160: 6420 5065 726d 616e 656e 746c 793c 2f68 d.Permanently&lt;/h 0x0170: 313e 3c2f 6365 6e74 6572 3e0d 0a3c 6872 1&gt;&lt;/center&gt;..&lt;hr 0x0180: 3e3c 6365 6e74 6572 3e6e 6769 6e78 3c2f &gt;&lt;center&gt;nginx&lt;/ 0x0190: 6365 6e74 6572 3e0d 0a3c 2f62 6f64 793e center&gt;..&lt;/body&gt; 0x01a0: 0d0a 3c2f 6874 6d6c 3e0d 0a ..&lt;/html&gt;..01:40:17.009406 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [.], ack 1101183620, win 237, options [nop,nop,TS val 120066396 ecr 599874923], length 0 0x0000: 4500 0034 a45e 4000 4006 b7e5 c0a8 0024 E..4.^@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b5c9 41a2 ba84 .......P....A... 0x0020: 8010 00ed dea6 0000 0101 080a 0728 115c .............(.\\ 0x0030: 23c1 5d6b #.]k 首先，我们向豆瓣发送了一个标志位为PSH和ACK的报文，注意看这里包开始有内容和length，我们先看内容，可以看到这里是一个HTTP的GET请求，length，也就是数据的字节长度是78，seq的值是470463867:470463945，代表这个报文的数据的首字节的序号是470463867，接收方期望接收到的下一个报文的首字节的序号是4704639456，ack的值依然是1101183245，表示希望接收到的豆瓣的下一个包的seq是1101183245 接着，豆瓣回复了我们一个报文，标志位为ACK，ack值是470463945，里面没有任何数据，代表豆瓣接收到了我们的报文，并且希望下一个收到的我们的报文的首字节序列号是470463945 然后，豆瓣又发送给我们一个标志位为PSH和ACK的报文，length是375，seq是 1101183245:1101183620，ack是470463945，内容中可以看到，豆瓣响应并返回了我们一个HTTP报文，里面含有HTTP报头和一些HTML内容，通过之前的分析，我们可以用一句话来概括，这个报文的首字节序列号是1101183245，豆瓣希望接收到的下一个包的首字节序列号是470463945，不出意外的话，我们回复给豆瓣的ack值应该是1101183620 最后，我们回复给豆瓣一个标志位为ACK的报文，ack的值是1101183620，表示我们收到了豆瓣的报文这个，就是数据发送与接收的过程，我们依然用一个图来表示看最后的一段：01:40:17.009480 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [F.], seq 470463945, ack 1101183620, win 237, options [nop,nop,TS val 120066396 ecr 599874923], length 0 0x0000: 4500 0034 a45f 4000 4006 b7e4 c0a8 0024 E..4._@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b5c9 41a2 ba84 .......P....A... 0x0020: 8011 00ed dea6 0000 0101 080a 0728 115c .............(.\\ 0x0030: 23c1 5d6b #.]k01:40:17.039006 IP 154.8.131.171.80 &gt; 192.168.0.36.41968: Flags [F.], seq 1101183620, ack 470463946, win 85, options [nop,nop,TS val 599874953 ecr 120066396], length 0 0x0000: 4500 0034 e588 4000 2f06 87bb 9a08 83ab E..4..@./....... 0x0010: c0a8 0024 0050 a3f0 41a2 ba84 1c0a b5ca ...$.P..A....... 0x0020: 8011 0055 8bdc 0000 0101 080a 23c1 5d89 ...U........#.]. 0x0030: 0728 115c .(.\\01:40:17.039013 IP 192.168.0.36.41968 &gt; 154.8.131.171.80: Flags [.], ack 1101183621, win 237, options [nop,nop,TS val 120066426 ecr 599874953], length 0 0x0000: 4500 0034 a460 4000 4006 b7e3 c0a8 0024 E..4.`@.@......$ 0x0010: 9a08 83ab a3f0 0050 1c0a b5ca 41a2 ba85 .......P....A... 0x0020: 8010 00ed dea6 0000 0101 080a 0728 117a .............(.z 0x0030: 23c1 5d89 #.]. 首先，我们往豆瓣发送了一个标志位为FIN和ACK的报文，首字节序列号是470463945，确认号是1101183620，代表我们收到了豆瓣前面传送的报文，并且表示数据已经发送完毕，可以释放连接 接着，豆瓣也向外面发送了一个标志位为FIN和ACK的报文，首字节序列号是1101183620，确认号是470463946(这里为什么+1，在前文建立连接的时候有过注释)，也向我们表示可以释放连接 最后，我们这边回复给豆瓣一个标志位为ACK的报文，确认号是1101183621，至此，连接完全关闭一些常见的问题： 为什么需要握手，为什么是三次根据RFC793上的描述，之所以需要握手来建立连接，因为TCP需要seq序列号来做可靠重传或接收，为此需要互相确认对方的ISN。那么为什么是三次呢，如果是两次行不行，客户端发送SYN告知服务器自己的ISN，服务器再返回SYN + ACK，确认客户端的序列号并告知客户端自己的ISN，很显然，这样没有客户端还没确认服务器的ISN，双方并没有建立起可靠的连接，如果是四次行不行呢，客户端SYN - 服务器ACK - 服务器 SYN - 客户端ACK，肯定是可以的，之所以是三次，是因为服务器ACK+服务器SYN可以合并成一个步骤，也就是说，最少要三次握手2.为什么需要挥手，为什么是四次挥手，为什么这次抓包是三次挥手为什么需要挥手呢，所谓挥手，其实也就是断开连接，其实不难理解握手是一个双方建立连接的过程，在这个过程中双方会在彼此的操作系统中开辟一些资源用于传输用(初始化一些结构，缓冲区等)，使得双方可以通过某种连接访问到对方的资源，而挥手，就是释放连接，释放资源的过程。那么为什么是四次挥手呢，因为TCP是全双工(Full Duplex)的，所谓全双工，就是指可以同时进行信号的双向传输，因此当第一次挥手：客户端第一次发送含有FIN的报文给服务器时，仅仅代表客户端不会再发报文给服务器了，但服务器仍然可以接收报文；第二次挥手：服务器在收到客户端含有FIN的报文时，可能还有数据报文需要发送给客户端，为了让客户端不会因为没有及时收到应答继续发送FIN报文，所以先发送ACK报文告知客户端已经收到其要断开连接的请求；第三次挥手：服务器处理完所有要处理的报文之后，发送FIN报文给客户端，并进入LAST_ACK状态；第四次挥手：客户端发送ACK报文，服务器释放连接那么为什么这次的抓包结果是客户端FIN + ACK - 服务器FIN + ACK - 客户端 ACK这样，三次挥手呢，因为这边服务器在接收到客户端的FIN报文之后也是直接关闭，没有任何后续操作的，所以这里FIN和ACK没有必要进行间隔，直接合并在一起发送了Socket是什么 这部分本来打算单独写一篇，但是因为需要特别理解的，和值写的不多，就合并到这里来了概念浅析Socket直译成“孔”或“插座”，作为进程之间的一种通信机制，通常也被称为“套接字”，是用于描述IP地址和端口号的通信链的句柄。要满足套接字这个概念，必须给出四个元组，一端的Ip+port 和另一端的ip+port，是在整个互联网中唯一表示的，唯一表示互联网中两个程序之间的通信 ，操作系统可以分配的最大的端口号是65535问：当一台服务器已经和另一台服务器建立了65536个(0号端口也能用)连接之后，还能不能和其它服务器建立连接答：能，因为连往的IP是不同的，还是能唯一表示不同的通信问：如果服务器就一台，另一台物理服务器要对其进行一个压力测试，测试其并发数，要怎么做答：使用虚拟IP，不断用不同的IP去与其建立连接通俗的讲，人与人之间可以通过打电话来进行通信，程序与程序之间要进行通信，互相收发数据，就需要通过Socket来通信，所以不难理解为什么需要描述IP地址和端口号，把电话区号当作IP地址，后面的部分当作端口号，这样构成的一个完整的 电话号码，才能和确切的某一个人进行通话 在这个过程中，协议可以理解成打电话时双方沟通时用的语言，这篇里简单了解，TCP协议是面向连接的，是流式(STREAM)的，每次传输都需要建立三次握手，确保通信过程不会出现数据丢失 UDP协议是无连接的，是数据报式(DATAGRAM)的，不安全(丢失，顺序混乱，在接收端要分析重排及要求重发)，但效率高，在传输视频的时候通常使用UDP其实这里的知识，在了解TCP的时候已经有很多可以体会到了，比如为什么必须有四元组，为什么TCP是面向连接的可靠的传输协议，不过因为是先写了一部分这篇，才去写第一篇关于TCP的知识，所以这一部分还是留下来了，不想太过于深究TCP知识，直接看这里也可以 从HTTP/1.1起，默认都开启了Keep-Alive，保持连接特性，简单地说，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。 &#8617; 工具中的标志位显示的是简写，不难看出，S是SYN，.是ACK，F是FIN &#8617; 有哪个标志位，在数据内容上的表示，就是将哪个标志位置为1，否则的话则为0，也就是不带这个标志位 &#8617; 为什么初始序列号需要随机，其实想想不难明白，主要有两个原因，如果初始序列号是硬编码1.假如由于各种原因，有一个包在网络中停留太久，本次连接已经结束了，又建立了一个新的连接，在新的连接建立完之后，这个包才到达目标地址上的端口，此时序列号就很容易和新建立起的序列号撞上，正确的数据包就可能被判定为重复包而被丢弃；2.容易被伪造IP地址的他人，通过使用一样的序列号发包 &#8617; 在回复SYN和FIN报文的时候，为什么要把确认号设置为收到的报文的seq + 1作为ack，而不直接用seq呢，收到的报文数据长度是0呀，而且直接用seq也能标识，这边找了许多资料，最终找到了一个比较信服的说法：SYNs and FINs require acknowledgement, thus they increment the stream’s sequence number by one when used.For example, if the connection is closed without sending any more data, then if the FIN did not consume a sequence number the closing end couldn’t tell the difference between an ACK for the FIN, and an ACK for the data that was sent prior to the FIN. 意思是说，SYN和FIN之所以会将序列号增加一个，是需要做确认，例：如果确认FIN之后，seq没有加1，则无法区分哪些是关闭前发送的数据，哪些是关闭之后发送的数据 &#8617; 注意这里期望接收到的下一个包的首字节的序号这个说法，通过观察这里的首字节号和长度不难看出，最后一个字节的字节号不是后面这个数字，所以这个数字代表的是接收方的ack值，其实这个值在报文里面是不会携带的，报文中携带的seq只是数据包第一个字节的序号，这里之所以有是工具为了方便我们查看前后关系 &#8617; " }, { "title": "Rust学习笔记(1) - 常见编程概念", "url": "/posts/rust-1/", "categories": "编程语言, Rust", "tags": "Rust", "date": "2020-07-28 00:00:00 +0800", "snippet": " 推进Rust的学习，之前有零散学习过，现在系统做些笔记，主要是看Rust程序设计语言常见编程概念变量与可变性不可变(immutable)变量，可变(mutable)变量，常量(constants)Rust中的变量默认是不可变的(immutable)，要声明可变变量，可以在其之前加mut来声明，可以用const关键字声明常量，常量可以在任何作用域，包括全局作用域中声明// 定义一个常量，命...", "content": " 推进Rust的学习，之前有零散学习过，现在系统做些笔记，主要是看Rust程序设计语言常见编程概念变量与可变性不可变(immutable)变量，可变(mutable)变量，常量(constants)Rust中的变量默认是不可变的(immutable)，要声明可变变量，可以在其之前加mut来声明，可以用const关键字声明常量，常量可以在任何作用域，包括全局作用域中声明// 定义一个常量，命名规范通常为用下划线分隔的大写字母单词，且必须注值的类型const MAX_POINTS:u32 = 100_000;fn main() { // 简单定义一个变量，定义后，其值不可改变 let immutable_int = 500; // 定义一个可变变量，这里在编译时会有警告，提示没有必要让其可变 let mut mutable_int = 6; println!(\"定义了一个可变变量{}，一个不可变变量{}，一个常量{}\",mutable_int,immutable_int,MAX_POINTS);}变量隐藏(Shadowing)可以定义一个与之前变量同名的新变量来隐藏之前的变量，这意味着使用这个变量时会看到第二个值fn main() { // 简单定义一个变量，定义后，其值不可改变 let immutable_int = 500; // 使用相同变量名，隐藏之前定义的变量 let immutable_int = 501; let immutable_int = 502; // 编译时，会弹出警告，提示上方两个变量从未使用过 println!(\"一个变量{}\",immutable_int);}当再次使用let时，实际上创建了一个新变量，只是复用了之前变量的名字，这个变量可以是不同类型的变量，使用mut，则不能用不同类型的变量赋值fn main() { // 定义一个字符串变量 let spaces = \" \"; // 用同样的变量名，得到这个字符串的长度 let spaces = spaces.len(); // 因为这个字符串有两个空格，最后这个变量的值是2 println!(\"最后变量的值是{}\",spaces);}数据类型Rust是静态类型(statically typed)语言，在编译时就必须知道所有变量的类型，当可能会是多种类型时，必须增加类型注解，例如：let num = \"2\";let num = num.parse().expect(\"这不是一个数字！\");这里在parse时，必须添加类型注解，说明编译器需要更多信息，写成：let num = \"2\";let num: u32 = num.parse().expect(\"这不是一个数字！\");就能编译通过了标量(scalar)类型标量(scalar)类型代表一个单独的值，Rust有四种基本的标量类型：整型、浮点型、布尔型和字符类型整型 长度 有符号 无符号 8-bit i8 u8 16-bit i16 u16 32-bit i32 u32 64-bit i64 u64 128-bit i128 u128 arch isize usize 有无符号代表数字能否为负值，有符号数以补码形式(two’s complement representatin)存储，如果变体使用的位数为n，则变体可以用的值包含从2的n-1次方的相反数到2的n-1次方-1在内的数，所以i8可以储存从-128到-127在内的数。无符号的变体可以存储从0到2的n次方-1的数，所以u8可以储存从0到255在内的数另外，isize和usize类型依赖运行程序的计算机架构：64位架构上它们是64位，32位架构上它们是32位除byte以外的所有数字字面量允许使用类型后缀，也允许使用_作为分隔符以方便读数，这里有一个表格 数字字面值 例子 Decimal (十进制) 98_222 Hex (十六进制) 0xff Octal (八进制) 0o77 Binary (二进制) 0b1111_0000 Byte (单字节字符)(仅限于u8) b'A' 例子：fn main() { let num = 2u8; let decimal_num = 9_8222; let hex_num = 0xff; let octal_num = 0o77; let binary_num = 0b1111_0000; let byte = b'A'; // 将输出2,98222,255,63,240,65 println!(\"{},{},{},{},{},{}\",num,decimal_num,hex_num,octal_num,binary_num,byte);}Rust的默认数字类型是i32，它通常是最快的，甚至在64位系统上也是，当使用一个整型变量存放超过其容量的值，会发生整型溢出(integer overflow)浮点型Rust有两个原生的浮点数(floating-point numbers)类型，它们是带小数点的数字，分别是f32和f64，占32位和64位。默认类型是f64，因为在现代CPU中，它与f32速度几乎一样，不过精度更高(f32是单精度浮点数，f64是双精度浮点数)。数值运算Rust中的所有数字类型都支持基本数学运算：加减乘除和取余，注意当整数和浮点数一起运算时，运算符两边的数值的类型要保持一致，需要均为浮点型或均为整型fn main() { let num = 2; let num = num + 6; let num = num - 1; let num = num * 10; let num = num as f32 / 2.5 ; let num = num % 5.0;}布尔型Rust中有两个布尔型：true和false，布尔类型用bool表示字符类型Rust中的char类型大小为四字节，并代表了一个Unicode标量值（Unicode Scalar Value），这意味着它可以比 ASCII 表示更多内容。在 Rust 中，拼音字母（Accented letters），中文、日文、韩文等字符，emoji（绘文字）以及零长度的空白字符都是有效的 char 值。Unicode 标量值包含从 U+0000 到 U+D7FF 和 U+E000 到 U+10FFFF 在内的值。不过，“字符” 并不是一个 Unicode 中的概念，所以人直觉上的 “字符” 可能与 Rust 中的 char 并不符合。fn main() { let c = '1'; let c = '数'; let c = '😀';}复合类型复合类型(Compound types)可以将多个值组合成一个类型。Rust有两个原生的复合类型：元组(tuple)和数组(array)元组类型元组是将多个其他类型的值组合进一个复合类型的主要方式，一旦声明，其长度固定，元组的定义：let tup = (1.2, 3, 4);// 添加了类型注解的元组let tup:(f64,u32,u32) = (1.2,3,4);可以使用模式匹配(pattern matching)来解构(destructure)元组值，或者用.来直接访问元组内的值：fn main() { let tup = (1.2, 3, 4); // 解构元组，不需要的值可以用_来充当占位符 let(_,y,_) = tup; println!(\"The value of y is {}\",y); println!(\"元组中的第一个值是{}\",tup.0);}数组类型与元组不同，数组(array)中的每个元素的类型必须相同，且Rust中的数组是固定长度的，一旦声明，其不能增长或缩小，几种声明数组的方式：fn main() { let months = [ \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\", ]; // 在定义时规定数组元素的类型和元素个数 let nums: [u32; 5] = [1, 2, 3, 4, 5]; // 创建一个每个元素都相同的数组，分号前面是数组中元素的值，后面是元素的个数 let repeat_nums = [3; 5];}访问数组元素：fn main() { let nums = [1, 2, 3, 4, 5]; println!(\"数组的第一个元素是{}\", nums[0]);}函数如何工作Rust中的函数和变量名使用snake case规范风格，所有字母都是小写并使用下划线分隔单词定义函数Rust中函数定义是以fn开头的，并且必须声明每个参数的的类型fn print_one_number(number_be_printed: i32) { println!(\"{}\", number_be_printed);}包含语句和表达式的函数体在了解这个概念之前，要先理解Rust是一门基于表达式(expression-based)的语言，具体来说，语句(Statements)是执行一些操作但不返回值的命令，表达式(Expressions)计算并产生一个值，直接来看一些例子：fn main() { // 这是一个语句，我们不能将其赋值给另一个变量，比如写成let x = (let num=6) // 这里5是一个表达式，其计算出的值是6 let num = 6; // 5 + 6是一个表达式，其计算出的值是11 let num = 5 + 6; // 大括号{}也是一个表达式，其包含的代码块被绑定到y上 // 表达式的结尾没有分号，如果在表达式的结尾加上分号，它就变成了语句 let y = { let x = 3; x + 1 };}虽然在例子中已经写了，但是还是要强调，表达式的结尾是没有分号的，其表示一个计算的过程，如果加上分号，就变成了语句，不会返回值具有返回值的函数在Rust中，函数的返回值等同于函数体最后一个表达式的值，并且要在箭头(-&gt;)后声明它的类型fn main() { let num = plus_one(5); println!(\"The value of num is:{}\", num);}fn plus_one(num: i32) -&gt; i32 { num + 1}注释关于注释，没有特别的地方，在前面加上//即可，放在行前，会持续到那一行结束，也可以放在代码行的行尾控制流if与else iffn main() { // 计算if表达式的值并返回给变量 let num = if 1 + 1 &gt; 2 { 5 } else { 6 }; // else if的使用 if num % 2 == 0 { print!(\"0\") } else if num % 2 == 1 { print!(\"1\") } else { print!(\"no match condition\"); }}循环使用loops重复执行代码loop关键字会让Rust重复执行代码到明确要求停止fn main() { let mut nums = 0; // 循环直到break表达式被触发，或程序结束 loop { println!(\"continue\"); nums += 1; if nums &gt; 5 { break; } }}从循环返回结果通过break表达式，可以从循环中返回结果fn main() { let mut num = 0; // 循环直到break语句被触发，或程序结束 loop { println!(\"continue\"); num += 1; if num &gt; 5 { break; } } let result = loop { println!(\"not yet\"); num += 1; if num &gt; 10 { break num } }; print!(\"the result is {}\", result);}" }, { "title": "数据库范式学习笔记", "url": "/posts/foundation-3/", "categories": "编程基础, 关系型数据库", "tags": "编程基础, DBMS", "date": "2020-07-20 00:00:00 +0800", "snippet": " 了解数据库范式，作为关系数据库表设计的理论基础之一，主要学习了知乎上的文章——数据库第一二三范式到底在说什么？，这篇只是重新整理归纳，同时作为个人梳理思路，大部分内容和示例来自该文章范式什么是范式数据库的范式(normal forms)，在讨论时通常被缩写成NF，指的是关系数据库内部数据联系的合理化程度，文中1总结为一张表的表结构所符合的某种设计标准的级别，级别从低到高分1NF，2NF，...", "content": " 了解数据库范式，作为关系数据库表设计的理论基础之一，主要学习了知乎上的文章——数据库第一二三范式到底在说什么？，这篇只是重新整理归纳，同时作为个人梳理思路，大部分内容和示例来自该文章范式什么是范式数据库的范式(normal forms)，在讨论时通常被缩写成NF，指的是关系数据库内部数据联系的合理化程度，文中1总结为一张表的表结构所符合的某种设计标准的级别，级别从低到高分1NF，2NF，3NF，BCNF，4NF，5NF。在日常关系数据库设计中，通常最多考虑到BCNF就足够，至于为什么，在了解完范式之后，会在文章后面进一步讨论反范式第一范式(1NF)先看定义和结论：符合1NF的关系中的每个属性都不可再分，也就是说，如果一张表是符合1NF的，那么其每个字段都是独立的，没有包含其它字段的，所有关系型数据库系统(RDBMS)的表设计，都是符合1NF的，看图可以理解：不符合1NF的表设计： 编号 品名 进货 销售 备注 数量 单价 数量 单价 &nbsp; 符合1NF的表设计： 编号 品名 进货数量 进货单价 销售数量 销售单价 备注               第二范式(2NF)直接来看这个表： 学号 姓名 系名 系主任 课名 分数 95001 李勇 数学系 张清玫 复变函数 80 95001 李勇 数学系 张清玫 大学英语 90 95001 李勇 数学系 张清玫 数学分析 70 95002 刘晨 计算机系 刘逸 数据结构 65 95002 刘晨 计算机系 刘逸 Java程序设计 90 95002 刘晨 计算机系 刘逸 数据库原理 65 95003 王敏 数学系 张清玫 复变函数 80 95003 王敏 数学系 张清玫 红楼梦赏析 85 2NF在1NF的基础上，消除了非主属性对于码的部分函数依赖函数依赖：若在一张表中，在属性(或属性组)X的值确定的情况下，必然能确定属性Y的值，就可以说Y函数依赖与X函数依赖又分三种：完全函数依赖：在一个属性的值确定的情况下，必然能确定属性Y的值部分函数依赖：若属性Y不完全依赖于一个属性组(大于一个属性)X，则Y部分函数依赖于X传递函数依赖：假如Z函数依赖于Y，且Y函数依赖于X，则Z传递依赖于X主属性，非主属性，码码是一个概念，若X为表中的一个属性或属性组，若除X之外所有的属性都完全函数依赖与X，则X就是这个表的码，一个表可以有多个码主属性/非主属性：包含在任意一个码中的属性称为主属性，不包含在任何一个码中的属性称为非主属性现在让我们来分析上方表的内部关系因为其它属性都完全函数依赖于学号或课名，只需要这两个属性确定了，则可以确定表中的所有其它内容，所以这个表的码是(学号，课名)非主属性是：姓名，系名，系主任，分数为了消除非主属性对于码的部分函数依赖，使其满足2NF范式，这种让表满足更高范式的行为，称为模式分解分解过程：可以看到，除了分数之外(分数需要学号和课名一起确定)，因为姓名，系名，系主任是部分函数依赖于码的，我们需要消除这一部分函数依赖，所以把表拆为学生信息表： 学号 姓名 系名 系主任         分数表： 学号 课名 分数       可以看到通过模式分解把码中的属性拆分到不同的表，消除了非主属性对码的部分依赖，使其满足了2NF范式第三范式(3NF)3NF：消除非主属性对码的传递依赖观察发现因为系主任完全函数依赖于系名，系名完全函数依赖于学号，所以这里存在传递依赖关系，将其进一步进行模式分解分解后的表为：学生表： 学号 姓名 系名       成绩表： 学号 课名 分数       系别表： 系名 系主任     BC范式(BCNF)BCNF：消除主属性对于码的部分与传递函数依赖换句话说就是在2NF和3NF时对非主属性做的操作，现在要对主属性也检查并操作一次直接看例子： 仓库名 管理员 物品名 数量         主属性为仓库名，管理员，物品名因为存在仓库名对于(管理员，物品名)的部分函数依赖，所以其不满足BCNF范式，拆分为仓库信息表： 仓库名 管理员     库存表 仓库名 物品名 数量       反范式与范式2反范式顾名思义，就是不完全遵循数据库范式的数据库表设计，在反范式化的数据库中，信息是抗御的，可能会存在多个地方高范式的优缺点从性能角度上来说，尤其是写密集的场景，一个满足更高范式的数据库常常有以下优势： 范式化的更新操作通常比反范式要快 当数据较好地范式化时，就只有很少或者没有重复数据，所以只需要修改更少的数据。 范式化的表通常更小，可以更好地放在内存里，所以执行操作会更快 很少有多余的数据意味着检索数据时需要DISTINCT或者GROUP BY语句范式化设计的表的缺点是通常需要关联，稍微复杂一些的查询语句在符合范式的数据表上需要至少一次或更多关联，这不但代价昂贵，也可能使一些索引策略无效。例如，范式化可能将列存放在不同的表中，而这些列如果在一个表中本可以属于同一个索引反范式的优缺点优点：避免了关联，在大部分大量查询的情况中，比关联要快，因为避免了随机I/O，单独的表也能使用更有效的索引策略混用范式化和反范式化完全的范式化和完全的反范式化设计都是实验室里才有的东西，在真实情况中很少会这么极端的使用，一些有必要的冗(rong，三声)余经常被用来辅助索引或者统计等 文中均指的文章一开头说明的知乎文章 &#8617; 摘自高性能MYSQL(第三版) &#8617; " }, { "title": "自己创建一个Jekyll项目", "url": "/posts/jekyll-2/", "categories": "Jekyll相关", "tags": "jekyll", "date": "2020-07-15 00:00:00 +0800", "snippet": " 之前的Jekyll主题是Fork别人的，最近学了一些前端知识，正好可以动手自己美化博客，所以重新建了一个Jekyll项目，并把之前的posts转移到了这里使用Jekyll创建Github Pages这篇本来是想介绍这个二级标题的内容的，好吧，仔细想了想，其实官方文档已经说得很清楚了，就不做仅仅类似翻译或者搬运的事了。根据官方文档做完之后，就能拥有一个属于自己的Github Pages了，...", "content": " 之前的Jekyll主题是Fork别人的，最近学了一些前端知识，正好可以动手自己美化博客，所以重新建了一个Jekyll项目，并把之前的posts转移到了这里使用Jekyll创建Github Pages这篇本来是想介绍这个二级标题的内容的，好吧，仔细想了想，其实官方文档已经说得很清楚了，就不做仅仅类似翻译或者搬运的事了。根据官方文档做完之后，就能拥有一个属于自己的Github Pages了，还是从这篇开始着重讲后续的美化过程吧" }, { "title": "关于HTML - 元素的布局与定位(float，绝对定位，CSS表格)", "url": "/posts/html-3/", "categories": "前端知识", "tags": "HTML, CSS", "date": "2020-07-15 00:00:00 +0800", "snippet": " 在对HTML元素，CSS样式的基础有了解之后，终于到了激动人心的布局与定位的时候了，这里光是看文字不容易理解，会在这里展示布局的方式和过程，并把示例直接写在这里需求现在想通过一些布局知识，仿制一个博客园这样的布局，可以看到其大体分为四个部分，上面的导航栏，左下方的文章列表及摘要，右下方的公告，以及悬浮在界面上的小火箭组成，在那之前，先让我们来了解一些知识流(Flow)流指的是网页中元素在...", "content": " 在对HTML元素，CSS样式的基础有了解之后，终于到了激动人心的布局与定位的时候了，这里光是看文字不容易理解，会在这里展示布局的方式和过程，并把示例直接写在这里需求现在想通过一些布局知识，仿制一个博客园这样的布局，可以看到其大体分为四个部分，上面的导航栏，左下方的文章列表及摘要，右下方的公告，以及悬浮在界面上的小火箭组成，在那之前，先让我们来了解一些知识流(Flow)流指的是网页中元素在页面上的一种显示规则，利用流的特性来设计的网页，是流式布局(liquid layouts)的，要了解流，先让我们看一个示例页面，根据这个界面，可以总结出： 块元素在页面从上到下逐个显示，每两个元素之间默认添加一个空格，这就是流在块元素中的体现 内联元素总体的流向是从左上方流向右下方 观察两个相邻的元素不难看出，在流中，两个相邻内联元素的左右外边距不会合并，会是各自的左右外边距，两个相邻块元素的上下外边距会合并浮动元素：float属性 为什么要先理解流呢，因为浮动元素和流息息相关，float属性可以尽可能远地向左或者向右(根据float的值)浮动一个元素。然后它下面的所有内容会绕流这个元素(像流体一样绕这个元素流动)依然用一个示例界面来展示这一过程观察页面，可以总结出： 如果希望一个元素浮动，通常首先要为其设置一个宽度，从而控制其显示的范围 当一个元素浮动之后，其会从正常的流中被忽略，块级元素会直接穿过它，不会进行换行，内联元素在遇到它时会围绕着它进行布局 通过设置clear属性，可以让对应元素的指定方向不存在浮动元素，解决元素重叠的问题 可以固定界面元素宽度，使屏幕无论怎么调整，设计依然保持原样，直接忽略用户拉伸窗口造成的流的变化，这种布局叫做冻结布局(frozen layouts) 凝胶(Jello)布局在冻结布局的基础上设置了左右外边距为auto，其依然锁定页面中内容区的宽度，将它在浏览器中居中，但是由于浏览器自动填充外边距，使得界面依然具有一些伸缩性绝对定位(absolute positioning)和固定定位(fixed positioning) 一个元素绝对定位时，浏览器将其从流中完全删除，然后将其放置在使用top，right，bottom，left指定的位置上，对于绝对定位元素来说，谁的z-index值越大，谁显示在越上层。当一个元素固定定位时，其位置是相对浏览器边界固定的，无论什么行为都无法改变其位置示例界面使用CSS创建表格显示 通过设置div的display属性为table，可以将其作为一个表格来显示其中包含的元素，其中的行的display属性设置为table-row，单元格的属性为table-cell，并可以通过在表格整体属性中设置border-spacing属性来设置其内部元素的外边距示例界面设计界面通过前面对布局的了解，我们已经有能力了解到博客园的布局方式，并且仿制一个和它一样的布局了(示例页面)，这里采用了float来做主要布局方式，并固定主要元素区的宽度，让浏览器自动填充外边距，这次主要只是对布局进行摆放，细节部分需要许多素材，这篇就讲到这里" }, { "title": "数据库系统(1) - 辅助存储管理", "url": "/posts/foundation-2/", "categories": "编程基础, 关系型数据库", "tags": "编程基础, DBMS", "date": "2020-07-14 00:00:00 +0800", "snippet": " 整理数据库系统(主要是关系数据库系统1)学习过程中的相关知识点，主要学习书籍：数据库系统实现辅助存储(辅存)管理在操作一个数据库系统的时候，其本质其实就是对于辅助存储的管理，要了解辅存的相关内容，我们先要了解一些知识：存储器层次典型的计算机系统包括几个不同的可以储存数据的部件，这些部件中，最小容量的设备提供了最快的访问速度，也具有相对最高的每个字节的价格，这里用一张知乎回答上的表格 ...", "content": " 整理数据库系统(主要是关系数据库系统1)学习过程中的相关知识点，主要学习书籍：数据库系统实现辅助存储(辅存)管理在操作一个数据库系统的时候，其本质其实就是对于辅助存储的管理，要了解辅存的相关内容，我们先要了解一些知识：存储器层次典型的计算机系统包括几个不同的可以储存数据的部件，这些部件中，最小容量的设备提供了最快的访问速度，也具有相对最高的每个字节的价格，这里用一张知乎回答上的表格 存储系统 内存存储器(内存，interal memory) 寄存器(register) 在CPU内部 高速缓冲处理器(cache) 现在一般集成在CPU内部 主存储器(主存，main memory) (其最大可利用空间由地址总线宽度决定) 内存条 显卡中的RAM芯片 接口卡中ROM芯片 等等 外部存储器/辅助存储器(外存(external memory)/辅存(secondary memory)) 硬盘 U盘 光盘 等等 在存储器层次间传送数据正常情况下，数据在相邻层之间进行传输，我们这里姑且分为：第一层：高速缓存处理器，第二层(主存储器)，第三层(外部存储器)，在第二层和第三层之间访问想要的数据或查找指定的位置用于存储数据会耗费大量时间。对于理解数据库系统非常重要的知识是，磁盘的最小物理存储单元是扇区(物理上的概念)，由于操作系统难以对数目众多的扇区寻址，所以把相邻扇区组合在一起，划分成磁盘块(簇)，磁盘块是一个虚拟的概念，是软件上的概念。操作系统以块为单位操作磁盘。整个块被从一个成为缓冲区的连续内存区域中移进移出，加速数据库的关键技术就在于如何安排好数据，使得每次磁盘块中有数据被访问时，访问的块上面有我们需要的所有数据。易失和非易失存储器易失的(volatile)和非易失的(nonvolatile)存储器的区别在于能否在断电的情况下保存数据，对于非易失的设备来说，其中的数据往往是可以在不断电的情况下长期保存的，磁和光材料满足这个条件，原则上讲，所有辅存设备都是非易失的，关于这里有一个和DBMS系统很重要的联系是，一个DBMS系统往往要求在修改被存储到辅存之前，其任何修改都不是最终有效的。虚拟存储器(Virtual Memory)虚拟存储器，也就是平时说的虚拟内存，在逐渐流行的主存数据库(内存数据库)中被使用，它是一个地址空间，由操作系统管理，其一部分留在内存中，剩下的保存在磁盘中。是操作系统运用机器硬件的产物。通俗的说，电脑中运行的程序需要占用内存，当内存不够用的时候，电脑会自动调用硬盘来充当内存，把数据移动到被称为”分页文件”的空间中，释放RAM，从而继续工作，内存数据库就是利用了这一机制，通过虚拟内存来管理数据，通过页面机制把需要的数据带到主存。在数据量小到主存足以保存时，因为不需要不断从硬盘提取数据。磁盘 磁盘是计算机主要的存储介质，可以存储大量的二进制数据，并且断电后也能保持数据不丢失。早期计算机使用的磁盘是软磁盘（Floppy Disk，简称软盘），如今常用的磁盘是硬磁盘（Hard disk，简称硬盘）。2磁盘结构这里引用_尖尖毛草博客园博客中的图：磁盘组合(disk assembly)由一个或者多个圆盘(platter)组成，围绕一根中心轴旋转，每个圆盘的上下面涂覆了一层薄的磁性材料，二进制位被存储在这些磁性材料上。0和1在磁材料中表现为不同的模式。磁道(track)是单个盘面上的同心圆(图示深灰色部分)，所有盘面上半径相同的磁道构成了柱面(cylinder)，除了最靠近主轴的区域，磁道占据了大部分的盘面。为简化电路设计，规定每个磁道上的记录的位数是相同的，所以越靠近内圈，磁道周长最来越短，其位密度(单位长度的二进制位的个数)越来越大，磁道密度(沿磁盘半径方向单位长度上的磁道数)也越来越大。磁道又被组织成扇区(sector)，扇区是被间隙(gap)分隔的圆的片段，间隙是没有被磁化成0或1的。就磁盘错误而言，其是一个不可分隔的单位，如果一部分磁化层被以某种方式损坏，则整个扇区都不能继续使用了。间隙大约占整个磁道的10%，用于帮助标识扇区的起点，前面”在存储器层次间传送数据 “处提到的”块”，是逻辑单元，由一个或多个扇区组成。第一张图左边黑色部分所示的部件是磁头组合(head assembly)，它承载着磁头。每一个盘面都由一个及其贴近地悬浮在上面，不与盘面接触(否则会发生”头损毁”，盘片被破坏)的磁头。磁头读出经过它下面的盘面的磁方向，也能改变其磁方向，以便在上面写信息。所有磁头被固定在一个磁头臂上，所有盘面的磁头随磁头臂一起动。 例子：Megatron 747磁盘是一种典型的vintage-2008的大容量的驱动器，它具有下列特性： 8个圆盘，16个盘面 每个盘面由65,536(2的16次方)个磁道 每个磁道(平均)由256(2的8次方)个扇区 每个扇区由4096(2的12次方)个字节 整个磁盘容量的算法是16(盘面数)×65,536(磁道数)×256(扇区数)*4096(每扇区字节) = 2的40次方个字节，即其为以块1TB的硬盘，每个磁道存放256×4096个字节，即1MB磁盘控制器一个或多个磁盘驱动器被一个磁盘控制器控制，磁盘控制器是一个小处理器，能完成： 控制移动磁头组合(移动磁头臂)的机械马达，将磁头定位到特定的半径位置，使得某一柱面任何磁道都可以被读写 从磁头所在柱面的扇区中选择一个扇区，其会负责识别何时旋转主轴已经到达了所要求的扇区正移动到磁头下方的点 将所要求的扇区读取的二进制位传送到计算机的主存储器 尽可能将一条或更多磁道缓存于磁盘控制器的内存中，以期该磁道的许多扇区能被很快读取。从而避免对磁盘的额外访问磁盘存取特性存取(读或写)一个磁盘块要三个步骤，每个步骤都有相关延迟： 磁盘控制器将磁头组合定位在磁盘块所在磁道的柱面上所需的时间为寻道时间(seek time) 磁盘控制器等待访问块的第一个扇区旋转到磁头下。此时间成为旋转延迟(rotational latency) 当磁盘控制器读取或写数据时，数据所在的扇区和扇区间的空隙经过磁头，此时间称为传输时间(transfer time)寻道时间、旋转延迟和传输时间的总和称为磁盘的延迟(latency)一个典型磁盘的寻道时间取决于磁头到它要访问位置的距离，如果磁头已经位于所需柱面，则寻道时间是0，但需用大概1ms的时间启动磁头，约10ms的时间移过所有磁道典型的磁盘旋转一次大约需10ms。因此旋转延迟的是0~10ms，平均5ms。传输时间相对更小，在毫秒以下。当我们将这3种延迟相加，通常情况平均延迟是10ms，最大的延迟约为它的两倍加速对辅助存储器的访问因为可能从多个进程或者线程访问磁盘，所以并不等于每个应用程序，在请求发送到磁盘控制器后就能10ms左右拿到数据，在这种情况下，调度延迟(scheduling latency)可能会变得无穷大，所以改进吞吐量(系统能适应的每秒磁盘访问次数)，减少平均访问时间，加速数据库对磁盘的访问的技术就非常重要，比如： 将要一起访问的块放在同一柱面上，从而可以经常避免寻道时间，也可能避免旋转延迟。 1970年Ted Codd发表了一篇著名的论文(CODASYL Data Base Task Group April 1971 Report, ACM, New York)，里面认为数据库系统应该呈现给用户一种被组织成叫做”关系”的表的数据。在幕后，应该有一个复杂的数据结构，允许对各式各样的查询进行快速相应。关系数据库的程序员不需要关心存储及结构。查询可以用很高级的语言来表达，而SQL(结构化查询语言)就是这一基于关系模型的最重要的查询语言。 &#8617; 引用自百度百科 &#8617; " }, { "title": "常用的操作系统操作备忘", "url": "/posts/tips-2/", "categories": "经验技巧, 日常工具", "tags": "Tips", "date": "2020-07-14 00:00:00 +0800", "snippet": " 平时工作中，一些电脑快捷键操作会让工作效率大大提高，并且，也会让别人看来更有”逼格”。更多时候，当一个快捷键别人已经习以为常，而你居然不知道，被人用惊异的眼光看着的时候，自己也会暗自记住这些内容，虽然都是很简单的东西，大多数用过一次就记得了，考虑到可能会有想不起来的或者冷门的，每次遇到还是收集收集Windows 1 选中文件或者文件夹，按F2可以进入重命名操作，这一点在很多IDE也是如...", "content": " 平时工作中，一些电脑快捷键操作会让工作效率大大提高，并且，也会让别人看来更有”逼格”。更多时候，当一个快捷键别人已经习以为常，而你居然不知道，被人用惊异的眼光看着的时候，自己也会暗自记住这些内容，虽然都是很简单的东西，大多数用过一次就记得了，考虑到可能会有想不起来的或者冷门的，每次遇到还是收集收集Windows 1 选中文件或者文件夹，按F2可以进入重命名操作，这一点在很多IDE也是如此，选中代码文件按F2； Win10进入Wsl文件夹：\\\\wsl$ Shift + Delete完全删除文件 计算机管理 - 事件查看器 - Windows日志 - 应用程序，可以查看Windows上因为发生异常而终止的程的日志，比如可以在这里查看未经程序本身捕获的.NET运行时异常 取消管理员确认权限确认弹窗：控制面板 - 用户账户 - 用户账户 - 更改用户账户控制设置，在这里将提醒设置成从不通知，之后就不会再弹出相关弹窗了 清除电脑icon的缓存：ie4uinit.exe -ClearIconCache，Win10：ie4uinit.exe -show 关闭内置管理员账户的管理员批准模式，gpedit.msc - 计算机配置 - 安全设置 - 本地策略 - 安全选项 - 用户帐户控制：用于内置管理员帐户的管理批准模式选择已禁用即可，这样内置管理员帐户就能使用完整管理权限运行所有应用程序，而不会弹出提示让用户批准操作。此外，若禁用用户账户控制：以管理员批准模式运行所有管理员，则可以彻底关闭UAC的管理员审批模式 CMD：netstat -aon | find \":8001\"查找占用了指定端口（这里是8001）的进程信息 CMD：powershell，切换到PowerShell PowerShell：get-command，获取常用指令列表 PowerShell：Start-Process后面加路径名，打开指定文件（或文件夹） PowerShell: Remove-Item，后面加路径名，删除指定文件（或文件夹），可以跟-Recurse参数，则不进行提示直接删除 Win + [num]，打开工具栏上指定位置的程序，可以借助此方法快速启动很多程序 在资源监视器中，搜索关联的句柄，可以找到占用了指定文件的进程信息 PowerShell：echo $Env:&lt;variable name&gt;，输出指定的环境变量的值 CMD：cls，清空命令框内容 CMD: systeminfo，查看系统信息，可用于查看系统类型，在获取软件安装包时提供帮助 Windows服务相关操作： 安装：sc.exe create \"Service Name\" binpath=C:\\Path\\To\\ServiceName.exe 启动：sc.exe start \"Service Name\" 停止：sc.exe stop \"Service Name\" 删除：sc.exe delete \"Service Name 对于基于.NET Framework开发的Windows服务，还可以使用InstallUtil.exe进行Windows服务的相关操作，和上面提到的sc.exe相比，可以进行一些日志记录，已经在安装时执行一些自定义的代码。此外如果想使操作过程更便捷更自定义化，也可以考虑使用Topshelf等方案 使用Powershell也可以操作Windows服务，使用Get-Help -Name *-Service命令查看关于Windows服务的相关命令 Powershell: Use dir Env: to display all environment variables, the $Env: to display specific variable value, the $Env: =\"\" to set variable value Out-GridView: Sends output to an interactive table in a separate window.(copy from Get-Help) Select-Object: Selects objects or object properties.(eg. Get-Service mysql Select-Object -Property *) Write your powershell functions in a scrpit module, make them easier to share:https://docs.microsoft.com/en-us/powershell/scripting/learn/ps101/10-script-modules?view=powershell-7.1 Powershell: 输出一个字符的Unicode，使用[int][char]'&lt;字符&gt;'，输出一个Unicode对应的字符，使用[char]Unicode&gt; 在Windows系统的Shell程序中输入EOF：Ctrl + Z 使用剪切板历史记录功能：Win + V 批量重命名文件夹下的所有文件，例如将所有markdown文件名全部转换为小写：Get-ChildItem *.md | Rename-Item -NewName {$_.Name.ToLower()}Linux 跳转到当前用户的home目录：cd ~ 跳转到上级目录：cd .. 跳转到上次的目录：cd - 跳转到根目录：cd / 解压缩命令：tar -zxvf &lt;filename&gt; -C &lt;target-path&gt;(其中zxvf都是tar的参数，z:通过gzip支持压缩或解压缩；x：解压缩；v：在压缩或解压缩过程中显示正在处理的文件名；f：跟要处理的文件名，-C后面跟要解压到的目录，在有需要时可以指定) 显示操作系统的发行版本号：uname -r 当前系统的信息所在位置：/etc/os-release 创建文件夹：mkdir -p，可以不加-p，加上之后，若创建时发现要创建文件夹的目录的上级目录有不存在的文件夹，会逐级对文件夹进行创建 查看指定端口是否被占用：netstat -anp |grep &lt;port&gt; 查看所有被占用的端口：netstat -nultp 安装C/C++编译环境（Debian系）：apt-get install build-essential，这个包会安装编译C/C++软件的所有依赖环境macOS通过指定软件打开文件：open filename -a application查看当前路径：pwd查看当前路径所有文件以及文件夹名：ls查看当前路径所有文件以及文件夹名（包括隐藏文件）：ls -a删除指定文件夹以及其中所有文件（-r：向下递归，无论多少级目录，一起删除，-f：强制删除，没有任何提示）：rm -rf 目录名复制文件到指定目标：cp -i file_copy_from file_copy_to将code指令添加到terminal：shift + command + P，输入shell command，然后选择Install 'code' command in PATHredo快捷键：shift + command + ZDocker安装镜像：docker pull {name}安装一个容器（以Redis为例）：docker run --name myredis -it -p 6379:6379 -v /data/redis-data redis --requirepass \"123456\"（-v这里指挂载到宿主机的目标文件夹,使用-p可以指定其他人可以用来访问的端口号）关闭一个容器：docker kill {name}开启一个容器：docker start {name}执行容器命令：docker exec -it {name} {command}（以Redis为例：docker exec -it myredis redis-cli -a \"your password\"） 没有特殊情况，这里默认指Win10 &#8617; " }, { "title": "Head First HTML与CSS(第二版)学习笔记(HTML+CSS)", "url": "/posts/html-2/", "categories": "前端知识", "tags": "HTML, CSS", "date": "2020-07-12 00:00:00 +0800", "snippet": " 前面对HTML基础知识做了了解，之后会结合CSS来构建，点此查看示例页面，因为HTML和CSS更多只是用来描述网页，涉及到需要理解的东西比较少，这里更多的只是读书笔记，会在示例页面中使用这里接触到的内容加一点样式：开始学习CSS CSS包含一些简单语句，称为规则。 每个规则为选择的一些HTML元素提供样式。 典型的规则包括一个选择器，以及一个或多个属性和值。 选择器指定规则将应用...", "content": " 前面对HTML基础知识做了了解，之后会结合CSS来构建，点此查看示例页面，因为HTML和CSS更多只是用来描述网页，涉及到需要理解的东西比较少，这里更多的只是读书笔记，会在示例页面中使用这里接触到的内容加一点样式：开始学习CSS CSS包含一些简单语句，称为规则。 每个规则为选择的一些HTML元素提供样式。 典型的规则包括一个选择器，以及一个或多个属性和值。 选择器指定规则将应用到哪些元素。 每个属性声明以一个分号结束。 规则中的所有属性和值都放在{ }大括号之间。 可以使用元素名作为选择器，来选择任意元素。 通过用逗号分割元素名，可以一次选择多个元素。 要在HTML中包含一个样式，最容易的办法就是使用&lt;style&gt;标记。 对于HTML以及相当复杂的网站，可能要链接到一个外部样式表。 &lt;link&gt;元素用于包含一个外部样式表。 很多属性都能继承。例如，如果为&lt;body&gt;元素设置了一个可继承的属性，那么&lt;body&gt;的所有子元素都会继承这个属性。 通过为你想改变的元素创建一个更特定的规则，能覆盖该元素继承的属性。 可以使用class属性将元素增加到一个类。 通过在元素名和类名之间加一个“.”，可以选择该类中的一个特定元素。 使用“.classname”可以选择属性这个类的所有元素。 通过在class属性中放入多个类名，可以指定一个元素属于多个类，类名之间用空格分割。 可以使用W3C验证工具验证CSS（https://jigsaw.w3.org/css-validator/）。扩大你的词汇量：字体和颜色样式 CSS提供了很多属性对字体的外观加以控制，包括font-family，font-weight，font-size和font-style。 font-family是一组有共同特征的字体。 用于Web的字体系列包括serif，sans-serif，monospace，cursive和fantasy。serif和sans-serif字体最为常用。 访问者在你的Web页面上看到字体取决于他们自己的计算机上安装了哪些字体，除非你使用Web字体。 在font-family CSS属性中指定候选字体是一个好主意，以防用户没有安装你的首选字体。 font-family:Verdana,Geneva,Arial,sans-serif; 最后一个字体要指定为一个通用字体，如serif或sans-serif，这样一来，如果找不到其他字体，浏览器可以替换适当的字体。 如果你要使用某种字体，而默认情况下用户可能没有安装这种字体，可以在CSS中使用@font-face规则。 字体大小通常使用像素、em、百分数或关键字指定。 如果使用像素（“px”）来指定字体大小，就是在告诉浏览器字母高度是多少像素。 em和%是相对字体大小，所以使用em和%指定字体大小时，就意味着字体大小相对于其父元素的字体大小指定。 使用相对字体大小可以让你的页面更可维护。 在body规则中使用字体大小关键字来设置基本字体大小，这样如果用户希望文本更大或更小，所有浏览器就能按比例缩放字体大小。xx-small、x-small、small、medium、large、x-large、xx-large 可以使用font-weight CSS属性设置文本为粗体。 font-style属性用于创建斜体或倾斜文本。斜体或倾斜文本是倾斜的。 Web颜色是混合不同数量的红、绿、蓝色得到。 如果混合红色100%，绿色100%和蓝色100%，可以得到白色。 如果混合红色0%，绿色0%和蓝色0%，可以得到黑色。 CSS有16个基本颜色，包括黑色、白色、红色、蓝色和绿色，以及150种扩展颜色。 可以使用红、绿、蓝百分数指定你想要的颜色，也可以使用红、绿、蓝数值（0~255）指定，或者使用颜色的十六进制码来指定颜色。 要找到你想要的一个颜色的十六进制码，有一种很容易的方法，可以使用一个照片编辑应用的颜色选择工具，或者某个在线Web工具，这样的工具有很多。 表示颜色的十六进制码有6位，每一位取值为0~F。前两位表示红色数量，接下来两位表示绿色数量，最后两位表示蓝色数量。 可以使用text-decoration属性为文本创建一个下划线。有下划线的文档通常会被用户误以为是链接文本，所以要谨慎使用这个属性。与元素亲密接触：盒模型 CSS使用一个盒模型来控制元素如何显示。 盒子由内容区和可选的内边距、边框和外边距组成。 内容区包含元素的内容。 内边距用来在内容区周围创建可见的空间。 边框包围内边距和内容，它提供了从视觉上分离内容的一种手段。 外边框包围边框、内边距和内容，允许在元素和其他元素之间增加空间。 内边距、边框和外边距都是可选的。 元素的背景会在内容和内边距下显示，但不会延伸到外边距下面。 内边距和外边距大小可以用像素或百分数设置。 边框宽度可以用像素设置，也就可以使用关键字thin、medium和thick来指定。 有8种不同的边框样式，包括实线、破折线、虚线和脊线。 对于外边距、内边距或边框，CSS提供了相应的属性，可以一次对所有四个边（上、右、下、左）完成设置，也可以单独设置任意一边。 使用border-radius属性可以对有边框的元素创建圆角。 使用line-height属性可以增加文本行之间的间距。 可以用background-image属性在元素的背景上放置图像。 使用background-position和background-repeat属性可以设置背景图像的位置和平铺行为。 对于希望成组指定样式的元素要使用class属性。 使用id属性为元素指定一个唯一的名字。还可以使用id属性为元素提供唯一的样式。 一个页面上有给定id的元素只能有一个。 可以使用id选择器按id选择元素，例如#myfavoriteid。 一个元素只能有一个id，不过它可以属于多个类。 在HTML中可以使用多个样式表。 如果两个样式表包含冲突的属性定义，HTML文件中最后链接的样式表最为优先。 可以在&lt;link&gt;元素中使用媒体查询或者使用CSS中的@media规则来指定设备。高级Web建设：div与span &lt;div&gt;元素用于将相关的元素归组在一起，放在逻辑区中。 创建逻辑区有助于标识主内容区以及页面的页眉和页脚。 可以使用&lt;div&gt;元素将需要共同样式的元素归组在一起。 使用嵌套&lt;div&gt;元素为文件增加更多结构，这有利于保证结构清晰或者方便增加样式。不过除非确实需要，否则不要过多地增加结构。 一旦用&lt;div&gt;元素将内容区归组在一起，类似于其他块元素，可以对这些&lt;div&gt;增加样式。例如，对包含在&lt;div&gt;中的一组元素，可以使用嵌入这些元素的&lt;div&gt;边框属性，对这组元素增加一个边框。 width属性设置一个元素内容区的宽度。 一个元素的总宽度是内容区宽度，加上所增加的内边距、边框和外边距的宽度。 一旦设置一个元素的宽度，它不会延伸来占满浏览器窗口的整个宽度。 text-align是块元素的一个属性，用来将这个块元素中的所有内容对齐，可以居中，左对齐或右对齐。这个属性可以由所有嵌套的块元素继承。 可以使用子孙选择器来选择嵌套在其他元素中的元素，例如，子孙选择器 div h2 {…} 会选择嵌套在&lt;div&gt;元素中的所有&lt;h2&gt;（包括子元素、孙子元素等）。 可以对相关的属性使用快捷方式。例如，padding-top、padding-right、padding-bottom和padding-left都与内边距有关，可以用一个快捷规则来指定：padding。 内边距、外边距、边框、背景和字体属性都可以用快捷方法指定。 &lt;span&gt;内联元素与&lt;div&gt;元素类似；它用于将相关的内联元素和文本归组在一起。 类似于&lt;div&gt;，可以将&lt;span&gt;元素增加到类（或者为&lt;span&gt;元素指定唯一的id），对它们增加样式。 有些元素有不同的状态，&lt;a&gt;元素就是这样一个例子。&lt;a&gt;元素的主要状态包括未访问、已访问和悬停。 可以用伪类单独地为各个状态指定样式。伪类最常用于&lt;a&gt;元素，:link对应未访问的链接，:visited对应已访问的链接，:hover对应悬停状态。 伪类还可以用于其他元素，而不仅限于&lt;a&gt;。 另外一些伪类包括:hover，:active，:focus，:first-child和last-child伪类等。摆放元素：布局与定位 这一章有一些东西需要辅助记忆，这里开一篇 浏览器使用流在页面中放置元素。 块元素从上向下流，各元素之间有一个换行。默认的，每个块元素会占浏览器窗口的整个宽度。 内联元素在块元素内部从左上方流向右下方。如果需要多行，浏览器会换行，在垂直方向上扩展外围块元素，来包含这些内联元素。 正常页面流中两个块元素上下相邻的外边距会折叠为最大外边距的大小，或者如果两个外边距大小相同，会折叠为一个外边距。 浮动元素会从正常流中取出，浮动到左边或右边。 浮动元素放在块元素之上，不会影响正常的页面流。不过，内联内容会考虑浮动元素的边界，围绕着这个浮动元素。 clear属性用来指定一个块元素左边或右边（或者左右两边）不能有浮动元素。设置了clear属性的块元素会下移，直到它旁边没有块元素。 浮动元素必须有特定的宽度width，不能设置为auto。 流体布局是指，扩展浏览器窗口时，页面中的内容会扩展以适应页面。 冻结布局是指，其中内容的宽度是固定的，不会随着浏览器窗口扩展或收缩。这有一个好处，可以对设计提供更多控制，不过也要付出代价，这样就不能有效地使用浏览器宽度了。 凝胶布局是指，其中内容的宽度是固定的，但是外边距会随着浏览器窗口扩展或收缩。凝胶布局通常会把内容放在中央，这与冻结布局有同样的好处，不过通常更美观。 position属性可以设置为4个值：static（静态）、absolute（绝对）、fixed（固定）和relative（相对）。 静态定位是默认方式，将元素放在页面给的正常流中。 绝对定位允许将元素放在页面上的任何位置。默认地，绝对定位元素会相对于页面边界来放置。注意：流元素并不知道绝对定位元素的存在，所以流元素中的内联内容不会围绕绝对定位元素。 如果一个绝对定位元素嵌套在另一个定位元素中，这个元素就会相对于外包含元素定位。 使用绝对、固定和相对定位时，属性top、right、bottom和left可以用来指定元素的位置。 绝对定位元素可以使用z-index属性分层放置，使一个元素在另一个元素上面。z-index值越大，说明它层次越高（在屏幕上离你越近）。 固定定位元素总是相对于浏览器窗口定位，页面滚动时，固定定位的元素不会移动。页面中的其他内容会在这些固定定位元素下面正常滚动。 相对定位元素首先正常流入页面，然后按指定的量偏移，从而留出它们原先所在的空间。 使用相对定位时，left、right、top和bottom是指距正常流中该元素位置的偏移量。 CSS表格显示允许按一种表格布局来摆放元素。 要创建CSS表格显示，需要使用对应表格的一个块元素，对应行的块元素，以及对应单元格的块元素。通常，这些块元素都是&lt;div&gt;元素。 如果需要建立多栏布局，而且内容栏是均匀的，表格显示就是一个很好的布局策略。现代HTML：HTML5标记 HTML5为HTML增加了很多新元素。 &lt;section&gt;、&lt;article&gt;、&lt;aside&gt;、&lt;nav&gt;、&lt;header&gt;和&lt;footer&gt;都是帮助你建立页面结构的新元素，与使用&lt;div&gt;相比，它们可以提供更多含义。 用于对相关的内容分组。 &lt;article&gt;用于类似博客帖子、论坛帖子和新闻报道等独立的内容。 &lt;aside&gt;用于表示不作为页面主内容的次要内容，如插图和边栏。 &lt;nav&gt;用于组织网站导航链接。 &lt;header&gt;将标题、logo和署名等通常放在页面或区块最上方的内容组织在一起。 &lt;footer&gt;将诸如文档信息、法律措辞和版权说明等通常放在页面或区块最下方的内容组织在一起。 &lt;time&gt;也是HTML5中的一个新元素。这个元素用来标记时间和日期。 &lt;div&gt;仍然用于建立结构。它通常将元素组织在一起来指定样式，或者有些内容可能不适合放在HTML5中那些与结构相关的新元素中，这些内容就可以使用&lt;div&gt;创建结构。 较早的浏览器不支持新的HTML5元素，所以一定要知道主要用户使用哪些浏览器访问你的Web页面，除非能确保新元素对你的用户适用，否则不要贸然使用这些新元素。 &lt;video&gt;是一个新的HTML元素，用于为页面增加视频。 视频编码是用来创建视频文件的编码，常用的视频编码包括h.264、Vp8和Theora。 视频容器文件包括视频、音频和元数据。流行的容器格式包括MP4、OGG和WebM。 要提供多个视频源文件，确保你的用户可以在他们的浏览器中观看你的视频文件。建立表格：表格与更多列表 HTML表格用来建立表格数据结构。 HTML表格元素&lt;table&gt;、&lt;tr&gt;、&lt;th&gt;和&lt;td&gt;一起用来创建一个表格。 &lt;table&gt;元素定义并包围整个表格。 表格使用&lt;tr&gt;元素按行定义。 每行包含一个或多个数据单元格，分别用&lt;td&gt;元素定义。 使用&lt;th&gt;元素表示作为行或列表头的数据单元格。 表格采用格状布局。每行对应HTML中的一个&lt;tr&gt;……&lt;/tr&gt;行，每列对应行中的&lt;td&gt;……&lt;/td&gt;内容。 可以用&lt;caption&gt;元素提供关于表格的额外信息。 表格有边框间距，也就是单元格之间的间距。 表格数据单元格还可以有内边距和边框。 就像能够控制元素的内边距、边框和外边距一样，可以用CSS控制表格单元格的内边距、边距和边框间距。 border-collapse是针对表格的一个特殊的CSS属性，允许将单元格边框合并为一个边框，让外观更简洁。 可以用text-align和vertical-align CSS属性改变表格单元格中数据的对齐方式。 可以用background-color属性为表格增加颜色。可以为整个表格、各行或者单个的数据单元格增加背景颜色。 使用CSS nth-child伪类可以为表格隔行增加背景颜色。 如果一个数据单元格没有数据，&lt;td&gt;元素中不放置任何内容。不过，需要使用一个&lt;td&gt;……&lt;/td&gt;元素维持表格的对齐。 如果你的数据单元格需要跨多行或多列，可以使用&lt;td&gt;元素的rowspan或colspan属性。 可以在表格中嵌套表格，将&lt;table&gt;元素及其所有内容放在一个数据单元格中。 表格应当于表示表格数据，而不是建立页面布局。另一方面，可以像第11章所介绍的，使用CSS表格显示创建多栏页面布局。 与所有其他元素一样，可以用CSS指定列表的样式。有几个特定于列表的CSS属性，如list-style-type和list-style-image。 list-style-type允许改变列表中使用的列表标记类型。 list-style-image允许指定列表标记图像。实现交互：HTML表单 &lt;form&gt;元素定义了表单，所有表单输入元素都嵌套在这个元素中。 action属性包含服务器脚本的URL。 method属性包含发送表单数据的方法，可以是POST或GET。 POST打包表单数据，并把它作为请求的一部分发送到服务器。 GET打包表单数据，并把数据追加到URL。 如果表单数据应当是私有的，或者表单数据很多，如使用了一个&lt;textarea&gt;或者file &lt;input&gt;元素，就应当使用POST。 对于可以加书签的请求，要使用GET。 &lt;input&gt;元素在Web页面上可以作为多种不同的输入控件，这取决于它的“type”属性值。 type为“text”时会创建一个单行文本输入框。 type为“submit”时会创建一个提交按钮。 type为“radio”时会创建一个单选钮。所有同名的单选钮构成一组互斥的按钮。 type为“checkbox”时会创建一个复选框控件。通过为多个复选框指定相同的名字，可以创建一组选择。 type为“number”时会创建一个只允许数字字符的单行文本输入控件。 type为“range”时会创建一个滑动条控件提供数字输入。 “color”类型会在支持这个类型的浏览器中创建一个颜色选择器（否则只会创建一个普通的文本输入控件）。 “date”类型会在支持这个类型的浏览器中创建一个日期选择器（否则只会创建一个普通的文本输入控件）。 “email”、“url”和“tel”类型会创建单行文本输入，在一些移动浏览器上会出现定制键盘来方便数据输入。 &lt;textarea&gt;元素会创建一个多行文本输入区。 &lt;select&gt;元素会创建一个菜单，包含一个或多个&lt;option&gt;元素。&lt;option&gt;元素定义了菜单中的菜单项。 如果文本放在&lt;textarea&gt;元素的内容中，这会成为Web页面上文本区控件中的默认文本。 text &lt;input&gt;元素中的value属性可以用来为单行文本输入控件提供一个初始值。 在提交按钮上设置value属性可以改变按钮上显示的文本。 提交一个Web表单时，表单数据值与相应的数据名匹配，所有名和值会发送到服务器。 由于表单有一个表格结构，通常会用CSS表格显示来建立表单布局。CSS还可以用来指定表单的颜色、字体风格、边框等样式。 HTML允许用&lt;fieldset&gt;元素组织表单元素。 可以用&lt;label&gt;元素以一种有助于提高可访问性的方式关联标签与表单元素。 使用placeholder属性可以为表单用户提供一个提示，指出你希望在一个输入域中输入什么内容。 required属性指示一个输入域是必要的，要让表单成功提交，这个输入域中必须有值。有些浏览器在你提交表单之前会强制要求在这些域中输入数据。" }, { "title": "Head First HTML与CSS(第二版)学习笔记(HTML相关)", "url": "/posts/html-1/", "categories": "前端知识", "tags": "HTML, CSS", "date": "2020-07-09 00:00:00 +0800", "snippet": " 开始学习HTML和CSS，以这本书为敲门砖，主要总结一些比较重点的知识，有必要的代码会敲一遍，在文章的源码中可以体现出来认识HTML 好吧，本来总结了挺多，没想到书里的章节末尾已经总结的比较详细了，而且关于这里确实没有太需要解释的地方，这里直接采用读一边书，然后摘抄一遍书里总结的内容的方式来加深印象 HTML和CSS是我们用来创建网页的语言 Web服务器存储并提供由HTML和CSS...", "content": " 开始学习HTML和CSS，以这本书为敲门砖，主要总结一些比较重点的知识，有必要的代码会敲一遍，在文章的源码中可以体现出来认识HTML 好吧，本来总结了挺多，没想到书里的章节末尾已经总结的比较详细了，而且关于这里确实没有太需要解释的地方，这里直接采用读一边书，然后摘抄一遍书里总结的内容的方式来加深印象 HTML和CSS是我们用来创建网页的语言 Web服务器存储并提供由HTML和CSS创建的网页，浏览器获取页面，并根据HTML和CSS显示网页的内容 HTML是超文本标记语言(HyperText Markup Language)的缩写，用来简历网页的结构 CSS是叠层样式表(Cascading Style)的缩写，用来控制HTML的表现 通过HTML，我们利用标记来标记内容提供结构。我们把匹配标记以及它们包围的内容称为元素 元素由3部分组成：一个开始标记，内容和一个技结束标记。不过有些元素(比如&lt;img&gt;)有所例外 开始标记可以有属性，我们已经见过一个属性：type 结束标记在左尖括号后面，标记名前面有一个/，以明确这是结束标记 所有页面都要有一个&lt;html&gt;元素，其中要有一个&lt;head&gt;元素和一个&lt;body&gt;元素 网页的信息放在&lt;head&gt;元素里 &lt;body&gt;元素里的内容就是你将在浏览器里看到的东西 大多数空白符(制表符、回车、空格)都会被浏览器忽略，不过可以利用空白符让你的HTML(对你)更有可读性 可以在&lt;style&gt;元素中写CSS规则，为HTML网页增加CSS。&lt;style&gt;元素总要放在&lt;head&gt;元素里 可以使用CSS在HTML中指定元素的特性认识HTML中的”HT” 想从一个页面链接到另一个页面时，要使用&lt;a&gt;元素 &lt;a&gt;元素的href属性指定了链接的目标文件 &lt;a&gt;元素的内容是链接的标签，这个标签就是你在网页上看到的链接文本，默认地，这个标签会有下划线，只是这里是可以单击的 文字或图像都可以用作链接的标签 单击一个链接时，浏览器会加载href属性中指定的Web页面 可以链接到相同文件中的文件，也可以链接到其他文件夹中的文件 相对路径是相对于子链接的源Web页面指向网站中其他文件的一个链接。就像在地图上一样，终点总是相对于起点。 使用”..”可以链接到源文件上一层文件夹中的一个文件 ..表示”父文件夹” 记住要用/(斜线)字符分隔路径中的各个部分 指向一个图像的路径不正确时，会在Web页面上看到一个损坏的图像 为网站选择的文件名和文件夹名中不要使用空格 最好在构建网站初期组织网站文件，这样就不用在网站升级时候修改一大堆的路径了 组织网站有很多种方法，具体如何组织由你决定例子：这是一个通往百度的链接Web页面建设 开始输入内容之前要规划好Web页面的结构，首先画出一个草图，然后创建一个略图，最后再写出HTML 规划页面时，首先设计大的块元素，然后再用内联元素完善 记住，要尽可能使用元素来告诉浏览器你的内容的含义 一定要使用与内容含义最接近的元素，例如，如果需要一个列表，就不要使用段落元素 &lt;p&gt;、&lt;blockquote&gt;、&lt;ol&gt;、&lt;ul&gt;和&lt;li&gt;都是块元素。它们单独显示，在内容前后分别一个换行(默认地) &lt;q&gt;和&lt;em&gt;是内嵌元素，这些元素中的内容与其包含元素的其余内容放在一起 需要插入你自己的换行时，可以使用&lt;br&gt;元素 &lt;br&gt;是一个”void”元素 void元素没有内容 void元素只有一个标记组成 “空”元素没有内容，不过它由开始和结束标记 嵌套元素是指完全包含在另一个元素中的元素。如果元素能正确地嵌套，所有标记都能正确匹配 要结合两个元素建立一个HTML列表，使用&lt;ol&gt;和&lt;li&gt;建立有序列表，使用&lt;ul&gt;和&lt;li&gt;可以建立一个无序列表 浏览器显示一个有序列表时，它会为列表创建序号，所以无需你费心 可以在列表中建立嵌套列表，将&lt;ol&gt;或&lt;ul&gt;元素放在&lt;li&gt;元素中 要对HTML内容中的特殊字符使用字符实体例子：这是一个引用块这是一个段落，是一个块元素；这是一个内嵌元素；这是一个内嵌的引用有序列表第一项第二项第三项无序列表第一项第二项第三项Web镇之旅 要把网站发布到Web上，可以找一家托管公司来托管你的Web页面 域名是一个唯一的名字，如amazon.com或starbuzzcoffee.com，用来唯一标识网站 托管公司可能会为你的域创建一个或多尔Web服务器。服务器通常命名为”www” 文件传输协议(File Transfer Protocol，FTP)是向服务器传输web页面和内容的常用方法 FTP应用提供了一个图形界面，使FTP的使用更为容易 URL是统一资源定位符或Web地址，可以用来标识Web上的任何资源 典型的URL由一个协议，一个网站名和资源的一个绝对地址组成 HTTP是一个请求和响应协议，用来在Web服务器和浏览器之间传送Web页面 浏览器使用file协议从你的计算机读取页面 绝对路径是从根文件夹到一个文件的路径 “index.html”和”default.htm”都是默认页面。如果指定一个目录而没有指定文件名，则Web服务器会朝朝一个默认界面返回到浏览器 &lt;a&gt;元素的href属性中可以使用相对路径或URL来链接其他Web页面。对于你的网站中的其他页面，最好使用相对路径，对外部链接才使用URL 可以用id属性在页面中创建一个目标。使用#后面加一个目标id，可以链接到页面中的那个位置 为了便于访问，可以在&lt;a&gt;元素中使用title属性提供链接的一个描述 使用target属性在另一个浏览器窗口中打开链接。不要忘了，对于使用各种不同设备和浏览器的用户，target属性可能会有问题例子：回到文章开头查看标签列表认识媒体 使用&lt;img&gt;元素在Web页面中放置图像。 浏览器对&lt;img&gt;元素的处理与其他HTML元素稍有不同。读取HTML页面之后，浏览器会从Web服务器获取各个图像并显示。 如果Web页面上有多个大图像，则可以通过创建图像的缩略图使你的Web页面更可用，下载也更快，缩略图是一些小图像（大图像的缩小版本），用户单击这些缩略图时可以看到原来的大图像。 &lt;img&gt;元素是一个内联元素，这说明浏览器不会在图像前后插入一个换行。 要利用src属性指定图像文件的位置。可以在src属性中使用相对路径包含你自己的网站中的图像，或者可以使用URL包含其他网站的图像。 &lt;img&gt;元素的alt属性是对图像的一个有意义的描述。在一些浏览器中，如果无法找到图像，就会显示这个描述，另外屏幕阅读器会使用这个属性为有视力障碍的人描述图像。 图像宽度要小于800像素，这是Web页面中关于照片大小的一个好经验。数码相机拍摄的大多数照片都太大，不能很好地放在Web页面中，所以需要调整它们的大小。 有很多照片编辑应用，Photoshop Elementsis就是其中之一，可以用来调整图像的大小。还可以使用很多免费的联机工具调整图像大小。可以在网上搜索“free online image editor”（免费联机图像编辑器）。 对于浏览器来说太大的图像会使Web页面很难使用，而且下载和显示都很慢。 JPEG、PNG和GIF是Web浏览器广泛支持的3种图像格式。 JPEG格式最适合保存照片和其他复杂图像。 GIF或PNG格式最适合保存logo和其他包含单色、线条或文本的简单图形。 JPEG图像可以按不同质量压缩，所以可以很好地权衡图像质量和文件大小，来满足你的需要。 GIF和PNG图像格式允许建立一个有透明背景的图像。如果把一个有透明背景的图像放在一个Web页面中，图像后面的东西（如页面的背景色）就会透过图像的透明部分显示出来。 GIF和PNG是无损格式，这说明相比于JPEG文件，这些格式的文件往往更大。 PNG可以提供比GIF更好的透明度控制，而且不像GIF只支持256种颜色，PNG可以支持更多颜色。 PNG有3种不同的大小选择：PNG-24（支持数百万种颜色）、PNG-16（支持数千种颜色），以及PNG-8（支持256种颜色），可以根据需要来选择。 在Photoshop Elements中，使用“Save for Web”（保存为Web格式）对话框中的Matte（蒙版）颜色菜单来选择合适的颜色，柔化PNG或GIF图像的边缘。 图像可以用作指向其他Web页面的链接。要由图像创建一个链接，可以使用&lt;img&gt;元素作为&lt;a&gt;元素的内容，将链接放在&lt;a&gt;元素的href属性中。例子：可以在新窗口中打开这张图片严肃的HTML HTML5是当前的HTML标准。 万维网协会（World Wide Web Consortium，W3C）是定义HTML标准的标准组织。 文档类型定义（doctype）用来告诉浏览器你使用的HTML版本。 HTML标准现在是一个“活的标准”，这说明这个标准会不断改变，加入新的特性和更新。 &lt;head&gt;元素中的&lt;meta&gt;标记告诉浏览器关于一个Web页面的额外信息，如内容类型和字符编码。 &lt;meta&gt;标记的charset属性告诉浏览器Web页面使用的字符编码。 大多数Web页面的HTML文件都使用utf-8编码，另外&lt;meta&gt;标记的charset属性值通常也是utf-8。 alt属性是&lt;img&gt;元素中的必要属性。 W3C验证工具是一个免费的在线服务，可以检查页面是否符合标准。http://validator.w3.org/ 可以使用这个验证工具确保你的HTML合法，而且元素和属性符合标准。 如果遵循标准，则你的页面会更快地显示，而且在不同浏览器中显示时差异会更小，CSS也能更好的工作。" }, { "title": "Blazor技术入门(1) - Blazor的简单介绍以及Blazor框架之间的区别", "url": "/posts/blazor/", "categories": "编程框架, ASP.NET Core", "tags": ".NET Core", "date": "2020-07-08 00:00:00 +0800", "snippet": " 最近在入门前端，并且有计划重写博客，这里选用了Blazor来作为这个计划的技术选型，一方面是为了了解这个算是比较新的技术，另一方面自己写小项目，用着也更顺手和快捷(用C#来与Web界面进行交互)WebAssembly(WASM)在了解Blazor之前，先让我们了解什么是WebAssembly，我们来看官方的定义： WebAssembly (abbreviated Wasm) is a ...", "content": " 最近在入门前端，并且有计划重写博客，这里选用了Blazor来作为这个计划的技术选型，一方面是为了了解这个算是比较新的技术，另一方面自己写小项目，用着也更顺手和快捷(用C#来与Web界面进行交互)WebAssembly(WASM)在了解Blazor之前，先让我们了解什么是WebAssembly，我们来看官方的定义： WebAssembly (abbreviated Wasm) is a binary instruction format for a stack-based virtual machine. Wasm is designed as a portable compilation target for programming languages, enabling deployment on the web for client and server applications.可以看到，WebAssembly是一种使用在Web客户端或者服务器端的字节码格式，大家知道在Web端，我们通常使用JS来操作网页，完成服务器和界面的交互行为等，但众所周知，JS是动态类型脚本语言，即使前后通过JIT的使用对其进行预编译，TypeScript对其加入类型检查，以及不断优化其引擎等，JS的速度已经变得越来越快，但是其在运行的时候才进行编译的本质还是没有变，编译器先高级语言编译成中间语言，最后再将其翻译成机器汇编语言并执行而WebAssembly，则可以当作更接近中间码的存在，其可以被快速编译成机器汇编码Blazor与WebAssembly那么，Blazor和WebAssembly有什么关联呢，通过微软文档和Blazor官方页面的介绍可以了解到说Blazor和WASM有关，主要是指Blazor WebAssembly与WASM的联系 Blazor WebAssemby是将 Blazor 应用、其依赖项以及 .NET 运行时下载到浏览器。 应用将在浏览器线程中直接执行，对于客户端来说，在浏览器中对Blazor应用进行操作就和本地操作一样，在需要与后端进行数据交互的时候可以使用Web API或者依然使用SignalR进行通信可以看出，Blazor WASM相当于把浏览器作为客户端，让编译出来的DLL基于.NET运行时，通过WASM运行，这样，就能通过C#与前端客户端实现交互两种Blazor框架之间的区别官方文档官方在这里对两种技术和他们各自的优缺点做了详细的介绍，从展示的图片中也可以很容易看出区别Blazor WebAssemblyBlazor ServerBlazor WebAssemblyWebAssemby，将 Blazor 应用、其依赖项以及 .NET 运行时下载到浏览器，是纯粹的SPA(单页面应用)。应用将在浏览器线程中直接执行，对于客户端来说，在浏览器中对Blazor应用进行操作就和本地操作一样，在需要与后端进行数据交互的时候可以使用Web API或者使用SignalR进行通信Blazor ServerBlazor Server，在服务器端将Html生成好，再发送整个页面到客户端，客户端使用SignalR与服务器端进行通信，缺点是在客户端进行的任何操作都要进行通信，延迟比较高，同时因为需要管理与多个客户端的连接，服务器压力较大，用户量多的时候不建议使用总结Blazor是一个使用 .NET 生成交互式客户端 Web UI 的框架，其主要的特征是使用 C# 代替 JavaScript 来创建丰富的交互式 UI以及Razor的应用，其中Blazor wasm程序，是完全托管在客户端的。Blazor Service程序则是把HTML渲染好，再发送到客户端，每次操作都需要与服务器进行通信。考虑到未来的扩展性和多用户使用时的性能，之后会主要学习使用Blazor WebAssembly来进行网站的搭建" }, { "title": "地基系列 - 引言", "url": "/posts/foundation-1/", "categories": "编程基础", "tags": "编程基础", "date": "2020-07-03 00:00:00 +0800", "snippet": " 前段时间忙着从准备南宁来深圳的事情，忙着收拾，卖二手物品，千辛万苦的搬家，到之后提着大包小包行李赶车，来到这座向往已久的城市，终于得以在现在这个夜晚静下心来，继续更新博客。之后会专门开一个类目，记录生活中的历程前言：为什么新增一个“地基系列”难忘的面试2020年7月2号，到达深圳的第二天，一次难忘的面试。之前有所准备，经历过，也上网浏览过一些公司面试中的笔试题，机试题。但今天这次面试还是...", "content": " 前段时间忙着从准备南宁来深圳的事情，忙着收拾，卖二手物品，千辛万苦的搬家，到之后提着大包小包行李赶车，来到这座向往已久的城市，终于得以在现在这个夜晚静下心来，继续更新博客。之后会专门开一个类目，记录生活中的历程前言：为什么新增一个“地基系列”难忘的面试2020年7月2号，到达深圳的第二天，一次难忘的面试。之前有所准备，经历过，也上网浏览过一些公司面试中的笔试题，机试题。但今天这次面试还是令我印象深刻，让我重新站在一个编程爱好者的角度正视自己应该学的，应该做的。面试之前，不断看，接触了一系列以为面试会用到的各种相对比较“新”的（微服务，消息队列，Redis相关概念，应用场景等），或者“经典”的问题（MVC中的传参方式，一些SQL语句的应用题等），这些问题，面试之前早已看过多次，心想在遇到的时候，也能稳得住阵脚，和面试官侃侃而谈。让我措不及防的是，这次的笔试和面试，考察的主要是编程基础，还有应用的基础。 “当大潮退去，才知道谁在裸泳”前两年的工作中，我一直觉得，程序员在我心中是一个解决实际问题的职业。所谓的解决实际问题，在我看来就是，当一个需求到来，我们要制作相应的程序去满足这个需求，当程序出现问题，我们找出并解决问题，使其更好，更正确的满足需求。在这个过程中，我们可能会不断调用新的库，用之前没用过的框架，来满足新需求在功能，效率等方面的问题。这样的想法要说是错的，其实也没有错，有需求才有交易，有交易才有利润，有利润才让众多公司不断编写新的程序满足市场需求。所以以前，也听到很多人说，自己也确实一度很难反驳这类观点： “面试造核弹，入职领螺丝”，内卷就完事了 底层的知识，那是“大佬”才需要关心的，平时的业务处理完了？解决老板，客户的需求才是第一位。微服务，大数据，什么东西听起来牛皮就往上面堆，互联网技术更迭那么快，两个月不学就有新名词了，给老板画饼就完事了，都是打工的，真当自己是科学家了 有造好的轮子，就别问那么多问题，深究原理了，会用，能用好就行了，轮子，每一天大家都在用，经过那么多人的检验了，一般人没能力，也没精力造出更好的 但是，说这些话的人，很少想过这些问题： 正因为不懂原理，所以每次遇到新的轮子，或者遇到使用轮子的时候出现的问题，总是会花更多时间去处理，这时候，仅仅依靠所谓的“老程序员的经验”真的够吗 总是使用别人用的轮子，到了没有合用的轮子，需要自己造的时候怎么办 大多数人当程序员的初衷，都不全是为了钞票吧，无论是为了找回逐渐迷失的自己，让自己摆脱curd boy的标签，还是为了追求更好的自己，多学习”底层知识”也没什么坏处不是吗 这个系列的博客会涉及到什么偏基础向，而不是轮子使用的经验总结，包括但不限于基础四大件：数据结构和算法，计算机网络，操作系统，设计模式等相关内容，以及衍生出的数据库原理等知识，在介绍相关知识的时候，会试图尽可能深的去了解相关原理并进行总结，会结合一些用例来说明今晚先记到这里吧，本打算先总结一些数据库相关的内容，开始写得有点晚，今天还要去租房，先结束这篇好了，可能这里观点会有表达得不是很清晰的地方，以后回顾的时候会进行补充" }, { "title": ".NET Core前后端分离(5) - IOC(控制反转)与DI(依赖注入)", "url": "/posts/dotnetcore-6/", "categories": "编程框架, ASP.NET Core", "tags": ".NET Core", "date": "2020-06-20 00:00:00 +0800", "snippet": " 准备好了所有的层，那么要如何办到在各个Service层中直接调用IRepository层，并控制调用的仓储层实例的生命周期呢，之前写在各构造函数中的参数是如何获得的呢，让我们来了解IoC(Inversion of Control)以及DI(Dependence Injection)这两个概念IoC(控制反转)思想 控制反转（Inversion of Control，缩写为IoC），是面...", "content": " 准备好了所有的层，那么要如何办到在各个Service层中直接调用IRepository层，并控制调用的仓储层实例的生命周期呢，之前写在各构造函数中的参数是如何获得的呢，让我们来了解IoC(Inversion of Control)以及DI(Dependence Injection)这两个概念IoC(控制反转)思想 控制反转（Inversion of Control，缩写为IoC），是面向对象编程中的一种设计原则，可以用来减低计算机代码之间的耦合度。其中最常见的方式叫做依赖注入（Dependency Injection，简称DI），还有一种方式叫“依赖查找”（Dependency Lookup）。通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体，将其所依赖的对象的引用传递(注入)给它。为什么需要控制反转先从工厂模式开始我们这里来写一段代码，定义一个小猫接口类，用几种不同的小猫类来实现这个接口，并且在调用程序用，动态的根据一个字符串的值，决定要用定义哪个小猫类，并且调用其发出叫声的函数首先定义小猫接口ICat，其包含一个猫叫函数：public interface ICat{ void Meow();}接着定义Cats类，里面包含三种不同类型的猫，并且都实现了ICat接口：using System;public class Cats{ public class BlackCat : ICat { public void Meow() { Console.WriteLine($\"I'm {nameof(BlackCat)}\"); } } public class WhiteCat : ICat { public void Meow() { Console.WriteLine($\"I'm {nameof(WhiteCat)}\"); } } public class PinkCat : ICat { public void Meow() { Console.WriteLine($\"I'm {nameof(PinkCat)}\"); } }}最后，我们对其进行调用，调用的代码是这样写的class Program{ static void Main(string[] args) { var strCatName = \"BlackCat\"; ICat cat = strCatName switch { \"BlackCat\" =&gt; new Cats.BlackCat(), \"WhiteCat\" =&gt; new Cats.WhiteCat(), \"PinkCat\" =&gt; new Cats.PinkCat(), _ =&gt; null }; cat.Meow(); }}可以看到，此时采用的是在调用的地方来对具体对象进行初始化，这样做的缺点是什么呢，显而易见，这里的代码不符合对修改关闭的设计原则，虽然使用了接口，但是还是在实现业务功能的代码中初始化了好几种具体的类，如果需要增加或删除任何猫咪的种类，将不得不对这一段代码做出调整，并且如果其它地方需要使用的话，不具有可复用性所以，我们创建一个新的类，将这个根据字符串获取具体类的方法放进去public static class CatFactory{ public static ICat CreateCat(string strCatName) { ICat cat = strCatName switch { \"BlackCat\" =&gt; new Cats.BlackCat(), \"WhiteCat\" =&gt; new Cats.WhiteCat(), \"PinkCat\" =&gt; new Cats.PinkCat(), _ =&gt; null }; return cat; }}之后，再对其进行调用class Program{ static void Main(string[] args) { var strCatName = \"BlackCat\"; ICat cat = CatFactory.CreateCat(strCatName); cat.Meow(); }}在这里，工厂的概念就产生了，可以看到，我们无论在哪里需要根据字符串获取到具体的小猫类时，都可以使用这个静态的工厂类，(注意，这里实现的只是一个简单的工厂类，不是完整的工厂模式，不过可以从中体会到工厂模式的思想)体会从最开始的模式到工厂模式的变化对于调用者来说，最开始的模式中，为了得到一个具体的小猫类，我们要需要自己描述小猫的外观，自己定义产生小猫的方法，最后才得到一个心仪的小猫类。而到了工厂模式，对于调用者来说，则只需要描述小猫的外观，由工厂那边代为处理，最后就能得到自己想要的结果，获取小猫的具体过程，不需要自己操心。在前后两种模式的变化中，可以看到我们获取小猫的过程的控制权已经发生了转移，可以理解为交给了一个专业的工厂去处理这个过程，即使我们仍然需要通过调用工厂类，来达到我们的目的，但是这样做，已经让代码耦合性降低了，至于工厂类的出现让代码的职责划分得更加明确，加强了通用性就更加不必说了。如何达到真正的控制反转呢来看一段项目中使用了依赖注入中的构造函数注入的代码：private readonly SqlSugarClient _db;public BaseRepository(IUnitOfWork unitOfWork){ _db = unitOfWork.GetDbClient();}/// &lt;summary&gt;/// 写入实体数据/// &lt;/summary&gt;/// &lt;param name=\"model\"&gt;实体类&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;public async Task&lt;int&gt; Add(TEntity model){ var insert = _db.Insertable(model); return await insert.ExecuteReturnIdentityAsync();}在使用这个BaseRepository类的时候，我们不需要手动去初始化unitOfWork，而是在代码走到其构造函数之前，已经得到了unitOfWork，进而得到_db来与数据库交互是不是非常不可思议，就好像是小说里面的人物，心里想着一把兵器，兵器就自己出现在他手上。在类的内部函数中，没有任何一个对于要使用的类的实例化过程，兵器不是自己造的，也不是在要用到的时候委托别人去造的，更像是有人知道他需要这把兵器，就直接把这把兵器给他了。兵器的存在早于使用者自身的存在，这才是真正的，达到了控制反转DI(依赖注入)通过上文我们也知道了，依赖注入是实现控制反转的一种方式，上文也展示了其使用的效果，但是描述得非常玄幻，那么实际上，依赖注入是怎么实现的呢其实，在介绍控制反转时开头引用的那段概念，已经可以很好的说明依赖注入的实现方式了，即：通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体，将其所依赖的对象的引用传递(注入)给它。在我们.NET Core Web框架中，是如何实现这一点的呢，这里我们介绍.NET Core中两种依赖注入的方式 通过调用原生框架自带的依赖注入方法上面提到了，依赖注入是由一个调控系统内所有对象的外界实体来完成的，这个实体在.NET Core框架中以容器的形式被提供，首先，查看Program.cs中的CreateHostBuilder函数public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .ConfigureWebHostDefaults(webBuilder =&gt; { webBuilder.UseStartup&lt;Startup&gt;(); });这里调用了UseStartup，然后我们看到Startup.cs中的ConfigureServices函数，这个函数的官方介绍是This method gets called by the runtime. Use this method to add services to the container.，可以看出，这个方法是在运行时被调用，用来往容器中添加服务没错，这里提到的容器，就是用来实现我们依赖注入的容器，这里要做的，就是在构建这个容器的时候，往里面添加我们需要用到的被注入的类就行了，我们直接用代码来说明，这里借鉴了Stack Overflow上一个答案的写法为了更好的展示，这里新建一个API项目，然后新建一个接口ICounter，随后定义几个接口，继承ICounternamespace WebLab.Interfaces{ public interface ICounter { public int GetCount { get; } } public interface ICounterTransient : ICounter { } public interface ICounterScoped : ICounter { } public interface ICounterSingleton : ICounter { }}接着，定义一个Counter类，实现这几个接口using WebLab.Interfaces;namespace WebLab.Classes{ public class Counter : ICounterTransient, ICounterScoped, ICounterSingleton { int _intCount; public Counter() { _intCount = 0; } public int GetCount =&gt; _intCount++; }}打开Startup.cs文件，编辑ConfigureServices函数的内容，编辑过后的代码是这样的：public void ConfigureServices(IServiceCollection services){ services.AddTransient&lt;ICounterTransient, Counter&gt;(); services.AddScoped&lt;ICounterScoped, Counter&gt;(); services.AddSingleton&lt;ICounterSingleton, Counter&gt;(); services.AddControllers();}新建一个CounterService类，在这里注入我们在ConfigureServices中添加的接口，这里注入的对象都用public来修饰，确保之后可以在外部访问到using WebLab.Interfaces;namespace WebLab.Services{ public class CounterService { public CounterService(ICounterTransient counterTransient, ICounterScoped counterScoped, ICounterSingleton counterSingleton) { CounterTransient = counterTransient; CounterScoped = counterScoped; CounterSingleton = counterSingleton; } public ICounterTransient CounterTransient { get; } public ICounterScoped CounterScoped { get; } public ICounterSingleton CounterSingleton { get; } }}然后，将这个类也添加到ConfigureServicesservices.AddTransient&lt;CounterService&gt;();最后，定义我们的CounterController类，用于待会儿访问接口，查看结果using Microsoft.AspNetCore.Mvc;using System;using WebLab.Interfaces;using WebLab.Services;namespace WebLab.Controllers{ [ApiController] [Route(\"[controller]\")] public class CounterController : ControllerBase { private readonly ICounterTransient _counterTransient; private readonly ICounterScoped _counterScoped; private readonly ICounterSingleton _counterSingleton; private readonly CounterService _counterService; public CounterController(ICounterTransient counterTransient, ICounterScoped counterScoped, ICounterSingleton counterSingleton, CounterService counterService) { _counterTransient = counterTransient; _counterScoped = counterScoped; _counterSingleton = counterSingleton; _counterService = counterService; } [HttpGet] public string Get() { string strResult = \"\"; string strNewLine = Environment.NewLine; strResult += $\"Transient:{_counterTransient.GetCount}{strNewLine}\"; strResult += $\"Scoped:{_counterScoped.GetCount}{strNewLine}\"; strResult += $\"Singleton:{_counterSingleton.GetCount}{strNewLine}\"; strResult += $\"Transient:{_counterService.CounterTransient.GetCount}{strNewLine}\"; strResult += $\"Scoped:{_counterService.CounterScoped.GetCount}{strNewLine}\"; strResult += $\"Singleton:{_counterService.CounterSingleton.GetCount}{strNewLine}\"; return strResult; } }}运行项目，通过请求http://localhost:5000/counter来查看返回的结果第一次请求：Transient:0Scoped:0Singleton:0Transient:0Scoped:1Singleton:1第二次请求：Transient:0Scoped:0Singleton:2Transient:0Scoped:1Singleton:3现在我们了解了如何使用原生框架的依赖注入，可以看到使用构造函数注入过后，只需要直接在调用者的构造函数里面加上需要的被注入的类就行了，是不是非常方便呢同时，也让我们体会了关于依赖注入另一个非常重要的内容，生命周期，通过观察上面的结果，可以总结出注入的生命周期分三种： 注入类型 生命周期 Transient 每个请求者得到的实例都是不一样的，每次涉及到注入的时候都会提供一个全新的实例 Scoped 在单次http请求中，得到的实例是一样的，在发起新的请求时，才会又提供新的实例 Singleton 在整个程序运行的生命周期内，得到的实例都是同一个 使用Autofac实现依赖注入为了体现Autofac的优势，我们先调整项目结构创建了一个IService层，来容纳之前的ICounter接口，再创建一个Service层，容纳具体类Counter，另外，去掉了刚刚为了演示生命周期创建的CounterService类，现在的CounterController类的内容为using Microsoft.AspNetCore.Mvc;using System;using WebLab.Interfaces;namespace WebLab.Controllers{ [ApiController] [Route(\"[controller]\")] public class CounterController : ControllerBase { private readonly ICounterTransient _counterTransient; private readonly ICounterScoped _counterScoped; private readonly ICounterSingleton _counterSingleton; public CounterController(ICounterTransient counterTransient, ICounterScoped counterScoped, ICounterSingleton counterSingleton) { _counterTransient = counterTransient; _counterScoped = counterScoped; _counterSingleton = counterSingleton; } [HttpGet] public string Get() { string strResult = \"\"; string strNewLine = Environment.NewLine; strResult += $\"Transient:{_counterTransient.GetCount}{strNewLine}\"; strResult += $\"Scoped:{_counterScoped.GetCount}{strNewLine}\"; strResult += $\"Singleton:{_counterSingleton.GetCount}{strNewLine}\"; return strResult; } }}此时，怎么进行依赖注入呢，首先，在WebLab项目中引入包Autofac.Extensions.DependencyInjection，这个是Autofac用于依赖注入的包，之后，修改Program.cs文件的CreateHostBuilder函数public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .UseServiceProviderFactory(new AutofacServiceProviderFactory()) .ConfigureWebHostDefaults(webBuilder =&gt; { webBuilder.UseStartup&lt;Startup&gt;(); });可以看到，这里增加了一句.UseServiceProviderFactory(new AutofacServiceProviderFactory())，这代表我们会用Autofac来注入一些服务，此时切换到Startup.cs文件，增加函数public void ConfigureContainer(ContainerBuilder builder){ builder.RegisterModule(new AutofacModuleRegister());}AutofacModuleRegister.cs文件的内容：using Autofac;using System;using System.IO;using System.Reflection;namespace WebLab{ public class AutofacModuleRegister : Autofac.Module { protected override void Load(ContainerBuilder builder) { var basePath = AppContext.BaseDirectory; var servicesDllFile = Path.Combine(basePath, \"WebLab.Service.dll\"); // 获取 WebLab.Service.dll 程序集服务，并注册 var assemblysServices = Assembly.LoadFrom(servicesDllFile); builder.RegisterAssemblyTypes(assemblysServices) .AsImplementedInterfaces() .InstancePerDependency(); } }}到目前为止，通过Autofac进行依赖注入的过程就完成了，可以看到Autofac通过反射获取到程序集，再进行批量注入，这里是直接注入了WebLab.Service.dll，并通过使用方法AsImplementedInterfaces()，将程序集中的类型作为对应接口的具体实现类注入了程序集中所有类型的公共接口(IDisposable除外)，所以之后在程序的任何地方，都可以直接使用被注入的接口注意这里的InstancePerDependency是对标原生注入方法中的AddTransient，另外还能选择InstancePerLifetimeScope和SingleInstance，分别对应原生注入中的AddScoped和AddSingleton最后我们运行程序，却发现在注册服务的时候出现了错误提示，这是为什么呢观察项目结构不难发现，我们现在的WebLab项目在Controller内已经是完全在调用接口了，和WebLab.Service项目已经完全解耦了，所以在作为启动项启动时，不会将WebLab.Service编译到程序启动目录，所以这里就不能正常注入了，于是我们调整WebLab.Service项目的生成路径，在项目属性-生成-输出-输出路径中将其生成路径调整到WebLab生成路径，这里使用相对路径再次生成解决方案，运行项目，项目正确启动了，对接口进行请求，因为这里采用的是Transient注入，所以每次都会请求到相同的内容，可以感受到，当项目结构清晰，相似功能的接口较多的时候，利用Autofac进行批量依赖注入是非常方便的，使用很短的代码就可以实现需求总结依赖注入和工厂模式，都有效的解决了项目耦合度高，业务代码被入侵的问题。依赖注入，可以说通过容器这个“第三方”完成了以前工厂模式做的事情，并且更进一步的，让获取新实例的代码从实际业务代码函数中不可见，使代码层次更加清晰，真正达到了控制反转的目的。同时，其还能让我们更方便管理实例的生命周期PS:文中用到的注入都是根据具体的实现类，对接口进行注入，达到了面向接口编程的目的，依赖注入的方法不局限于这样，也可以直接对具体的类或者对象实例进行注入，写法和用法相对容易理解，就不举例说明了" }, { "title": "LeetCode记录(SQL)(普通题)", "url": "/posts/sql-1/", "categories": "数据库, SQL", "tags": "SQL", "date": "2020-06-19 00:00:00 +0800", "snippet": " 记录在LeetCode的SQL相关问题的提交记录，因为都是一些简单问题，就不单独放了，全部归档在这篇里，均是用MySQL语法，如果用了其它的会注明1.组合两个表select Person.FirstName, Person.LastName, Address.City, Address.Statefrom Personleft join Addresson Person.PersonId...", "content": " 记录在LeetCode的SQL相关问题的提交记录，因为都是一些简单问题，就不单独放了，全部归档在这篇里，均是用MySQL语法，如果用了其它的会注明1.组合两个表select Person.FirstName, Person.LastName, Address.City, Address.Statefrom Personleft join Addresson Person.PersonId = Address.PersonId总结：left join的基本用法，应该是要考察几种join的区别，没啥好总结2.第二高的薪水select IFNULL((select distinct Salaryfrom Employeeorder by Salary desclimit 1,1),null) as SecondHighestSalary因为SQL Server没有limit，这里用offset+fetch实现，另外注意在IFNULL在SQL Server等价的是ISNULLselect ISNULL((select distinct Salaryfrom Employeeorder by Salary descoffset 1 rowsfetch next 1 rows only),null) as SecondHighestSalary总结：注意limit的位置在order by之后，以及注意审题即可3.第N高的薪水CREATE FUNCTION getNthHighestSalary(numN INT) RETURNS INTBEGIN SET numN = numN - 1; RETURN( select IFNULL((select distinct Salary from Employee order by Salary desc limit numN,numN),null) );ENDSQL ServerCREATE FUNCTION getNthHighestSalary(@N INT) RETURNS INT ASBEGIN SET @N = @N - 1; RETURN ( select ISNULL((select distinct Salary from Employee order by Salary desc offset @N rows fetch next 1 rows only),null) );END总结：和第二题相比，主要考察如何用函数创建自定义function4.分数排名MySQLselect Scores.Score,T2.Rank from Scoresleft join (select T1.Score,Convert((@rownum := @rownum + 1),unsigned) as `Rank`from (select distinct Score,(SELECT @rownum := 0) from Scores order by Score desc)T1)T2 on Scores.Score = T2.Scoreorder by Score descSQL Serverselect Scores.Score,T2.Rank from Scoresleft join (select T1.Score,ROW_NUMBER() over(ORDER BY T1.Score desc) as Rankfrom (select distinct Score from Scores)T1)T2 on Scores.Score = T2.Scoreorder by Score desc总结：注意在MySQL中，用``符号来对保留字进行转义，另外注意取行号在两种数据库中的写法PS:在版本允许的情况下，用函数DENSE_RANK()可以很容易处理这个问题，写法为select Score,DENSE_RANK() OVER(order by Score desc) as `Rank` from Scores5.连续出现的数字MySQLselect distinct T1.Num as ConsecutiveNums from(select case when @preNum = Num then @times := @times+1else(case when (@preNum :=Num) is not null then @times :=1 end)end as num_times,Numfrom Logs,(select @preNum := 0,@times := 0)init)T1where T1.num_times&gt;2总结：需要熟悉MySQL用户变量的用法，体会其初始化之后的作用域以及随着查询值变化的过程" }, { "title": ".NET Core前后端分离(4) -仓储层(Repository)和服务层(Service)层的创建", "url": "/posts/dotnetcore-5/", "categories": "编程框架, ASP.NET Core", "tags": ".NET Core", "date": "2020-06-16 00:00:00 +0800", "snippet": " 建立好数据库，注入了ORM相关类之后，就开始构建我们通过ORM和数据库进行交互的层（Repository层）和只负责调用仓储层的(Service层)什么是仓储层，为什么要分层Repository(仓储)是DDD(领域驱动设计)中的经典思想，可以归纳为介于实际业务层(领域层)和数据访问层之间的层，能让领域层能在感觉不到数据访问层的情况下，完成与数据库的交互和以往的DAO层相比，Reposi...", "content": " 建立好数据库，注入了ORM相关类之后，就开始构建我们通过ORM和数据库进行交互的层（Repository层）和只负责调用仓储层的(Service层)什么是仓储层，为什么要分层Repository(仓储)是DDD(领域驱动设计)中的经典思想，可以归纳为介于实际业务层(领域层)和数据访问层之间的层，能让领域层能在感觉不到数据访问层的情况下，完成与数据库的交互和以往的DAO层相比，Repository层的设计理念更偏向于面向对象，而淡化直接对数据表进行的CRUD操作那么，为什么要建立Service层呢Service层是位于Controller和Repository层之间的，处理业务逻辑的层，主要目的是解耦，让每个层可以各自专注自己的事情，而无需在意具体的实现创建各层的接口为什么还需要创建接口接口可以很方便的规定两个类之间的交互标准，是一种规范，在协同开发的时候尤其重要，特别是在描述多个有相似行为的类的时候开始创建仓储层接口首先添加项目Hanabi.Flow.IRepository，然后添加文件夹Base，创建IBaseRepository.cs文件，这将作为基类接口，声明一些所有仓储层接口都拥有的公共功能/// &lt;summary&gt;/// 基类仓储接口/// &lt;/summary&gt;/// &lt;typeparam name=\"TEntity\"&gt;Model类型&lt;/typeparam&gt;public interface IBaseRepository&lt;TEntity&gt; where TEntity: class{ Task&lt;TEntity&gt; QueryById(object objId); Task&lt;TEntity&gt; QueryById(object objId, bool blnUseCache = false); Task&lt;List&lt;TEntity&gt;&gt; QueryByIDs(object[] lstIds); Task&lt;int&gt; Add(TEntity model); Task&lt;int&gt; Add(List&lt;TEntity&gt; listEntity); Task&lt;bool&gt; DeleteById(object id); Task&lt;bool&gt; Delete(TEntity model); Task&lt;bool&gt; DeleteByIds(object[] ids); Task&lt;bool&gt; Update(TEntity model); Task&lt;bool&gt; Update(TEntity entity, string strWhere); Task&lt;bool&gt; Update(object operateAnonymousObjects); Task&lt;bool&gt; Update(TEntity entity, List&lt;string&gt; lstColumns = null, List&lt;string&gt; lstIgnoreColumns = null, string strWhere = \"\"); Task&lt;List&lt;TEntity&gt;&gt; Query(); Task&lt;List&lt;TEntity&gt;&gt; Query(string strWhere); Task&lt;List&lt;TEntity&gt;&gt; Query(Expression&lt;Func&lt;TEntity, bool&gt;&gt; whereExpression, string strOrderByFileds); Task&lt;List&lt;TEntity&gt;&gt; Query(Expression&lt;Func&lt;TEntity, bool&gt;&gt; whereExpression, Expression&lt;Func&lt;TEntity, object&gt;&gt; orderByExpression, bool isAsc = true); Task&lt;List&lt;TEntity&gt;&gt; Query(string strWhere, string strOrderByFileds); Task&lt;List&lt;TEntity&gt;&gt; Query(Expression&lt;Func&lt;TEntity, bool&gt;&gt; whereExpression, int intTop, string strOrderByFileds); Task&lt;List&lt;TEntity&gt;&gt; Query(string strWhere, int intTop, string strOrderByFileds); Task&lt;List&lt;TEntity&gt;&gt; QuerySql(string strSql, SugarParameter[] parameters = null); Task&lt;DataTable&gt; QueryTable(string strSql, SugarParameter[] parameters = null); Task&lt;List&lt;TEntity&gt;&gt; Query( Expression&lt;Func&lt;TEntity, bool&gt;&gt; whereExpression, int intPageIndex, int intPageSize, string strOrderByFileds); Task&lt;List&lt;TEntity&gt;&gt; Query(string strWhere, int intPageIndex, int intPageSize, string strOrderByFileds); Task&lt;PageModel&lt;TEntity&gt;&gt; QueryPage(Expression&lt;Func&lt;TEntity, bool&gt;&gt; whereExpression, int intPageIndex = 1, int intPageSize = 20, string strOrderByFileds = null); Task&lt;List&lt;TResult&gt;&gt; QueryMuch&lt;T, T2, T3, TResult&gt;( Expression&lt;Func&lt;T, T2, T3, object[]&gt;&gt; joinExpression, Expression&lt;Func&lt;T, T2, T3, TResult&gt;&gt; selectExpression, Expression&lt;Func&lt;T, T2, T3, bool&gt;&gt; whereLambda = null) where T : class, new();}接着，根据之前建立的Model类，继承这个基类接口来构建接口(以UserRole为例)/// &lt;summary&gt;/// 继承基类接口创建的接口，若有额外方法可以在此处扩展/// &lt;/summary&gt;public interface IUserRoleRepository : IBaseRepository&lt;UserRole&gt;{}考虑到事务控制的需要，在仓储接口层新增文件夹UnitOfWork,实现事务控制单元，代码为IUnitOfWork.cspublic interface IUnitOfWork{ SqlSugarClient GetDbClient(); void BeginTran(); void CommitTran(); void RollbackTran();}开始创建服务层接口和IRepository类似，添加项目Hanabi.Flow.IService，然后添加文件夹Base，创建IBaseService.cs文件，这将作为基类接口，声明一些所有服务层接口都拥有的公共功能，因为这里是和仓储层保持统一的，代码就不贴上来了，之后，根据Model类继承这个基类接口构建每个接口根据抽象接口实现各接口已经定义好了各接口，接下来根据各接口定义的规范来实现接口，首先新建项目Hanabi.Flow.Repository，添加对Hanabi.Flow.IRepository的依赖，先来实现基类接口新建文件夹Base，新建文件BaseRepository.cs，首先先完成其构造函数public class BaseRepository&lt;TEntity&gt; : IBaseRepository&lt;TEntity&gt; where TEntity : class, new(){}首先，因为要通过ORM与数据库交互，先实现工作单元接口(IUnitOfWork)public class UnitOfWork : IUnitOfWork{ private readonly MyContext _myContext; public UnitOfWork(MyContext myContext) { _myContext = myContext; } public void BeginTran() { GetDbClient().BeginTran(); } public void CommitTran() { GetDbClient().CommitTran(); } public SqlSugarClient GetDbClient() =&gt; _myContext.Db; public void RollbackTran() { GetDbClient().RollbackTran(); }}使用VS的快速重构来实现这个接口，通过在各个函数中利用注入的IUnitOfWork实现使用ORM数据交互，代码太长，就不贴在这里了，可以在Github看详细代码之后再分别实现UserRole等Model类的仓储接口，这里以UserRole为例public UserRoleRepository(IUnitOfWork unitOfWork) : base(unitOfWork){}最后，添加Hanabi.Flow.Service项目，用来实现IService接口项目中的接口，项目的整体框架就完成了补充定义完所有的接口，并实现完它们的函数之后，可以看看我们各个项目的依赖关系先定义了仓储层和服务层的接口层，它们需要用到对应的Model类型，所以都引用了Model层接着用Repository层实现了IRepository层的接口，最后在Service层实现IService层的接口，并通过IRepository层和仓储层进行交互" }, { "title": ".NET Core前后端分离(3) - ORM的选用(SqlSugar) + Code First初始化数据库", "url": "/posts/dotnetcore-4/", "categories": "编程框架, ASP.NET Core", "tags": ".NET Core", "date": "2020-06-14 00:00:00 +0800", "snippet": " 经过之前的步骤，已经设置好了配置文件的读取方法，现在让我们来设置ORM，这里我们选用SqlSugar作为本项目的ORM构建Model层因为要使用Code First,先在解决方案下新增类库项目Hanabi.Flow.Model，引入ORM包sqlSugarCore，会在这里构建项目的Model层，在其中添加文件RootEntity.cs，内容为public class RootEntit...", "content": " 经过之前的步骤，已经设置好了配置文件的读取方法，现在让我们来设置ORM，这里我们选用SqlSugar作为本项目的ORM构建Model层因为要使用Code First,先在解决方案下新增类库项目Hanabi.Flow.Model，引入ORM包sqlSugarCore，会在这里构建项目的Model层，在其中添加文件RootEntity.cs，内容为public class RootEntity{ /// &lt;summary&gt; /// ID /// &lt;/summary&gt; [SugarColumn(IsNullable = false, IsPrimaryKey = true, IsIdentity = true)] public int Id { get; set; } }这是所有Models的基类，因为之后的所有Models都会具有Id列，所以它们都会继承这个类新建类UserRole.cs以及UserInfo.cs，分别作为用户角色类以及用户信息类这里只写出UserRole.cs的内容，注意详细定义每个字段的SugarColumn特性即可/// &lt;summary&gt;/// 权限ID/// &lt;/summary&gt;[SugarColumn(IsNullable = false)]public int RoleId { get; set; }/// &lt;summary&gt;/// 角色名称/// &lt;/summary&gt;[SugarColumn(ColumnDataType = \"nvarchar\",Length = 20,IsNullable = true)]public string Name { get; set; }/// &lt;summary&gt;/// 角色描述/// &lt;/summary&gt;[SugarColumn(ColumnDataType = \"nvarchar\", Length = 50, IsNullable = true)]public string Description { get; set; }/// &lt;summary&gt;/// 创建者ID/// &lt;/summary&gt;[SugarColumn(IsNullable = true)]public int? CreateId { get; set; }/// &lt;summary&gt;/// 创建时间/// &lt;/summary&gt;[SugarColumn(IsNullable = false)]public DateTime? CreateTime { get; set; } = DateTime.Now;/// &lt;summary&gt;/// 修改ID/// &lt;/summary&gt;[SugarColumn(IsNullable = true)]public int? ModifyId { get; set; }/// &lt;summary&gt;/// 修改时间/// &lt;/summary&gt;[SugarColumn(IsNullable = true)]public DateTime? ModifyTime { get; set; } = DateTime.Now;/// &lt;summary&gt;/// 逻辑删除/// &lt;/summary&gt;[SugarColumn(IsNullable = true)]public bool? IsDeleted { get; set; }定义数据库上下文类新建Data文件夹， 在这里面新增数据库上下文类MyContext，主要用于建立和数据库之间的连接，以及程序启动时数据库的生成，其中object.ObjToEnum是一个自定义的扩展方法，之后可以在项目中查看具体写了啥using Hanabi.Flow.Common.Helpers;using SqlSugar;using System;using System.Collections.Generic;using System.Linq;using System.Reflection;using System.Text;namespace Hanabi.Flow.Data{ public class MyContext { private SqlSugarClient _db; private static string _connectionString; private static DbType _dbType; /// &lt;summary&gt; /// 数据连接对象 /// Blog.Core /// &lt;/summary&gt; public SqlSugarClient Db { get { return _db; } private set { _db = value; } } /// &lt;summary&gt; /// 连接字符串 /// Blog.Core /// &lt;/summary&gt; public static string ConnectionString { get { return _connectionString; } set { _connectionString = value; } } /// &lt;summary&gt; /// 数据库类型 /// Blog.Core /// &lt;/summary&gt; public static DbType DbType { get { return _dbType; } set { _dbType = value; } } public MyContext() { string connectionString = AppSettings.app(\"DBSetting\", \"DBString\"); string dbType = AppSettings.app(\"DBSetting\", \"DBType\"); _connectionString = connectionString; _dbType = dbType.ObjToEnum&lt;DbType&gt;(); if (string.IsNullOrEmpty(connectionString)) { throw new ArgumentNullException(\"数据库连接字符串为空\"); } _db = new SqlSugarClient(new ConnectionConfig() { ConnectionString = connectionString, DbType = _dbType, IsAutoCloseConnection = true, InitKeyType = InitKeyType.Attribute,//mark MoreSettings = new ConnMoreSettings() { IsAutoRemoveDataCache = true } }); } public void GeneratorData() { Console.WriteLine(\"正在初始化数据库...\"); _db.DbMaintenance.CreateDatabase(); Console.WriteLine(\"数据库初始化完毕\"); Console.WriteLine(\"正在遍历Models\"); var modelTypes = Assembly.GetExecutingAssembly().GetTypes() .Where(type =&gt; type.IsClass &amp;&amp; type.Namespace == \"Blog.Core.Model.Models\") .Select(type =&gt; type) .ToList(); modelTypes.ForEach(model =&gt; { if (!_db.DbMaintenance.IsAnyTable(model.Name)) { Console.WriteLine($\"正在建{model.Name}表\"); _db.CodeFirst.InitTables(model); } }); Console.WriteLine(\"建表完成\"); } /// &lt;summary&gt; /// 功能描述:根据实体类生成数据库表 /// 作　　者:Blog.Core /// &lt;/summary&gt; /// &lt;param name=\"blnBackupTable\"&gt;是否备份表&lt;/param&gt; /// &lt;param name=\"lstEntitys\"&gt;指定的实体&lt;/param&gt; public void CreateTableByEntity&lt;T&gt;(bool blnBackupTable, params T[] lstEntitys) where T : class, new() { Type[] lstTypes = null; if (lstEntitys != null) { lstTypes = new Type[lstEntitys.Length]; for (int i = 0; i &lt; lstEntitys.Length; i++) { T t = lstEntitys[i]; lstTypes[i] = typeof(T); } } CreateTableByEntity(blnBackupTable, lstTypes); } /// &lt;summary&gt; /// 功能描述:根据实体类生成数据库表 /// 作　　者:Blog.Core /// &lt;/summary&gt; /// &lt;param name=\"blnBackupTable\"&gt;是否备份表&lt;/param&gt; /// &lt;param name=\"lstEntitys\"&gt;指定的实体&lt;/param&gt; public void CreateTableByEntity(bool blnBackupTable, params Type[] lstEntitys) { if (blnBackupTable) { _db.CodeFirst.BackupTable().InitTables(lstEntitys); //change entity backupTable } else { _db.CodeFirst.InitTables(lstEntitys); } } }}接着我们在Startup中将其注册到服务*services.AddScoped();*接着在Hanabi.Flow.API项目中添加文件夹Extensions，添加文件DataGenerator.cs，在这里调用MyContext里的方法，实现启动时生成数据库public static void UseDataGenerator(this IApplicationBuilder app, MyContext myContext){ myContext.GeneratorData();}最后，在Startup.cs文件的Configure函数使用短路中间件(UseEndpoints)的后面使用这个新添加的中间件app.UseDataGenerator(myContext);启动程序，发现数据库已经在启动时被正确初始化了：连接数据库查看，确实已经生成了库和表，至此，利用SqlSugar作为ORM，并实现Code First就完成了" }, { "title": ".NET Core前后端分离(2) - 配置文件与变量", "url": "/posts/dotnetcore-3/", "categories": "编程框架, ASP.NET Core", "tags": ".NET Core", "date": "2020-06-13 00:00:00 +0800", "snippet": " 在代码中，为了避免代码复用，以及在没有编译条件时能调整程序内部的一些设置，常常需要有一个配置中心，方便快速更改整个程序的全局变量，所以我们先来编写好配置中心的相关代码在代码中编写全局变量的一些方法 使用定义全局静态类，添加静态变量，方便修改，全局可用 采用依赖注入的方式在项目中注入一个Singleton的变量，使其在整个项目周期中都可以使用这两种，都是直接写在代码中的配置，所以我们需...", "content": " 在代码中，为了避免代码复用，以及在没有编译条件时能调整程序内部的一些设置，常常需要有一个配置中心，方便快速更改整个程序的全局变量，所以我们先来编写好配置中心的相关代码在代码中编写全局变量的一些方法 使用定义全局静态类，添加静态变量，方便修改，全局可用 采用依赖注入的方式在项目中注入一个Singleton的变量，使其在整个项目周期中都可以使用这两种，都是直接写在代码中的配置，所以我们需要一种可以直接通过非代码文件操作配置，并方便快速取用的方法项目目录中，默认有appssettings.json文件，用于储存一些项目配置，所以我们需要将取用的方式封装成方便我们取用的方式通过封装官方接口来注入配置为了让项目层次更清晰，我们先在当前解决方案添加一个新的类库，取名Hanabi.Flow.Common，在类库下创建一个新的Helpers文件夹，并添加文件，名为AppSettings.cs在新建的类库项目中安装Microsoft.Extensions.Configuration.Json包，在新建文件的类中添加构造函数，并传入IConfiguration，此时代码为static IConfiguration Configuration { get; set; }public AppSettings(IConfiguration configuration){ Configuration = configuration;}这里的IConfiguration是之后会在项目启动注入服务时传入的，这里定义一个方函数，方便我们快速获取Configuration中的内容/// &lt;summary&gt;/// 封装要操作的字符/// &lt;/summary&gt;/// &lt;param name=\"sections\"&gt;节点配置&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;public static string app(params string[] sections){ try { if (sections.Any()) { // 获取配置中的对应内容 return Configuration[string.Join(\":\", sections)]; } } catch (Exception) { } return \"\";}最后，我们在主项目中引用当前类库项目，整个项目的Startup.cs处对这个类进行注入，在ConfigureServices函数中增加内容services.AddSingleton(new AppSettings(Configuration));在项目中使用注入好的配置类在默认的Controller中，添加新的函数，测试注入的配置类已经生效，正确获取到了默认配置文件的内容/// &lt;summary&gt;/// 获取配置文件内容/// &lt;/summary&gt;/// &lt;returns&gt;&lt;/returns&gt;[HttpGet]public string GetSetting(){ return AppSettings.app(\"Logging\", \"LogLevel\", \"Default\");}" }, { "title": ".NET Core前后端分离(1) - Swagger的使用", "url": "/posts/dotnetcore-2/", "categories": "编程框架, ASP.NET Core", "tags": ".NET Core", "date": "2020-06-12 00:00:00 +0800", "snippet": " 在前后端分离过程中,API文档是非常重要的,在项目搭建的第一步,我们使用Swagger来实现这一点引入Nuget包在项目中安装Swashbuckle.AspNetCore.SwaggerGen和Swashbuckle.AspNetCore.SwaggerUI配置服务在Startup.cs文件的ConfigureServices函数中添加服务:// 类中定义常量,方便后续编辑private...", "content": " 在前后端分离过程中,API文档是非常重要的,在项目搭建的第一步,我们使用Swagger来实现这一点引入Nuget包在项目中安装Swashbuckle.AspNetCore.SwaggerGen和Swashbuckle.AspNetCore.SwaggerUI配置服务在Startup.cs文件的ConfigureServices函数中添加服务:// 类中定义常量,方便后续编辑private const string ApiVersion = \"V1.0\";// ConfigureServices函数内添加代码services.AddSwaggerGen(setup =&gt;{ // 设置Swagger文档的名称，描述信息等 setup.SwaggerDoc(ApiVersion, new OpenApiInfo { Version = ApiVersion, Title = \"后端API说明文档\", Description = \"具体描述见各API详情\", Contact = new OpenApiContact { Name = \"HANABI\", Email = \"Narancia86@outlook.com\", Url = new Uri(\"https://colasaikou.com/\") }, License = new OpenApiLicense { Name = \"HANABI\", Url = new Uri(\"https://colasaikou.com/\") } }); // 设置API的排序规则 setup.OrderActionsBy(description =&gt; description.RelativePath);});在Startup.cs文件的Configure函数中启动HTTP管道中间件:public void Configure(IApplicationBuilder app, IWebHostEnvironment env){ if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseSwagger(); app.UseSwaggerUI(c =&gt; { c.SwaggerEndpoint($\"/swagger/{ApiVersion}/swagger.json\", ApiVersion); // 在launchSettings.json把launchUrl设置为空,表示程序启动时访问根域名,并且在这里把Swagger页面路由前缀设置为空,即可在API根域名访问Swagger界面 c.RoutePrefix = \"\"; }); app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); });}配置API注释 此时启动API已经可以看到Swagger界面了，但是可以看到，此时这些API是没有注释的，现在进行最后一步，给他们加上注释在项目名称处点击右键-属性-生成，勾选上XML文档文件，并设置好文档的相对路径，对项目进行生成，发现项目下已经出现了对应的注释XML文档，在错误列表中会出现很多警告，根据警告类型同样在项目的属性-生成中添加取消显示警告1591此时,在Controller代码中加上注释,并在ConfigureServices函数的Swagger服务设置中添加内容:// 设置接口注释信息var xmlPath = Path.Combine(AppContext.BaseDirectory, \"Hanabi.Blog.xml\");setup.IncludeXmlComments(xmlPath, true);重新生成项目并运行,此时可以看到API说明中已经出现了添加的注释内容如果想忽略某个API，使其不显示，在Controller或者Action上方加上[ApiExplorerSettings(IgnoreApi = true)]特性即可" }, { "title": "部署Vue+.NET Core前后端分离项目中遇到的问题", "url": "/posts/dotnetcore-1/", "categories": "编程框架, ASP.NET Core", "tags": ".NET Core", "date": "2020-06-04 00:00:00 +0800", "snippet": " 这里记录一些在部署项目过程中容易忘记的点，主要做备忘用Nginx1.双击之后一闪而过这个是在Windows中使用的时候出现的，双击nginx.exe之后一闪而过，打开任务管理器也没有相关进程，在浏览器中输入localhost也无法访问欢迎页面，检查之后才知道是因为nginx所在路径存在中文，换了没有中文的路径之后启动，没有出现此问题2.配置vue项目后刷新后出现404的问题根据官方文档，...", "content": " 这里记录一些在部署项目过程中容易忘记的点，主要做备忘用Nginx1.双击之后一闪而过这个是在Windows中使用的时候出现的，双击nginx.exe之后一闪而过，打开任务管理器也没有相关进程，在浏览器中输入localhost也无法访问欢迎页面，检查之后才知道是因为nginx所在路径存在中文，换了没有中文的路径之后启动，没有出现此问题2.配置vue项目后刷新后出现404的问题根据官方文档，调整nginx.conflocation / { try_files $uri $uri/ /index.html;}3.解决访问后端API时的跨域问题在nginx.conf中添加内容，设置代理，如这里的设置把要访问的后端API代理到前端location /api { proxy_pass http://localhost:8081;}IIS1.使用IIS部署后访问出现404的问题根据官方文档 安装 IIS UrlRewrite 在你的网站根目录中创建一个 web.config 文件，内容如下：&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;system.webServer&gt; &lt;rewrite&gt; &lt;rules&gt; &lt;rule name=\"Handle History Mode and custom 404/500\" stopProcessing=\"true\"&gt; &lt;match url=\"(.*)\" /&gt; &lt;conditions logicalGrouping=\"MatchAll\"&gt; &lt;add input=\"{REQUEST_FILENAME}\" matchType=\"IsFile\" negate=\"true\" /&gt; &lt;add input=\"{REQUEST_FILENAME}\" matchType=\"IsDirectory\" negate=\"true\" /&gt; &lt;/conditions&gt; &lt;action type=\"Rewrite\" url=\"/\" /&gt; &lt;/rule&gt; &lt;/rules&gt; &lt;/rewrite&gt; &lt;/system.webServer&gt;&lt;/configuration&gt;2.解决访问后端API时的跨域问题在后端代码中使用CORS中间件允许前端访问后端项目官方示例(.NET Core 3.1)：https://docs.microsoft.com/zh-cn/aspnet/core/security/cors?view=aspnetcore-3.1" }, { "title": "VS使用备忘", "url": "/posts/vs-1/", "categories": "编程工具, IDE", "tags": "Visual Studio", "date": "2020-05-24 00:00:00 +0800", "snippet": " 这里记录一些在使用VS的过程中遇到的值得记录的点使F12键可以看到对应nuget包的源代码(若有)在VS2019打开工具-选项-文本编辑器-高级-支持导航到反编译源(实验)选项，可以使用F12直接看.NET Core框架的源代码生成项目XML文档在项目上按右键-属性-生成中勾选上XML文档文件选项，建议把XML文档路径改成相对路径，并且取消警告，如图获取.NET Core智能提示汉化包在...", "content": " 这里记录一些在使用VS的过程中遇到的值得记录的点使F12键可以看到对应nuget包的源代码(若有)在VS2019打开工具-选项-文本编辑器-高级-支持导航到反编译源(实验)选项，可以使用F12直接看.NET Core框架的源代码生成项目XML文档在项目上按右键-属性-生成中勾选上XML文档文件选项，建议把XML文档路径改成相对路径，并且取消警告，如图获取.NET Core智能提示汉化包在官网下载对应汉化包打开文件夹：C:\\Program Files\\dotnet\\packs\\Microsoft.NETCore.App.Ref\\3.1.0\\ref\\netcoreapp3.1，把压缩包内解压出来的Microsoft.NETCore.App.Ref\\zh-hans文件夹都Copy到这里(这里以Microsoft.NETCore.App.Ref为例，解压出来的其它文件夹操作均相同)重启VS，可以看到，已经出现汉化之后的中文提示了让解决方案管理器自动定位当前选中文件在工具-选项-项目和解决方案中，勾选上在解决方案资源管理器中跟踪活动项即可快速转到文件/类型/成员使用Ctrl+T(这里用的是VS2019，默认是这个快捷键)，会弹出一个输入框，在其中输入想要转到的相关内容，就可以快速定位想要跳转到的位置，和资源管理器中的搜索类似，但是更方便，在编辑-转到可以看到更多转到选项及其快捷键使用dotnet命令运行项目时，添加HTTPS开发证书在项目目录使用命令dotnet dev-certs https --trust显示内联参数名称提示工具-选项-文本编辑器-C#-显示内联参数名称提示(实验)(在这里使用的是Microsoft Visual Studio Community 2019 版本 16.8.0)开启导航到反编译源功能工具-选项-文本编辑器-C#-高级-支持导航到反编译源(实验)，开启之后再导航到定义的时候就可以进一步导航到反编译的源码了NuGet包互相依赖导致无法卸载在卸载NuGet包，想替换成一个自己的DLL的时候提示无法卸载“XXX“，因为“XXX”依赖于它，之前都是按照提示，按照依赖顺序来删除引用，最后再达到换掉自己想换的DLL的目的，忽然发现在展开卸载选项时，有一个”强制卸载，即使有依赖项”，勾上这个，再进行卸载，就可以避免互相依赖导致没办法直接卸载的问题了在Visual Studio中快速前往MSDN查看选中内容的相关文档按F1按钮即可快速将选中的文本进行大/小写切换大写：Ctrl + Shift + U小写：Ctrl + U关闭引用数量提示找到工具 - 选项 - 文本编辑器 - 所有语言 - CodeLens，关闭CodeLens开关即可添加新行并将光标定位到新添加的行(与VS Code预设的快捷键相反)在当前行上方添加：Ctrl + Enter在当前行下方添加：Ctrl + Shift + Enter定位与当前括号或者大括号匹配的令一个大括号定位：Ctrl + ]定位并选中：Ctrl + Shift + ]刪除当前行会复制当前行：Ctrl + L or Ctrl + X or Shift + Delete不会复制当前行：Ctrl + Shift + L粘贴历史剪切板的内容Ctrl + Shift + V打开IDE导航器Ctrl + Tab快速转到任务列表(详情点击)Ctrl+\\、T or Ctrl+\\、Ctrl+T快速转到指定位置Ctrl + T" }, { "title": "Python爬虫基础之广西人才网的信息爬取(3) - 分词统计", "url": "/posts/python-crawler-3/", "categories": "经验技巧, 爬虫", "tags": "Python", "date": "2020-05-24 00:00:00 +0800", "snippet": " 在通过异步爬取提升了爬取速度之后，最后来扩展一下，进一步爬取每个工作的详情并利用分词库来对具体工作内容进行分词统计准备工作在上次爬取的过程中，我们异步获取了所有IT类工作的标题，在过程中也得了它们的详情页链接，这里在之前的基础上获取到每个链接的详情页，利用分词库进行分词，从而统计出每种编程语言在所有岗位中的占比，为此我们要用到中文分词库结巴分词，其安装方法和用法示例在页面中都有介绍。编写...", "content": " 在通过异步爬取提升了爬取速度之后，最后来扩展一下，进一步爬取每个工作的详情并利用分词库来对具体工作内容进行分词统计准备工作在上次爬取的过程中，我们异步获取了所有IT类工作的标题，在过程中也得了它们的详情页链接，这里在之前的基础上获取到每个链接的详情页，利用分词库进行分词，从而统计出每种编程语言在所有岗位中的占比，为此我们要用到中文分词库结巴分词，其安装方法和用法示例在页面中都有介绍。编写代码代码都放到了这里，在上次的基础上，主要加了在遍历岗位标题时打开详情页并记录详情页内容的代码： # 打开详情页 detailPage = await fetch(session, \"https:\" + href) jobDetail = BeautifulSoup(detailPage, 'lxml').find( \"pre\") global content content += str(jobDetail)以及最后的分词统计部分 time_end = time.time() counter = Counter() words = jieba.cut(content, cut_all=False) for word in words: wordCommn = word.lower() if wordCommn in jobList: counter[wordCommn] += 1 print('广西人才网IT岗统计结果(词频)') print('总岗位数量:' + str(len(jobsNum))) common = counter.most_common(len(jobList)) for k, v in common: print(f\"{k} {v}次\")运行结果广西人才网IT岗统计结果(词频)总岗位数量:2233java 665次javascript 493次sql 454次css 446次php 340次js 263次c# 202次c++ 154次python 142次go 13次vb 6次ruby 6次swift 5次总结这次的代码其实很早就写好了，但是一直想不到有什么特别值得详细写的地方，加上最近比较忙，就没有更新这篇上去。总的来说，使用Python写爬虫是一个非常舒服的过程，上手快，写出可用的爬虫的速度也快，对于爬虫这种随时可能因为爬取的网站结构或者反爬措施变化需要调整甚至全部重写的工具来说，选Python肯定不会错。因为网络教程和使用范例的丰富，各种用来编写爬虫的库的使用方法已经不再是难点。对于爬取过程来说，最重要的还是网站结构的分析，以及请求头，Cookies都要按不同网站来做出调整，以及如何在数据量较大时，对整个爬取过程做优化，这才是最重要的地方。Python小工具合集因为用Python来写一些小工具或者短时间使用的工具实在太方便了，最近就写了好几个，建了一个repository，之后会把这些小工具都更新到这里，供个人备忘以及大家参考python-little-tools" }, { "title": "Python爬虫基础之广西人才网的信息爬取(2) - 异步爬虫", "url": "/posts/python-crawler-2/", "categories": "经验技巧, 爬虫", "tags": "Python", "date": "2020-05-17 00:00:00 +0800", "snippet": " 经过之前的爬取，已经了解了网页的爬取流程，现在来了解异步爬取为什么要进行异步爬取上一篇中，我们的代码是从上往下写的，逻辑比较清晰，先获取到每一页岗位的url，然后在for循环中获取每一页的岗位列表，再进行分析与统计，这样的代码虽然没有问题，但只是相当于一个人在飞快浏览网站内容然后做记录，我们的代码只是加速了这个过程，没有发挥爬虫的最大优势，如果能让程序变成很多人在同时帮我浏览并分析数据，...", "content": " 经过之前的爬取，已经了解了网页的爬取流程，现在来了解异步爬取为什么要进行异步爬取上一篇中，我们的代码是从上往下写的，逻辑比较清晰，先获取到每一页岗位的url，然后在for循环中获取每一页的岗位列表，再进行分析与统计，这样的代码虽然没有问题，但只是相当于一个人在飞快浏览网站内容然后做记录，我们的代码只是加速了这个过程，没有发挥爬虫的最大优势，如果能让程序变成很多人在同时帮我浏览并分析数据，那速度肯定能提高很多，带着这种想法，我们来试试用异步的方法执行爬取了解需要用到的库asynico库这次我们需要用到的库主要有asyncio和aiohttp两个库，其中asyncio库的官方文档简介如下 asyncio 是用来编写 并发 代码的库，使用 async/await 语法。asyncio 被用作多个提供高性能 Python 异步框架的基础，包括网络和网站服务，数据库连接库，分布式任务队列等等。asyncio 往往是构建 IO 密集型和高层级 结构化 网络代码的最佳选择。1.首先来了解asyncio，我们用下面这段代码来帮助我们理解import asyncioimport timetime_format = '%Y-%m-%d %X'async def printTime(taskname): print(f\"{taskname}开始时间:{time.strftime('%X')}\") await asyncio.sleep(10)async def main(): print(f\"开始时间:{time.strftime('%X')}\") task1 = asyncio.create_task(printTime(\"任务一\")) task2 = asyncio.create_task(printTime(\"任务二\")) task3 = asyncio.create_task(printTime(\"任务三\")) await task1 task4 = asyncio.create_task(printTime(\"任务四\")) await task2 await task3 await task4 print(f\"结束时间:{time.strftime('%X')}\")# 输出结果# 开始时间:18:10:39# 任务一开始时间:18:10:39# 任务二开始时间:18:10:39# 任务三开始时间:18:10:39# 任务四开始时间:18:10:49# 结束时间:18:10:59asyncio.run(main())可以看到，我们定义了一个函数printTime()，函数功能是输出当前任务的开始时间并等待十秒，从输出的结果可以看到，前面三个任务被同时开始了，第四个任务在他们开始的十秒之后也开始了，也就是说在这三个任务同时完成并且结束之后，任务四开始执行如何来理解这样的运行结果呢，通过分析代码中的关键字和asyncio库的用法就可以很容易明白：首先，在要运行的函数前面使用async来进行声明，可以将其指定为协程，协程不能直接调用并执行，在程序的入口部分，我们用asyncio.run()来异步执行被标记为协程的main()，在内部，使用await来对可等待对象，可等待对象包括协程，任务和Futures每当程序运行到用await来进行等待的地方，会立即并发执行当前所有被创建的任务和协程，所以其实上面的代码可以简写，只要任务被创建，就在等待运行，使用一次await进行等待，所有任务就会并发执行，我们调整之前代码中的main()函数，可以看到输出结果发生了改变async def main(): print(f\"开始时间:{time.strftime('%X')}\") asyncio.create_task(printTime(\"任务一\")) asyncio.create_task(printTime(\"任务二\")) asyncio.create_task(printTime(\"任务三\")) await printTime(\"任务四\") print(f\"结束时间:{time.strftime('%X')}\")# 输出结果# 开始时间:18:10:39# 任务四开始时间:18:10:39# 任务一开始时间:18:10:39# 任务二开始时间:18:10:39# 任务三开始时间:18:10:39# 结束时间:18:10:49当使用await时，马上调用任务四，并且之前队列中被创建的任务也全部异步开始，所以会出现这样的输出结果aiohttp库关于aiohttp库，其主要是配合asycio使用，达到异步请求的目的，官方示例已经用比较直观的代码介绍了用法import aiohttpimport asyncioasync def fetch(session, url): async with session.get(url) as response: return await response.text()async def main(): async with aiohttp.ClientSession() as session: html = await fetch(session, 'http://python.org') print(html)if __name__ == '__main__': loop = asyncio.get_event_loop() loop.run_until_complete(main())这里main()函数的调用可以不用太在意，是另一种异步启动协程的办法，这里用我们之前的写法asyncio.run(main())也是一样的效果，aiohttp库内的函数支持协程的特性，让其可以很好和异步编程配合代码中使用aiohttp.ClientSession()创建了一个session对象，对于这个对象，官方文档这样说： 不要为每个请求都创建一个会话。大多数情况下每个应用程序只需要一个会话就可以执行所有的请求。 每个会话对象都包含一个连接池，可复用的连接和持久连接状态(keep-alives，这两个是默认的)可提升总体的执行效率。可以理解成，通过反复使用创建的session对象并keep-alives，就能在单次会话中提高整体请求页面的速率，因为不用在每次请求时再建立新连接开始编写代码在了解了这两个库之后，我们对之前做的爬虫代码进行改善，这里直接上代码：from bs4 import BeautifulSoupimport urllib.requestimport aiohttpimport asynciofrom collections import OrderedDictimport time# IT类工作地址listTypes = ['5480', '5484']jobsNum = []jobList = [\"c#/.net\", \"java\", \"php\", \"web\"]dicResult = OrderedDict()urls = []# 伪装浏览器头部headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ' 'AppleWebKit/537.36 (KHTML, like Gecko) ' 'Chrome/81.0.4044.138 Safari/537.36'}# 获取网页（文本信息）async def fetch(session, url): headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36' } async with session.get(url, headers=headers) as response: return await response.text()def getData(page): soup = BeautifulSoup(page, 'lxml') searchResultPage = soup.find_all(name='div', attrs='rlOne') bolTypeRight = False for job in searchResultPage: tag_a = job.find('a') href = tag_a.get('href') company = job.find('li', 'w2').text salary = job.find('li', 'w3').text jobName = tag_a.text.lower() if href not in jobsNum: jobsNum.append(href) for jobType in jobList: if '-' in salary: if '/' in jobType: bolTypeRight = jobType.split( '/')[0] in jobName or jobType.split('/')[1] in jobName else: bolTypeRight = jobType in jobName if bolTypeRight: if jobType not in dicResult.keys(): dicResult[jobType] = [int(salary.split('-')[0])] else: dicResult[jobType].append( int(salary.split('-')[0])) print(company + \" \" + jobName + \":\" + salary + \" \" + href)# 处理网页async def download(url): async with aiohttp.ClientSession() as session: page = await fetch(session, url) getData(page)time_start = time.time()for type_number in listTypes: url_prefix = 'https://s.gxrc.com/sJob?schType=1&amp;expend=1&amp;PosType=' + \\ type_number + '&amp;page=' # Request类的实例，构造时需要传入Url,Data，headers等等的内容 request = urllib.request.Request(url=url_prefix + '1', headers=headers) first_page = urllib.request.urlopen(request) soup = BeautifulSoup(first_page, 'lxml') intLastPageNumber = int(soup.find('i', {\"id\": \"pgInfo_last\"}).text) urls.extend([url_prefix + str(i) for i in range(1, intLastPageNumber + 1)])async def main(): tasks = [] for url in urls: tasks.append(asyncio.create_task(download(url))) for task in tasks: await task print('广西人才网IT岗统计结果(按岗位标题)') print('总岗位数量:' + str(len(jobsNum))) for resultKey, value in dicResult.items(): print(resultKey + '岗位总数量:' + str(len(value)) + ',平均工资(按岗位最低工资为准):' + str(sum(value) / len(value))) time_end = time.time() print('time cost', time_end-time_start, 's')asyncio.run(main())值得注意的是，对于其中的这一段代码：async def main(): tasks = [] for url in urls: tasks.append(asyncio.create_task(download(url))) for task in tasks: await task可以写成：async def main(): tasks = [] for url in urls: tasks.append(asyncio.create_task(download(url))) await asyncio.gather(*tasks)这里不需要太过在意，把asyncio.gather(*tasks)起到的作用当作和第一种写法实现的相同即可，减少代码量，并发运行所有列表中的协程但是如果写成： tasks = [] for url in urls: tasks.append(asyncio.create_task(download(url))) await(tasks[0])发现程序运行到一半就停止了，只处理了一部分url，这是因为，虽然使用await时所有任务是会同时并发运行，但是我这里只等待了第一项，所以当第一条url完全处理完时，之后程序将不会再等待剩余协程的情况对比非异步的版本终于，我们的异步爬虫编写好了，我们在之前编写的代码和现在编写的代码文件中import time，在循环开始前加上time_start = time.time()，在统计完成后加上time_end=time.time()print('time cost',time_end-time_start,'s')通过对比两次的结果可以看到，爬虫的速度从90s左右变成了20s左右，提升非常巨大，由此可以可以看到，协程配合aiohttp提供的session，可以让爬虫的效率有质的飞跃！" }, { "title": "Python爬虫基础之广西人才网的信息爬取(1) - 简单爬虫", "url": "/posts/python-crawler-1/", "categories": "经验技巧, 爬虫", "tags": "Python", "date": "2020-05-15 00:00:00 +0800", "snippet": " 最近刚学习了Python的语法，迫不及待想做自己的第一个爬虫了，这里记录自己编写一个简单的爬虫程序爬取广西人才网的过程前期准备1.拟定好要爬取的数据，因为这是第一次做爬虫，简单爬取一下广西人才网上各大编程语言的招聘信息，以每个岗位的标题为准，之后再做扩展2.分析网页结构，来到广西人才网首页，如图所示，在分类中找到本次要爬取的岗位分类，都是开发类：点进这两个分类的，可以看到浏览器URL栏中...", "content": " 最近刚学习了Python的语法，迫不及待想做自己的第一个爬虫了，这里记录自己编写一个简单的爬虫程序爬取广西人才网的过程前期准备1.拟定好要爬取的数据，因为这是第一次做爬虫，简单爬取一下广西人才网上各大编程语言的招聘信息，以每个岗位的标题为准，之后再做扩展2.分析网页结构，来到广西人才网首页，如图所示，在分类中找到本次要爬取的岗位分类，都是开发类：点进这两个分类的，可以看到浏览器URL栏中他们的URL分别为：https://s.gxrc.com/sJob?schType=1&amp;expend=1&amp;PosType=5480https://s.gxrc.com/sJob?schType=1&amp;expend=1&amp;PosType=5484点击进去，可以看到如图的页面：可以看出，本次，我们主要需要爬取分析的就是这些岗位的标题部分，以及薪资部分，这两个分类，每个分类都有几十页，这里如何获取到每一页的URL呢，我们试着跳转到本分类的下一页，可以看到，URL变成了https://s.gxrc.com/sJob?schType=1&amp;expend=1&amp;PosType=5480&amp;page=2再多往后面后面翻几页，可以印证我们的猜想，这个网站各分类中每一页的岗位信息分别为：https://s.gxrc.com/sJob?schType=1&amp;expend=1&amp;PosType=岗位类型&amp;page=页码开始编写代码1.这里直接上代码，关于Beautiful Soup具体用法和如何查看页面中元素的标签这里不再赘述，网上有详细教程，不在此篇讨论范围之内from bs4 import BeautifulSoupimport urllib.requestfrom collections import OrderedDict# IT类工作地址listTypes = ['5480', '5484']jobsNum = []jobList = [\"c#/.net\", \"java\", \"php\"]dicResult = OrderedDict()# 伪装浏览器头部headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ' 'AppleWebKit/537.36 (KHTML, like Gecko) ' 'Chrome/81.0.4044.138 Safari/537.36'}for type_number in listTypes: url_prefix = 'https://s.gxrc.com/sJob?schType=1&amp;expend=1&amp;PosType=' + type_number + '&amp;page=' # Request类的实例，构造时需要传入Url,Data，headers等等的内容 request = urllib.request.Request(url=url_prefix + '1', headers=headers) first_page = urllib.request.urlopen(request) soup = BeautifulSoup(first_page, 'lxml') intLastPageNumber = int(soup.find('i', {\"id\": \"pgInfo_last\"}).text) urls = [url_prefix + str(i) for i in range(1, intLastPageNumber + 1)] for url in urls: request = urllib.request.Request(url=url, headers=headers) page = urllib.request.urlopen(request) search_result = BeautifulSoup(page, 'lxml').find_all(name='div', attrs='rlOne') bolTypeRight = False for job in search_result: tag_a = job.find('a') href = tag_a.get('href') company = job.find('li', 'w2').text salary = job.find('li', 'w3').text jobName = tag_a.text.lower() if href not in jobsNum: jobsNum.append(href) for jobType in jobList: if '-' in salary: if '/' in jobType: bolTypeRight = jobType.split('/')[0] in jobName or jobType.split('/')[1] in jobName else: bolTypeRight = jobType in jobName if bolTypeRight: if jobType not in dicResult.keys(): dicResult[jobType] = [int(salary.split('-')[0])] else: dicResult[jobType].append(int(salary.split('-')[0])) print(company + \" \" + jobName + \":\" + salary + \" \" + href)print('广西人才网IT岗统计结果(按岗位标题)')print('总岗位数量:' + str(len(jobsNum)))for resultKey, value in dicResult.items(): print(resultKey + '岗位总数量:' + str(len(value)) + ',平均工资(按岗位最低工资为准):' + str(sum(value) / len(value)))" }, { "title": "Python入门小记(3)：函数，类", "url": "/posts/python-3/", "categories": "编程语言, Python", "tags": "Python", "date": "2020-05-08 00:00:00 +0800", "snippet": " 最后需要了解的入门知识，函数和类函数函数的定义以及调用方式1.可以通过示例的函数和相关调用看出Python中函数的一些特征，比较特别的地方有 使用def关键字来表示将要开始定义一个函数 从函数内容开始的行，到函数的结束行，缩进的字符数都必须大于0，且以函数内容的第一行的缩进数为基准，按照Python的缩进规则进行代码编写，到不进行缩进的行为止，则不为该函数的内容def printUs...", "content": " 最后需要了解的入门知识，函数和类函数函数的定义以及调用方式1.可以通过示例的函数和相关调用看出Python中函数的一些特征，比较特别的地方有 使用def关键字来表示将要开始定义一个函数 从函数内容开始的行，到函数的结束行，缩进的字符数都必须大于0，且以函数内容的第一行的缩进数为基准，按照Python的缩进规则进行代码编写，到不进行缩进的行为止，则不为该函数的内容def printUserID(userName, userID=1): # 冒号表示函数开始 print(userName + \"'s userID is \" + str(userID)) return 'OK'printUserID('Tony', 2)printUserID(userName='John', userID=3)print(printUserID('Jack'))# 输出内容# Tony's userID is 2# John's userID is 3# Jack's userID is 1# OK传递任意数量的实参1.用星号可以让多个参数作为一个元组传进函数中def printNumers(tilte, *numbers): for number in numbers: print(tilte + str(number))title = \"This is \"printNumers(title)printNumers(title, 0)printNumers(title, 1, 2, 3)# 输出内容# This is 0# This is 1# This is 2# This is 3使用任意数量的关键字实参1.用两个星号让参数以字典的形式传进函数中def printSetting(userName, **settings): print(userName + ' setting:') for key, value in settings.items(): print(\"loading...\") print(settings)printSetting(\"Tom\", Enable=True, Font='Big', Location='China')# 输出内容# Tom setting:# loading...# loading...# loading...# {'Enable': True, 'Font': 'Big', 'Location': 'China'}使用模块中的函数首先，我们新建几个文件，表示不同的模块# animal_one.pydef print_animal_one(): print('An animal')# animal_two.pydef print_animal_two(): print('Two animals')# animal_three.pydef print_animal_three(): print('Three animals')def print_animal_two(): print('Two animals in three')接着，在一个模块中进行导入和函数调用# call_animals.pyimport animal_one # 导入整个模块，在调用具体函数时使用模块名加句点的方式from animal_two import print_animal_two # 导入指定模块中的指定函数import animal_one as t # 使用as给模块指定别名from animal_two import print_animal_two as print_two # 使用as给函数指定别名from animal_three import * # 引入指定模块中的所有函数，在调用时不需要使用句点animal_one.print_animal_one()print_animal_two()t.print_animal_one()print_two()print_animal_three()# An animal# Two animals in three# An animal# Two animals# Three animals1.从上面的示例中不难看出在Python中如何使用模块中的函数，值得注意的是，如果进行了重复导入，行号靠后的导入会覆盖之前的导入类定义类首先，我们新建一个文件，创建两个类# animals.pyclass Dog(): def sit(self): print('小狗蹲下了') def roll(self): print('小狗打了个滚')class Cat(): def __init__(self, name): self.name = name def meow(self): print('喵~') def run(self): print(self.name + '跑起来了')1.类中的函数被称为方法，__init__()是一个特殊的方法，每次创建新实例时，都会自动调用它，开头和末尾的下划线是一种约定，为了避免Python默认方法与普通方法发生冲突，在这个方法中，可以进行对属性进行定义并初始化等操作2.方法的定义中都必须包含形参self，它是一个指向实例本身的引用，让实例能访问类中的属性和方法，在调用方法时，此参数会自动传递导入并使用类# call_animals.pyfrom animals import Dog, CatmyDog = Dog()myDog.sit()myDog.roll()myCat = Cat(\"Cola\")myCat.name = \"可乐\"myCat.meow()myCat.run()# 输出内容# 小狗蹲下了# 小狗打了个滚# 喵~# 可乐跑起来了继承在已有animals模块的基础上创建新的类并对其进行调用# AmazingCat.pyfrom animals import Catclass AmazingCat(Cat): def __init__(self, name, size): super().__init__(name) # 初始化父类的属性 self.size = size # 初始化LittleCat类的特有属性 def meow(self): print('meow~') def description(self): print(self.name + \" is a \" + self.size + \" cat\")myLittleCat = AmazingCat(\"Cola\", \"little\")myLittleCat.meow()myLittleCat.run()myLittleCat.description()# 输出内容# meow~# Cola跑起来了# Cola is a little cat1.首先需要注意的是，在子类AmazingCat的首行，定义子类时，在括号内指定父类的名称，第一个__init__指定AmazingCat需要的所有参数2.通过使用特殊函数super()，让父类和子类相关联，这里调用父类的__init__方法对父类的内容进行初始化，从而让子类也包含父类的所有属性。因为父类也被成为超类(superclass)，所以这个函数名为super3.需要重写父类的方法，只需要在子类定义父类中同名的方法P.S.在Python中，存在一些内置的标准库，可以在实际使用中用import直接调用，这里演示标准库中的一个类OrderedDict，其与字典几乎完全相同，区别只在于记录了键值对的添加顺序from collections import OrderedDictdict_ordered = OrderedDict()dict_ordered['Tony'] = 'Los Angeles'dict_ordered['Jack'] = 'San Francisco'dict_ordered['Tom'] = 'California'for name, hometown in dict_ordered.items(): print(name + \" is from \" + hometown)# 输出结果# Tony is from Los Angeles# Jack is from San Francisco# Tom is from California" }, { "title": "让博客内容被搜索引擎搜到-谷歌篇", "url": "/posts/jekyll-1/", "categories": "Jekyll相关", "tags": "Jekyll", "date": "2020-05-06 00:00:00 +0800", "snippet": "第一步：验证网站所有者身份使用自己的Google账户登录到Google搜索控制台，点击添加资源，先选择资源类型，在这里我选择网域，输入要验证的域名，点击继续此时，会弹出提示，让你通过 DNS 记录验证域名所有权，此时，根据自己的DNS提供商，来选择相应的TXT记录具体添加方式，可以在根据自己的DNS，在这里查询到具体添加指南，按照指南把TXT记录添加到DNS配置，再回到此页面，点击验证，等待...", "content": "第一步：验证网站所有者身份使用自己的Google账户登录到Google搜索控制台，点击添加资源，先选择资源类型，在这里我选择网域，输入要验证的域名，点击继续此时，会弹出提示，让你通过 DNS 记录验证域名所有权，此时，根据自己的DNS提供商，来选择相应的TXT记录具体添加方式，可以在根据自己的DNS，在这里查询到具体添加指南，按照指南把TXT记录添加到DNS配置，再回到此页面，点击验证，等待验证成功即可第二步：生成并提交站点地图此时，Google已经知道你的网站的存在，现在需要做的是，告诉Google你网站的层次结构，这通过sitemap.xml文件实现因为这里博主用的是Jekyll来搭建的博客，它提供了自动生成站点地图的插件，这里讲解下相关步骤，首先，在Jekyll模板目录的Gemfile文件中，添加gem: jekyll-sitemap# If you have any plugins, put them here!group :jekyll_plugins do gem \"jekyll-feed\", \"~&gt; 0.6\" gem 'jekyll-sitemap'end之后，打开_config.yml文件，添加 add plugins: - jekyll-sitemap并保存文件plugins: - jekyll-sitemap最后，运行bundle exec jekyll serve,名为sitemap.xml的文件将会在网站的根目录自动生成（若在执行这条时，弹出错误信息，提示需要运行bundle install来安装缺少的插件，运行即可）此时，使用域名/sitemap.xml,比如https://colasaikou.com/sitemap.xml就可以查看到生成的站点地图了，此时，回到Google搜索控制台，在索引-站点地图中添加站点地图网址即可，提交站点地图可以帮助Google建立网站的索引，这可能需要一定的时间，我是在添加之后几个小时内看到自己的网站内容陆续出现在Google搜索中查看自己站点在搜索引擎上的收录情况这里以Google和本站为例，建立站点地图后，在Google搜索栏输入site:https://colasaikou.com,就可以看到网站在搜索引擎上的收录情况，所有可以被搜索到的条目会被列出来" }, { "title": "Python入门小记(2)：if语句、字典、while循环", "url": "/posts/python-2/", "categories": "编程语言, Python", "tags": "Python", "date": "2020-05-03 00:00:00 +0800", "snippet": " 经过前面的学习，发现Python和之前接触到的编程语言，还是有很多相同之处，之后的记录，会着重记录比较特别的部分if语句1.Python中，if语句的写法示例(注意冒号的位置)messge = 'We can find 'namelist = ['Jack', 'Tony', 'Alice']if 'jack' in namelist: print(messge + 'jack')...", "content": " 经过前面的学习，发现Python和之前接触到的编程语言，还是有很多相同之处，之后的记录，会着重记录比较特别的部分if语句1.Python中，if语句的写法示例(注意冒号的位置)messge = 'We can find 'namelist = ['Jack', 'Tony', 'Alice']if 'jack' in namelist: print(messge + 'jack')elif namelist and 'Tony' in namelist: print(messge + 'Tony')else: print(messge + 'nobody')字典1.在Python中，字典用放在花括号{}中的一系列键值对表示letterValue = {'A': 1, 'B': 2, 'C': 3}print(letterValue['A']) # 1letterValue['D'] = 3 # 添加新的键值对del letterValue['B'] # 删除指定的键值对print('D' in letterValue.keys()) # 判断字典中是否有此键，这里为Trueprint(letterValue) # {'A': 1, 'C': 3, 'D': 3}print([value for key, value in letterValue.items()]) # [1, 3, 3]print([key for key in sorted(letterValue.keys(), reverse=True)]) # 对Key值按照倒序排列之后输出['D', 'B', 'A']print([value for value in set(letterValue.values())]) # 输出去重后的结果[1, 3]while循环1.Python中的while也可以用continue,break等语句listName = []name = ''while True: name = input('Please enter your name:') if name.strip() == '': continue elif name != 'Quit': listName.append(name) else: breakprint(listName)# 运行结果# Please enter your name:aa# Please enter your name:# Please enter your name:bb# Please enter your name:cc# Please enter your name:dd# Please enter your name:ee# Please enter your name:ff# Please enter your name:Quit# ['aa', 'bb', 'cc', 'dd', 'ee', 'ff']" }, { "title": "在PS中调用JS实现批量替换智能对象图层", "url": "/posts/tips-1/", "categories": "经验技巧, 日常工具", "tags": "Tips", "date": "2020-05-02 00:00:00 +0800", "snippet": " 今天看到女友在用PS制图的时候，有很多张图片需要替换智能对象的内容，不得不对图片一张一张进行对象替换并且保存，一番搜寻之后找到了这个方法首先，在PS中是可以调用JS的，具体方法是在PS中通过文件→脚本→浏览，选中脚本文件执行这里贴出用批量替换智能对象图层的JS代码，代码来源：replace_smartobject_image.js// Replace SmartObject’s Cont...", "content": " 今天看到女友在用PS制图的时候，有很多张图片需要替换智能对象的内容，不得不对图片一张一张进行对象替换并且保存，一番搜寻之后找到了这个方法首先，在PS中是可以调用JS的，具体方法是在PS中通过文件→脚本→浏览，选中脚本文件执行这里贴出用批量替换智能对象图层的JS代码，代码来源：replace_smartobject_image.js// Replace SmartObject’s Content and Save as JPG// 2017, use it at your own risk// Via @Circle B: https://graphicdesign.stackexchange.com/questions/92796/replacing-a-smart-object-in-bulk-with-photoshops-variable-data-or-scripts/93359// JPG code from here: https://forums.adobe.com/thread/737789#target photoshopif (app.documents.length &gt; 0) { var myDocument = app.activeDocument; var theName = myDocument.name.match(/(.*)\\.[^\\.]+$/)[1]; var thePath = myDocument.path; var theLayer = myDocument.activeLayer; // JPG Options; jpgSaveOptions = new JPEGSaveOptions(); jpgSaveOptions.embedColorProfile = true; jpgSaveOptions.formatOptions = FormatOptions.STANDARDBASELINE; jpgSaveOptions.matte = MatteType.NONE; jpgSaveOptions.quality = 8; // Check if layer is SmartObject; if (theLayer.kind != \"LayerKind.SMARTOBJECT\") { alert(\"selected layer is not a smart object\") } else { // Select Files; if ($.os.search(/windows/i) != -1) { var theFiles = File.openDialog(\"please select files\", \"*.psd;*.tif;*.jpg\", true) } else { var theFiles = File.openDialog(\"please select files\", getFiles, true) }; if (theFiles) { for (var m = 0; m &lt; theFiles.length; m++) { // Replace SmartObject theLayer = replaceContents(theFiles[m], theLayer); var theNewName = theFiles[m].name.match(/(.*)\\.[^\\.]+$/)[1]; // Save JPG myDocument.saveAs((new File(thePath + \"/\" + theName + \"_\" + theNewName + \".jpg\")), jpgSaveOptions, true,Extension.LOWERCASE); } } }};// Get PSDs, TIFs and JPGs from filesfunction getFiles(theFile) { if (theFile.name.match(/\\.(psd|tif|jpg)$/i) != null || theFile.constructor.name == \"Folder\") { return true };};// Replace SmartObject Contentsfunction replaceContents(newFile, theSO) { app.activeDocument.activeLayer = theSO; // ======================================================= var idplacedLayerReplaceContents = stringIDToTypeID(\"placedLayerReplaceContents\"); var desc3 = new ActionDescriptor(); var idnull = charIDToTypeID(\"null\"); desc3.putPath(idnull, new File(newFile)); var idPgNm = charIDToTypeID(\"PgNm\"); desc3.putInteger(idPgNm, 1); executeAction(idplacedLayerReplaceContents, desc3, DialogModes.NO); return app.activeDocument.activeLayer};" }, { "title": "Python入门小记(1)：简单数据类型、列表、元组", "url": "/posts/python-1/", "categories": "编程语言, Python", "tags": "Python", "date": "2020-04-29 00:00:00 +0800", "snippet": " 开始学习Python，买了好久的书终于派上用场，虽然Python语法简单，但想从基础了解Python，所以一步一步来，先开始了解简单的数据类型、列表、元组，把重点地方做个小记字符串1.引号，在Python中，可以用单引号或者双引号括起整个字符串，这使得字符串中可以包含引号和撇号print(\"这是一个字符串\") # 这是一个字符串print('这也是一个字符串') # 这也是一个字符串...", "content": " 开始学习Python，买了好久的书终于派上用场，虽然Python语法简单，但想从基础了解Python，所以一步一步来，先开始了解简单的数据类型、列表、元组，把重点地方做个小记字符串1.引号，在Python中，可以用单引号或者双引号括起整个字符串，这使得字符串中可以包含引号和撇号print(\"这是一个字符串\") # 这是一个字符串print('这也是一个字符串') # 这也是一个字符串print(\"It's a string\") # It's a stringprint('这是一个\"字符串\"') # 这是一个\"字符串\"2.修改字符串的大小写，除了熟悉的 string.upper()，string.lower()之外，还有一个有用的方法叫做string.title()，它可以让字符串的每个单词首字母大写，而其它部分变为小写print(\"love song,lOvE SONG,love sOng\".title()) # Love Song,Love Song,Love Song3.去掉字符串开头，结尾，两边的括号，分别用print(\" 这是一个字符串\".lstrip()) # 这是一个字符串print(\"这是一个字符串 \".rstrip()) # 这是一个字符串print(\" 这是一个字符串 \".strip()) # 这是一个字符串数字1.Python用两个乘号表示乘方运算print(2**3) # 8列表1.Python中，用方括号([])来表示列表，用逗号分隔元素tasklist = ['task1', 'task2', 'task3', 1, 2, 3]print(tasklist) # ['task1', 'task2', 'task3', 1, 2, 3]2.使用索引-1可以返回列表中最后一个元素（以此类推）tasklist = ['task1', 'task2', 'task3', 1, 2, 3]print(tasklist[-1]) # 3print(tasklist[-2]) # 2print(tasklist[-3]) # 13.修改、添加和删除列表中的元素tasklist = ['task1', 'task2', 'task3', 1, 2, 3]tasklist.append(4) # 在列表末尾添加元素tasklist.insert(3, \"task4\") # 在列表指定位置添加元素del tasklist[0] # 删除列表中指定位置的元素print(tasklist.pop()) # 弹出列表末尾的值并接着使用这个值tasklist.remove(\"task2\") # 弹出列表中的指定值，若该值出现过多次，则需要循环判断print(tasklist) # ['task3', 'task4', 1, 2, 3]4.使用方法sort()可以对列表进行永久性排序，向sort()方法传递参数reverse=true可以反向排序listOne=[\"C\",\"D\",\"A\",\"B\"]listOne.sort()print(listOne) # ['A', 'B', 'C', 'D']listOne.sort(reverse=True)print(listOne) # ['D', 'C', 'B', 'A']5.使用函数sorted()可以对列表进行临时排序listOne=[\"C\",\"D\",\"A\",\"B\"]print(sorted(listOne)) # ['A', 'B', 'C', 'D']print(sorted(listOne,reverse=True)) # ['D', 'C', 'B', 'A']print(listOne) # ['C', 'D', 'A', 'B']6.使用方法reverse()可以反转列表中元素的排列顺序listOne=[\"C\",\"D\",\"A\",\"B\"]listOne.reverse()print(listOne) # ['B', 'A', 'D', 'C']listOne.reverse()print(listOne) # ['C', 'D', 'A', 'B']操作列表1.Python中for循环的使用示例值得注意的地方有： Python中用缩进来判断代码行与前一个代码行的关系，这里需要注意缩进； 小心不要遗漏循环第一行前的冒号，这告诉程序下一行是循环的第一行，如果遗漏，会导致语法错误listnum=[1,2,3,4,5,6]for number in listnum: print(number) # 这段代码会循环依次打印出1,2,3,4,5,62.使用函数range()快速创建数字列表print(list(range(6))) # [0, 1, 2, 3, 4, 5]print(list(range(2,6))) # [2, 3, 4, 5]print(list(range(2,10,2))) # [2, 4, 6, 8]单个参数的range()会指定停止值，产生从0开始到停止值之前的数字；两个参数时，要求指定开始值和停止值，产生从开始值到停止值之前的数字；三个参数时，则可以额外指定步长3.找出数字列表中的最大值，最小值，以及求和numbers=[1,2,3,4,5,6,7,8,9,10]print(min(numbers)) # 1print(max(numbers)) # 10print(sum(numbers)) # 554.使用列表解析快速构建出想要的列表numbersIWant = [value**3 for value in range(100,103)]print(numbersIWant) # [1000000, 1030301, 1061208]5.使用切片输出列表中想要的元素letters = ['A','B','C','D','E','F','G','H','I']# 指定要使用的第一个元素的索引和最后一个元素的索引加1来指定要切片的部分print(letters[1:4]) # ['B', 'C', 'D']# 如果不指定第一个元素的索引，默认从0开始print(letters[:4]) # ['A', 'B', 'C', 'D']# 如果不指定第二个元素的索引，默认到列表的末尾print(letters[1:]) # ['B', 'C', 'D', 'E', 'F', 'G', 'H', 'I']# 这里输入列表的最后三个元素print(letters[-3:]) # ['G', 'H', 'I']# 使用切片创建列表的副本print(letters[:]) # ['A','B','C','D','E','F','G','H','I']元组1.元组是不可变的列表，其用圆括号而不是方括号来标识，需要修改元组的元素时，只能重新定义整个元组numbers=(1,2,3)# 因为元组中的元素是不能修改的，所以这里会返回错误信息numbers[1] = 0 # TypeError: 'tuple' object does not support item assignment" }, { "title": "Hello Jekyll", "url": "/posts/hello-jekyll/", "categories": "Jekyll相关", "tags": "Jekyll", "date": "2020-04-13 00:00:00 +0800", "snippet": "Welcome to my blog这是我的第一篇jekyll博客，以后会在这里更新啦！", "content": "Welcome to my blog这是我的第一篇jekyll博客，以后会在这里更新啦！" }, { "title": "Code snippets(代码片段)的使用(附简单的Snippet管理工具)", "url": "/posts/vs-2/", "categories": "编程工具, IDE", "tags": "Visual Studio", "date": "2019-09-27 00:00:00 +0800", "snippet": " Code snippet (代码片段)在VS中指的是基于IDE支持的利用快捷方式快速输入一小段，或者称之为一整块代码的功能，在日常编程，特别是在工作中写内容相似的业务代码时，利用Snippet功能，可以极大加快编程效率引言小张是一个IMIS软件的程序员，每天的工作内容就是处理各种数据表，他最近在写代码的时候，发现经常有客户需要在一个Remark字段中储存一串多行的字符串，用其中的每一行的...", "content": " Code snippet (代码片段)在VS中指的是基于IDE支持的利用快捷方式快速输入一小段，或者称之为一整块代码的功能，在日常编程，特别是在工作中写内容相似的业务代码时，利用Snippet功能，可以极大加快编程效率引言小张是一个IMIS软件的程序员，每天的工作内容就是处理各种数据表，他最近在写代码的时候，发现经常有客户需要在一个Remark字段中储存一串多行的字符串，用其中的每一行的冒号之后的内容代表一个自定义的字段，比如，在这串字符串中得到姓名字段：职业：程序员姓名：张三性别：男为此，他经常需要在不同的客户的程序中写同一个方法：/// &lt;summary&gt;/// 得到字符串特定行的第一个冒号(若有)之后的内容/// &lt;/summary&gt;/// &lt;param name=\"strSource\"&gt;源字符串&lt;/param&gt;/// &lt;param name=\"intRow\"&gt;指定的行数&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;public static string GetSpecificRow(string strSource, int intRow){ string strResult = \"\"; //用回车分割字符串 string[] strFields = strSource.Split('\\n'); //只有目标行数不大于当前字符串行数且大于0才需要操作 if (intRow &gt;= 1 &amp;&amp; strFields.Length &gt;= intRow) { //用冒号拆分这一行的内容为两部分 string[] strRow = strFields[intRow - 1].Split(new char[] { ':' }, 2); //若数组长度为1，证明没有冒号，直接返回这一行的内容，否则返回冒号之后的内容 strResult = strRow.Length == 1 ? strRow[0] : strRow[1].TrimEnd(); } return strResult;}因为写的次数确实也有好几次了，小张觉得每次遇到都写一次这个方法，实在是太蠢了，虽然其实很多时候可以去找到上次写过的，然后Copy过来，但是还是有点蠢，因为每次都不得不去回忆在哪里用到过，然后找到对应的代码文件。他转念一想，可以放在公司的公用代码库(Code Library)里作为一个公用方法，就可以直接调用啦，可不成想，这个做法却遭到了一个老同事的反对，同事这样说：“不要整天你觉得有一个方法很常用就往库里面加，谁知道你写的方法可不可靠，而且谁都像你这样动不动就往里面加东西的话，以后里面方法一大堆，谁找得到。”好吧，觉得有点道理，又觉得没什么道理，不过确实也是这样，有时候你觉得好的东西，别人不一定觉得好，你觉得值得分享的东西，别人可能觉得没价值。既然如此，只能再想想办法啦。忽然，小张想到，平时在写for循环和定义属性的时候，经常会这样做：在代码中输入for，IDE会提示有可用的代码片段，双击Tab键就会出现属于for循环的内置代码片段：for (int i = 0; i &lt; length; i++){}此时，光标会定位在”i”处，然后可以把”i”改成自己想要的局部变量名，再按Tab键，可以看到后面的两个”i”都会随之改变，之后光标会定位在”length”处，把”length”改成自己想要的数，按Enter键，可以看到光标定位在了for循环体中，可以开始写循环体中的代码了如此方便的功能，能否自己DIY，创建一些属于自己的代码片段呢，小张搜索了[MSDN文档]https://docs.microsoft.com/zh-cn/visualstudio/ide/code-snippets?view=vs-2019)相关内容，发现结论是肯定的，甚至可以说这个功能就是为DIY而生的，他总结了一些有价值的信息代码片段的存放位置及其内容打开Visual Studio → 工具 → 代码片段管理器 → 选择编程语言可以看到出现了一些文件夹供选择，我们可以在这里找到刚刚出现的那个for循环的代码片段：根据图示文件夹，找到for.snippet文件，双击打开(会默认自动用VS打开，没有的话可以用其它任意的文本编辑器打开)，可以看到是一个XML结构的文本，也就是说，snippet实际上是以XML文件来储存的，那么现在问题就简单了，为了快速说明这个文件，我们为其添加一些注释可以看到，一个Snippet文件大致分为两个部分：&lt;Header&gt;&lt;/Header&gt;标签之间的一些关于属性的定义 Title 标题 Shortcut 在IDE中以何快捷键触发 Description Snippet内容描述 Author 作者 SnippetType Snippet种类，是否允许插入在光标处，是否允许围绕在选中代码两边(选中一段代码，按Ctrl+K,Ctrl+X，然后选中支持此属性的Snippet，就能把这段代码放在选中代码的两边)等 **标签之间的一些关于代码片段内容的定义(Markdown不支持复杂的表格，这里用图片来表示)如何自定义并使用自己的代码片段打开Visual Studio → 工具 → 代码片段管理器 → 选择编程语言可以看到VS为我们内置了一个代码片段文件夹，叫做My Code Snippets，我们只要自己创建一个snippet文件(复制内置的过来调整即可)，然后在里面写上自己想要的内容，放进这个文件夹就行啦，比如前言中小张的需求，我们为他编写了一个snippet因为他的需求比较简单，只是想要快速输入方法，所以内容主要是方法体本身，没有$包含的字符串，我们把这个文件存进刚刚说的My Code Snippets文件夹，可以看到，不需要重启VS，打开代码片段管理器，这里已经出现了我们自定义的代码片段试着使用看看，在IDE中输入快捷方式”gsr”，可以看到一整个方法体直接出现了，小张终于可以解放双手了，他接下来有了新的想法，把Snippet分类，做一个属于自己的代码片段库，里面包含各种自己常用的代码片段，这样不但可以方便查找常用的方法，不用去仔细回忆，寻找各种文件，还能作为自己的一个知识储备库，想到这里，他笑开了花后记：合理使用代码片段确实能给我们的编程提高不少效率，但是编写代码片段本身也是一个有点消耗时间的过程，笔者为了进一步解放双手，用Winform开发了一个简单的小工具用于快速编写和储存Snippet，大家可以随意取用，代码在https://github.com/GadHao/SnippetManager晚安啦各位！" }, { "title": "C#中的值类型和引用类型", "url": "/posts/csharp-1/", "categories": "编程语言, C#", "tags": "C#", "date": "2019-09-21 00:00:00 +0800", "snippet": " 工作之外暂没有可以上手写的东西，这周主要内容还是对C#一些关于类型的知识进行巩固，涉及到的书籍主要是深入理解C#（第3版）值类型和引用类型先从现实生活中的值和引用来讨论这点： 假设你正在读一份报纸，觉得里面的内容很棒，希望一个朋友也去读，影印了报纸的全部内容并交给他。届时，他将获得属于他自己的一份完整的报纸。在这种情况下，我们处理的是值类型的行为。所有信息都在你的手上，不需要从任何其他...", "content": " 工作之外暂没有可以上手写的东西，这周主要内容还是对C#一些关于类型的知识进行巩固，涉及到的书籍主要是深入理解C#（第3版）值类型和引用类型先从现实生活中的值和引用来讨论这点： 假设你正在读一份报纸，觉得里面的内容很棒，希望一个朋友也去读，影印了报纸的全部内容并交给他。届时，他将获得属于他自己的一份完整的报纸。在这种情况下，我们处理的是值类型的行为。所有信息都在你的手上，不需要从任何其他地方获得。制作了副本之后，你的这份信息和朋友的那份是各自独立的。可以在自己的报纸上添加一些注解，他的报纸根本不会改变。 再假设你正在读的是一个网页。与前一次相比，这一次，唯一需要给朋友的就是网页的URL。这是引用类型的行为，URL代替引用。为了真正读到文档，必须在浏览器中输入URL，并要求它加载网页来导航引用。另一方面，加入网页由于某种原因发生了变化（如一个维基页面，你在上面添加了自己的注释），你和你的朋友下次载入页面时，都会看到那个改变。.NET中大多数类型都是引用类型 类（使用class来声明）是引用类型，而结构（使用struct）来声明是值类型。特殊情况包括：1.数组类型是引用类型，即使元素类型是值类型（所以即便int是值类型，int[]仍是引用类型）；2.枚举(使用enum来声明)是值类型；3.委托类型(使用delegate来声明)是引用类型；4.接口类型（使用interface来声明）是引用类型，但可由值类型实现。那么，为什么要分为值类型和引用类型呢： ​ 引用类型总是从托管堆分配，C#的new操作符返回对象的内存地址，如果所有类型都是引用类型，则程序在运行的过程中，需要进行很多次内存分配，会显著影响程序性能 ​ 值类型的实例一般在线程栈上分配（虽然也可作为字段嵌入引用类型的对象中），代表值类型实例的对象中不包含指向实例的指针，其不受垃圾回收器的控制。因此，值类型的使用缓解了托管堆的压力，并减少了应用程序生存期内的垃圾回收次数。可以这样说：对于值类型的表达式，它的值就是表达式的值，与此同时，对于引用类型的值，它的值是一个引用，这个引用指向它在堆中的位置。我们用下一段代码，通过对不同类型的变量内部进行值比较以及赋值等操作来理解前面提到的这些：static void Main(string[] args){ //定义一个值类型变量，其值存放在线程栈上 int intVal = 0; //定义一个引用类型变量，其实际数据位于堆中，值(其引用)存放在线程栈上 List&lt;int&gt; objListRef = new List&lt;int&gt;(); bool bolResult; #region 变量值比较 //先定义两个新的变量，用来与前面的两个变量作比较 int intCompare = 0; List&lt;int&gt; objListCompare = new List&lt;int&gt;(); bolResult = (intVal == intCompare); //这里返回true，因为这两个值类型的值是相同的 Console.WriteLine($\"{nameof(intVal)}和{nameof(intCompare)}{(bolResult == true ? \"\" : \"不\")}相等\"); bolResult = (objListRef == objListCompare); //这里返回false，因为这两个值(这两个变量的引用)位于堆中不同的位置 Console.WriteLine($\"{nameof(objListRef)}和{nameof(objListCompare)}{(bolResult == true ? \"\" : \"不\")}相等\"); #endregion #region 变量赋值 intCompare = intVal; intCompare++; //这里会输出0，因为虽然intCompare的值加了1，但是其是值类型 //intCompare = intVal把intVal的值赋给了intCompare，相当于于复制了一个intVal，其值和intCompare相同 //所以对intCompare的更改不会作用到intVal Console.WriteLine($\"{nameof(intVal)}:{intVal}\"); objListCompare = objListRef; objListCompare.Add(0); //这里会输出1，因为这里的变量是引用类型 //objListCompare = objListRef表示把objListRef的值(它的引用)赋给objListCompare //因为它们指向堆中的同一个位置，所以从此时开始，对objListCompare做的任何修改操作都会作用到objListRef Console.WriteLine($\"{nameof(objListRef)}长度为:{objListRef.Count}\"); objListCompare = new List&lt;int&gt;(); //这里仍然会输出1，因为当objListCompare重新初始化，它的值和objListRef的值已经不是指向堆中的同一个位置 //所以对它们的操作又重新变成对堆中不同数据的操作 Console.WriteLine($\"{nameof(objListRef)}长度为:{objListRef.Count}\"); #endregion}所以不难理解在日常使用方法的产生的一些疑惑：Question1：为什么日常使用一些方法时，方法参数用默认的val传递，在方法内部对传递过来的参数进行修改，在方法执行完毕后，调用位置的那个变量的数据不会发生改变(当参数为值类型)，数据发生改变(当参数为引用类型) 呢？Answer：在进行参数值传递时，对于值类型来说，相当于传递了它的值的一个副本，对于引用类型来说，相当于传递了它的引用的一个副本。所以在方法内部对值的副本进行改变，外部值类型变量本身的数据不会发生变化，而引用类型变量变化时(前提是不改变其引用)，因为它们都指向同一个地址，所以可以实现数据的改变；Tips：值传递时，如果在方法内修改了参数的引用，则代表切断了与外部变量的联系，即在值传递时，是无法在方法内部修改调用处变量的引用的实际值的，只是把这个值赋值过来“用”。如果想改变调用处变量的引用，需要使用ref传递，如下面的代码：static void Main(string[] args){ List&lt;int&gt; objList = null; SomeByValMethod(objList); //这里判断的结果是等于null Console.WriteLine($\"{nameof(objList)}{(objList == null ? \"\" : \"不\")}等于null\"); SomeByRefMethod(ref objList); //这里判断的结果是不等于null Console.WriteLine($\"{nameof(objList)}{(objList == null ? \"\" : \"不\")}等于null\");}private static void SomeByValMethod(List&lt;int&gt; objList){ objList = new List&lt;int&gt;();}private static void SomeByRefMethod(ref List&lt;int&gt; objList){ objList = new List&lt;int&gt;();}Question2：为什么ref传递时，在传参时不能写形如ref null这样的形式，而是必须要传一个实际的参数，但当一个引用类型的变量等于null，却是可以这样写且不会报错的呢？Answer：关于为何不能写成ref null的形式，因为不难看出这样做的不合理性，因为不可能“改变null在内存中指向的位置”；而当一个引用类型的变量等于null的时候，只是代表还没有为其在堆中重新分配内存，还未引用任何一个对象(内存中用全零来表示null)，本质上它还是采用和其他引用一样的方式来存储的，所以在方法内部把这个变量的地址指向一个新的位置也就说得通了今天就总结到这儿，以后根据个人理解可能会修改或者新增一些内容，晚安啦！（之前发到知乎没什么人看，以后还是在这儿更新吧）" } ]
